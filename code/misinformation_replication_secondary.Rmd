---
title: 'Facebook Misinformation Study, pre-analysis replication script'
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_folding: hide
    number_sections: true
---



# Data reading
```{r paths, message = FALSE}
set.seed(60637)
source('utils.R')
library(xtable)

dir.create(file.path('..', 'tables'), showWarnings = FALSE)
dir.create(file.path('..', 'figures'), showWarnings = FALSE)
dir.create(file.path('objects'), showWarnings = FALSE)
```




## Load Data
Load most recent download of data; the file name indicates the download date. 
```{r data, cache = TRUE}
files <- list.files('../data', 
                    pattern = '^cleaned-data.*rds$', 
                    full.names = TRUE)

(INPUT_FILENAME <- files[which.max(file.info(files)$mtime)])
df_treat <- readRDS(INPUT_FILENAME)


files <- list.files('../data', 
                    pattern = '^cleaned-data-secondary.*rds$', 
                    full.names = TRUE)

(INPUT_FILENAME <- files[which.max(file.info(files)$mtime)])
df_secondary <- readRDS(INPUT_FILENAME)

context_cols <- c('male', 
                  'age', 
                  'age_flag',
                  'age_check_flag',
                  'ed', 'ed_flag', 
                  'urban',
                  'rel_christian', 'rel_muslim',
                  'denom_pentecostal', 
                  'religiosity', 'religiosity_flag',
                  'locus', 'locus_flag',
                  'science', 'science_flag',
                  'dli',
                  'fb_post', 'fb_post_flag',
                  'fb_msg', 'fb_msg_flag',
                  'crt',
                  'hhi', 'hhi_flag',
                  'cash',
                  'hh', 'hh_flag',
                  'pol',
                  'cov_concern', 'cov_concern_flag',
                  'cov_efficacy', 'cov_efficacy_flag',
                  'nigeria')

demos_cols <- c('male', 
                'age', 'age_flag',
                'ed', 'ed_flag', 
                'urban', 
                'rel_none', 'rel_christian', 'rel_muslim', 'rel_traditionalist', 'rel_other', 'denom_pentecostal', 'religiosity',
                'religiosity_flag',
                'god',
                'locus', 'locus_flag',
                'science', 'science_flag',
                'dli',
                'fb_post', 'fb_post_flag',
                'fb_msg', 'fb_msg_flag',
                'crt',
                'hhi', 'hhi_flag',
                'cash',
                'hh', 'hh_flag',
                'pol',
                'cov_concern', 
                'cov_concern_flag',
                'cov_info',
                'cov_efficacy', 
                'cov_efficacy_flag')

predv_cols <- c('strat_send_false0', 'strat_send_false1', 'strat_send_false2', 
                'strat_send_true0', 'strat_send_true1', 'strat_send_true2', 
                'strat_timeline_false0', 'strat_timeline_false1', 'strat_timeline_false2', 
                'strat_timeline_true0', 'strat_timeline_true1', 'strat_timeline_true2')

# names for treatment levels
W_terms <- c('Factcheck', 'More information', 'Real information', 'Related articles', 'Control', 'Accuracy nudge', 'Deliberation nudge', 'Emotion suppression', 'Pledge', 'AfricaCheck Tips', 'Facebook Tips', 'Video training') 
WC_terms <- c('Control', W_terms) # with control

# names for respondent-level treatments
WR_terms <- c('Accuracy nudge', 'Deliberation nudge', 'Emotion suppression', 'Pledge', 'AfricaCheck tips', 'Facebook tips', 'Video training')
WCR_terms <- c('Control', WR_terms) # with control

# names for headline-level treatments
WH_terms <- c('Factcheck', 'More information', 'Real information', 'Related articles')
WCH_terms <- c('Control', WH_terms) # with control

# evaluation treatment levels
treatment_levels <- c('Control', 
                      'Headline\nFactcheck', 
                      'Headline\nRelated articles', 
                      'Respondent\nAccuracy', 
                      'Respondent\nFacebook tips', 
                      'Respondent\nLearned targeted',
                      'Respondent\nAlternative targeted')

covariate_list <- c('age', 'male', 'pol', 'dli', 'science')
stimuli_types <- c('true', 'false')
channel_types <- c('send', 'timeline')
```


```{r datasets, cache = TRUE, cache.lazy=FALSE}
df_eval <- df_treat[which(df_treat$batch == 5),]
df_learn <- df_treat[which(df_treat$batch<5 & df_treat$attrited == 0),]

```

```{r attrition, cache = TRUE, cache.lazy=FALSE}
# Accounting for attrition
uncens_prob <- probability_forest(X = as.matrix(df_eval[, c(context_cols, predv_cols)]),
                                  Y = as.factor(1*(df_eval$attrited == 0)))$predictions[which(df_eval$attrited == 0),]

ws_eval <- as.factor(case_when(as.numeric(df_eval$W) == 1 ~ 1, # control
                               as.numeric(df_eval$W) == 2 ~  2, # headline factcheck,
                               as.numeric(df_eval$W) == 5 ~ 3, # headline related,
                               as.numeric(df_eval$W) == 6 ~ 4, # respondent accuracy
                               as.numeric(df_eval$W) == 11 ~ 5, # facebook tips,
                               # combine optimal with small groups
                               TRUE ~ 6 # other optimal respondent (8/12)
)) 
treat_uncens <- factor(case_when(df_eval$attrited == 0 ~ as.numeric(ws_eval),
                                 TRUE ~ 7))
treat_uncens_prob <- probability_forest(X = as.matrix(df_eval[, c(context_cols, predv_cols)]),
                                        Y = treat_uncens)$predictions[which(df_eval$attrited == 0),]

balwts_uncens <- (1/uncens_prob)[, 2]

balwts_treat_uncens <- (1/treat_uncens_prob)[cbind(1:nrow(treat_uncens_prob), treat_uncens[which(df_eval$attrited == 0)])]

df_eval <- df_eval[which(df_eval$attrited == 0),]
ws_eval <- ws_eval[which(df_eval$attrited == 0)]
```


```{r hyperparameters, cache = TRUE}
## Hyperparameters
num_batches <- 3
# times at which the model is updated (applied in following observation)
update_times <- sapply(1:4, function(x) length(which(df_learn$batch == x)))
update_times <- cumsum(update_times)
num_init_draws <- update_times[1]
A <- update_times[4] # no. observations in learning split/ last model update
N <- nrow(df_learn) + nrow(df_eval)
K <- length(unique((df_learn$W)))
```



```{r data_components, cache = TRUE}
xs_learn <- as.matrix(df_learn[, c(context_cols, predv_cols)])
yobs_learn <- df_learn$Y
ws_learn <- as.numeric(df_learn$W)

xs_eval <- as.matrix(df_eval[, c(context_cols, predv_cols)])
yobs_eval <- df_eval$Y
ws_eval <- as.factor(case_when(as.numeric(df_eval$W) == 1 ~ 1, # control
                               as.numeric(df_eval$W) == 2 ~  2, # headline factcheck,
                               as.numeric(df_eval$W) == 5 ~ 3, # headline related,
                               as.numeric(df_eval$W) == 6 ~ 4, # respondent accuracy
                               as.numeric(df_eval$W) == 11 ~ 5, # facebook tips,
                               # combine optimal with small groups
                               TRUE ~ 6 # other optimal respondent (8/12)
)) 

```


# Analysis
## Calculating scores

```{r treament_levels, cache=TRUE}
# For learning split only
df_learn['treatment_r'] <- relevel(as.factor(gsub('H_.*_|R_', '', df_learn$W)),
                                   ref = 'control')
df_learn['treatment_h'] <- relevel(as.factor(gsub('H_|_R_.*', '', df_learn$W)),
                                   ref = 'control')

W_levels <- levels(df_learn$W)
# Decompose treatment levels into separate factors
WH_levels <- unique(sub('_R_.*', '', W_levels))
WR_levels <- unique(sub('H_[a-z]*_*[a-z]*_*', '', W_levels))

# Identify treatment locations where each respective factor level is represented
WH_idx <- lapply(WH_levels, function(x) grep(x, W_levels))
WR_idx <- lapply(WR_levels, function(x) grep(x, W_levels))


ws_r <- as.numeric(df_learn$treatment_r) # respondent-level treatment only
ws_h <- as.numeric(df_learn$treatment_h) # headline-level treatment only
K_r <- length(unique(ws_r))
K_h <- length(unique(ws_h))
# Include headline as context
xs_h <- cbind(xs_learn, 
              model.matrix(lm(Y~ treatment_h-1, data = df_learn)))
# Predict when headline == control
xs_h_new <- xs_h
treat_cols <- grepl(pattern = 'treatment', colnames(xs_h))
xs_h_new[, treat_cols] <- matrix(c(1, rep(0, sum(treat_cols) -1 )), 
                                 nrow = nrow(df_learn), 
                                 ncol = sum(treat_cols), byrow = TRUE)

# Include respondent as context
xs_r <- cbind(xs_learn, 
              model.matrix(lm(Y~ treatment_r-1, data = df_learn)))
# Predict when headline == control
xs_r_new <- xs_r
treat_cols <- grepl(pattern = 'treatment', colnames(xs_r))
xs_r_new[, treat_cols] <- matrix(c(1, rep(0, sum(treat_cols) -1 )), 
                                 nrow = nrow(df_learn), 
                                 ncol = sum(treat_cols), byrow = TRUE)

```

### Learning scores
```{r probs_learning, cache = TRUE}
# For learning
probs_learn <- as.matrix(df_learn[, paste0('probs_', 0:39)])
balwts_learn <- (1/probs_learn)[cbind(1:A, ws_learn)]

# Re-calculate probs to aggregate across headline level
# Conditional on being assigned a given headline level, what is the probability of being assigned a given respondent condition?
probs_rwide <- probs_learn
for(x in WH_idx){
  probs_rwide[,x] <- probs_learn[,x]/rowSums(probs_learn[,x])
}
balwts_r <- (1/probs_rwide)[matrix(c(1:nrow(df_learn),ws_learn), ncol = 2)]


probs_r <- t(sapply(1:nrow(df_learn), function(x){
  hval <- ws_h[x]
  colidx <- WH_idx[[hval]]
  probs_rwide[x, colidx]
} ))

# Re-calculate probs to aggregate across respondent level
probs_hwide <- probs_learn
for(x in WR_idx){
  probs_hwide[,x] <- probs_learn[,x]/rowSums(probs_learn[,x])
}
balwts_h <- (1/probs_hwide)[matrix(c(1:nrow(df_learn),ws_learn), ncol = 2)]


probs_h <- t(sapply(1:nrow(df_learn), function(x){
  rval <- ws_r[x]
  colidx <- WR_idx[[rval]]
  probs_hwide[x, colidx]
} ))
```

```{r learn_scores, cache=TRUE}

ws_learn_r <- factor(df_learn$treatment_r, 
                     levels = c('control', 'accuracy', 'deliberation',
                                'emotion', 'pledge', 'africacheck',
                                'facebook', 'video'))
ws_learn_h <- factor(df_learn$treatment_h, 
                     levels = c('control', 'factcheck', 'more_info',
                                'real_info', 'related'))

if(file.exists('objects/aipw_scores_learn.RDS')){ # read in scores if already generated
  aipw_scores_learn <- readRDS('objects/aipw_scores_learn.RDS')
  aipw_scoresR_learn <- aipw_scores_learn[[1]]
  aipw_scoresRmarg_learn <- aipw_scores_learn[[2]]
  aipw_scoresH_learn <- aipw_scores_learn[[3]]
  aipw_scoresHmarg_learn <- aipw_scores_learn[[4]]
  
}else{
  aipw_scores_learn <- aw_scores_learn(xs_h = xs_h, xs_r = xs_r,
                                       ws_h = ws_learn_h, 
                                       ws_r = ws_learn_r, 
                                       ws = ws_learn,
                                       yobs = yobs_learn,
                                       K_h = K_h, K_r = K_r, K = K,
                                       balwts = balwts_learn,
                                       balwts_r = balwts_r, balwts_h = balwts_h,
                                       probs_r = probs_r, probs_h = probs_h,
                                       probsK = probs_learn,
                                       chunks = update_times)
  
  aipw_scoresR_learn <- aipw_scores_learn[[1]]
  aipw_scoresRmarg_learn <- aipw_scores_learn[[2]]
  aipw_scoresH_learn <- aipw_scores_learn[[3]]
  aipw_scoresHmarg_learn <- aipw_scores_learn[[4]]
  
  saveRDS(aipw_scores_learn, 'objects/aipw_scores_learn.RDS')
  
}
```

### Evalution Scores

```{r optimal_policy_learning, cache=TRUE, warning=FALSE, message=FALSE}
train_idx <- ws_r %in%c(2,6) # note that ordering does not match probs_r
probs_eval <- as.matrix(df_eval[, paste0('probs_', 0:39)])

cf.priority <- causal_forest(
  X = xs_learn[train_idx, ],
  Y = df_learn$post_false_prop[train_idx],
  W = 1*(ws_r[train_idx]==2),
  W.hat = probs_r[train_idx, 2]/(rowSums(probs_r[train_idx, c(2,7)])),
  seed = 60637)

optimal_assignment <- ifelse(predict(cf.priority, xs_eval)$predictions<0, 4, 5)

df_eval$optimal_assignment <- factor(optimal_assignment,
                                     labels = c('Optimal policy == accuracy',
                                                'Optimal policy == FB tips'))

optimal_assignment_original <- case_when(df_eval$optimal0 == 6 ~ 4,
                                         df_eval$optimal0 == 8 ~ 6, #8/12 collapsed
                                         df_eval$optimal0 == 11 ~ 5,
                                         df_eval$optimal0 == 12 ~ 6)

```


```{r combined_eval_scores, cache=TRUE, warning=FALSE, message=FALSE}
## Combined response function scores 
if(file.exists('objects/aipw_scores.RDS')){ # read in scores if already generated
  aipw_scores <- readRDS('objects/aipw_scores.RDS')
  
}else{
  aipw_scores <- aw_scores_eval(xs = xs_eval,
                                yobs = yobs_eval, 
                                ws = ws_eval, 
                                sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores, 'objects/aipw_scores.RDS')
  
}


# learned optimal policy
if(file.exists('objects/aipw_scores_learned.RDS')){ # read in scores if already generated
  aipw_scores_learned <- readRDS('objects/aipw_scores_learned.RDS')
  
}else{
  aipw_scores_learned <- aw_scores_eval(xs = xs_eval,
                                        yobs = yobs_eval, 
                                        ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                 ws_eval == optimal_assignment_original ~ 2,
                                                                 TRUE ~ 3)), 
                                        sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_learned, 'objects/aipw_scores_learned.RDS')
  
}

# alternative optimal policy
if(file.exists('objects/aipw_scores_alternative.RDS')){ # read in scores if already generated
  aipw_scores_alternative <- readRDS('objects/aipw_scores_alternative.RDS')
  
}else{
  aipw_scores_alternative <- aw_scores_eval(xs = xs_eval,
                                            yobs = yobs_eval, 
                                            ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                     ws_eval == optimal_assignment ~ 2,
                                                                     TRUE ~ 3)), 
                                            sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_alternative, 'objects/aipw_scores_alternative.RDS')
  
}
```

```{r any_eval_scores, cache = TRUE, warning=FALSE, message=FALSE}
## Any share scores
any_true <- df_eval$post_true_prop
any_false<- df_eval$post_false_prop

if(file.exists('objects/aipw_scores_any_true.RDS')){ # read in scores if already generated
  aipw_scores_any_true <- readRDS('objects/aipw_scores_any_true.RDS')
  
}else{
  aipw_scores_any_true <- aw_scores_eval(xs = xs_eval,
                                         yobs = any_true, 
                                         ws = ws_eval,
                                         sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_true, 'objects/aipw_scores_any_true.RDS')
}

# learned optimal policy
if(file.exists('objects/aipw_scores_any_true_learned.RDS')){ # read in scores if already generated
  aipw_scores_any_true_learned <- readRDS('objects/aipw_scores_any_true_learned.RDS')
  
}else{
  aipw_scores_any_true_learned <- aw_scores_eval(xs = xs_eval,
                                                 yobs = any_true, 
                                                 ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                          ws_eval == optimal_assignment_original ~ 2,
                                                                          TRUE ~ 3)), 
                                                 sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_true_learned, 'objects/aipw_scores_any_true_learned.RDS')
}


# alternative optimal policy
if(file.exists('objects/aipw_scores_any_true_alternative.RDS')){ # read in scores if already generated
  aipw_scores_any_true_alternative <- readRDS('objects/aipw_scores_any_true_alternative.RDS')
  
}else{
  aipw_scores_any_true_alternative <- aw_scores_eval(xs = xs_eval,
                                                     yobs = any_true, 
                                                     ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                              ws_eval == optimal_assignment ~ 2,
                                                                              TRUE ~ 3)), 
                                                     sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_true_alternative, 'objects/aipw_scores_any_true_alternative.RDS')
}


if(file.exists('objects/aipw_scores_any_false.RDS')){ # read in scores if already generated
  aipw_scores_any_false <- readRDS('objects/aipw_scores_any_false.RDS')
  
}else{
  aipw_scores_any_false <- aw_scores_eval(xs = xs_eval,
                                          yobs = any_false, 
                                          ws = ws_eval, 
                                          sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_false, 'objects/aipw_scores_any_false.RDS')
}


if(file.exists('objects/aipw_scores_any_false_learned.RDS')){ # read in scores if already generated
  aipw_scores_any_false_learned <- readRDS('objects/aipw_scores_any_false_learned.RDS')
  
}else{
  aipw_scores_any_false_learned <- aw_scores_eval(xs = xs_eval,
                                                  yobs = any_false, 
                                                  ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                           ws_eval == optimal_assignment_original ~ 2,
                                                                           TRUE ~ 3)), 
                                                  sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_false_learned, 'objects/aipw_scores_any_false_learned.RDS')
}

# alternative optimal policy
if(file.exists('objects/aipw_scores_any_false_alternative.RDS')){ # read in scores if already generated
  aipw_scores_any_false_alternative <- readRDS('objects/aipw_scores_any_false_alternative.RDS')
  
}else{
  aipw_scores_any_false_alternative <- aw_scores_eval(xs = xs_eval,
                                                      yobs = any_false, 
                                                      ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                               ws_eval == optimal_assignment ~ 2,
                                                                               TRUE ~ 3)), 
                                                      sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_false_alternative, 'objects/aipw_scores_any_false_alternative.RDS')
}
```

```{r channel_eval_scores, cache = TRUE, message=FALSE, warning=FALSE}
## Channel scores
timeline_true <- df_eval$post_true_timeline_prop
timeline_false <- df_eval$post_false_timeline_prop
send_true <- df_eval$post_true_send_prop
send_false <- df_eval$post_false_send_prop

if(file.exists('objects/aipw_scores_timeline_true.RDS')){ # read in scores if already generated
  aipw_scores_timeline_true <- readRDS('objects/aipw_scores_timeline_true.RDS')
  
}else{
  
  aipw_scores_timeline_true <- aw_scores_eval(xs = xs_eval,
                                              yobs = timeline_true, 
                                              ws = ws_eval, 
                                              sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_true, 'objects/aipw_scores_timeline_true.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_true_learned.RDS')){ # read in scores if already generated
  aipw_scores_timeline_true_learned <- readRDS('objects/aipw_scores_timeline_true_learned.RDS')
  
}else{
  
  aipw_scores_timeline_true_learned <- aw_scores_eval(xs = xs_eval,
                                                      yobs = timeline_true, 
                                                      ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                               ws_eval == optimal_assignment_original ~ 2,
                                                                               TRUE ~ 3)), 
                                                      sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_true_learned, 'objects/aipw_scores_timeline_true_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_true_alternative.RDS')){ # read in scores if already generated
  aipw_scores_timeline_true_alternative <- readRDS('objects/aipw_scores_timeline_true_alternative.RDS')
  
}else{
  
  aipw_scores_timeline_true_alternative <- aw_scores_eval(xs = xs_eval,
                                                          yobs = timeline_true, 
                                                          ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                                   ws_eval == optimal_assignment ~ 2,
                                                                                   TRUE ~ 3)), 
                                                          sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_true_alternative, 'objects/aipw_scores_timeline_true_alternative.RDS')
  
}



if(file.exists('objects/aipw_scores_timeline_false.RDS')){ # read in scores if already generated
  aipw_scores_timeline_false <- readRDS('objects/aipw_scores_timeline_false.RDS')
  
}else{
  
  aipw_scores_timeline_false <- aw_scores_eval(xs = xs_eval,
                                               yobs = timeline_false, 
                                               ws = ws_eval, 
                                               sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_false, 'objects/aipw_scores_timeline_false.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_false_learned.RDS')){ # read in scores if already generated
  aipw_scores_timeline_false_learned <- readRDS('objects/aipw_scores_timeline_false_learned.RDS')
  
}else{
  
  aipw_scores_timeline_false_learned <- aw_scores_eval(xs = xs_eval,
                                                       yobs = timeline_false, 
                                                       ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                                ws_eval == optimal_assignment_original ~ 2,
                                                                                TRUE ~ 3)), 
                                                       sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_false_learned, 'objects/aipw_scores_timeline_false_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_false_alternative.RDS')){ # read in scores if already generated
  aipw_scores_timeline_false_alternative <- readRDS('objects/aipw_scores_timeline_false_alternative.RDS')
  
}else{
  
  aipw_scores_timeline_false_alternative <- aw_scores_eval(xs = xs_eval,
                                                           yobs = timeline_false, 
                                                           ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                                    ws_eval == optimal_assignment ~ 2,
                                                                                    TRUE ~ 3)), 
                                                           sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_false_alternative, 'objects/aipw_scores_timeline_false_alternative.RDS')
  
}


if(file.exists('objects/aipw_scores_send_true.RDS')){ # read in scores if already generated
  aipw_scores_send_true <- readRDS('objects/aipw_scores_send_true.RDS')
  
}else{
  
  aipw_scores_send_true <- aw_scores_eval(xs = xs_eval,
                                          yobs = send_true, 
                                          ws = ws_eval, 
                                          sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_true, 'objects/aipw_scores_send_true.RDS')
}

if(file.exists('objects/aipw_scores_send_true_learned.RDS')){ # read in scores if already generated
  aipw_scores_send_true_learned <- readRDS('objects/aipw_scores_send_true_learned.RDS')
  
}else{
  
  aipw_scores_send_true_learned <- aw_scores_eval(xs = xs_eval,
                                                  yobs = send_true, 
                                                  ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                           ws_eval == optimal_assignment_original ~ 2,
                                                                           TRUE ~ 3)), 
                                                  sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_true_learned, 'objects/aipw_scores_send_true_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_send_true_alternative.RDS')){ # read in scores if already generated
  aipw_scores_send_true_alternative <- readRDS('objects/aipw_scores_send_true_alternative.RDS')
  
}else{
  
  aipw_scores_send_true_alternative <- aw_scores_eval(xs = xs_eval,
                                                      yobs = send_true, 
                                                      ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                               ws_eval == optimal_assignment ~ 2,
                                                                               TRUE ~ 3)), 
                                                      sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_true_alternative, 'objects/aipw_scores_send_true_alternative.RDS')
  
}

if(file.exists('objects/aipw_scores_send_false.RDS')){ # read in scores if already generated
  aipw_scores_send_false <- readRDS('objects/aipw_scores_send_false.RDS')
  
}else{
  aipw_scores_send_false <- aw_scores_eval(xs = xs_eval,
                                           yobs = send_false, 
                                           ws = ws_eval, 
                                           sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_false, 'objects/aipw_scores_send_false.RDS')
}


if(file.exists('objects/aipw_scores_send_false_learned.RDS')){ # read in scores if already generated
  aipw_scores_send_false_learned <- readRDS('objects/aipw_scores_send_false_learned.RDS')
  
}else{
  
  aipw_scores_send_false_learned <- aw_scores_eval(xs = xs_eval,
                                                   yobs = send_false, 
                                                   ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                            ws_eval == optimal_assignment_original ~ 2,
                                                                            TRUE ~ 3)), 
                                                   sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_false_learned, 'objects/aipw_scores_send_false_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_send_false_alternative.RDS')){ # read in scores if already generated
  aipw_scores_send_false_alternative <- readRDS('objects/aipw_scores_send_false_alternative.RDS')
  
}else{
  
  aipw_scores_send_false_alternative <- aw_scores_eval(xs = xs_eval,
                                                       yobs = send_false, 
                                                       ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                                ws_eval == optimal_assignment ~ 2,
                                                                                TRUE ~ 3)), 
                                                       sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_false_alternative, 'objects/aipw_scores_send_false_alternative.RDS')
  
}
```

### Evalution Estimation
```{r response_eval_estimation, cache=TRUE}
# Scores estimates
# mean response
aipw_est <- find_est(aipw_scores)
aipw_est_learned <- find_est(aipw_scores_learned)
aipw_est_alternative <- find_est(aipw_scores_alternative)
aipw_est <- bind_rows(aipw_est[1:5,],
                      aipw_est_learned[2,],
                      aipw_est_alternative[2,])
# treatment effects
aipw_te <- find_te(aipw_scores)
aipw_te_learned <- find_te(aipw_scores_learned)
aipw_te_alternative <- find_te(aipw_scores_alternative)
aipw_te <- bind_rows(aipw_te[1:4,],
                     aipw_te_learned[1,],
                     aipw_te_alternative[1,])

# Any
## true
aipw_t_est <- find_est(aipw_scores_any_true)
aipw_t_est_learned <- find_est(aipw_scores_any_true_learned)
aipw_t_est_alternative <- find_est(aipw_scores_any_true_alternative)
aipw_t_est <- bind_rows(aipw_t_est[1:5,],
                        aipw_t_est_learned[2,],
                        aipw_t_est_alternative[2,])

aipw_t_te <- find_te(aipw_scores_any_true)
aipw_t_te_learned <- find_te(aipw_scores_any_true_learned)
aipw_t_te_alternative <- find_te(aipw_scores_any_true_alternative)
aipw_t_te <- bind_rows(aipw_t_te[1:4,],
                       aipw_t_te_learned[1,],
                       aipw_t_te_alternative[1,])

## false
aipw_f_est <- find_est(aipw_scores_any_false)
aipw_f_est_learned <- find_est(aipw_scores_any_false_learned)
aipw_f_est_alternative <- find_est(aipw_scores_any_false_alternative)
aipw_f_est <- bind_rows(aipw_f_est[1:5,],
                        aipw_f_est_learned[2,],
                        aipw_f_est_alternative[2,])

aipw_f_te <- find_te(aipw_scores_any_false)
aipw_f_te_learned <- find_te(aipw_scores_any_false_learned)
aipw_f_te_alternative <- find_te(aipw_scores_any_false_alternative)
aipw_f_te <- bind_rows(aipw_f_te[1:4,],
                       aipw_f_te_learned[1,],
                       aipw_f_te_alternative[1,])

# Channel
## true
aipw_tt_est <- find_est(aipw_scores_timeline_true)
aipw_tt_est_learned <- find_est(aipw_scores_timeline_true_learned)
aipw_tt_est_alternative <- find_est(aipw_scores_timeline_true_alternative)
aipw_tt_est <- bind_rows(aipw_tt_est[1:5,],
                         aipw_tt_est_learned[2,],
                         aipw_tt_est_alternative[2,])

aipw_tt_te <- find_te(aipw_scores_timeline_true)
aipw_tt_te_learned <- find_te(aipw_scores_timeline_true_learned)
aipw_tt_te_alternative <- find_te(aipw_scores_timeline_true_alternative)
aipw_tt_te <- bind_rows(aipw_tt_te[1:4,],
                        aipw_tt_te_learned[1,],
                        aipw_tt_te_alternative[1,])


aipw_st_est <- find_est(aipw_scores_send_true)
aipw_st_est_learned <- find_est(aipw_scores_send_true_learned)
aipw_st_est_alternative <- find_est(aipw_scores_send_true_alternative)
aipw_st_est <- bind_rows(aipw_st_est[1:5,],
                         aipw_st_est_learned[2,],
                         aipw_st_est_alternative[2,])

aipw_st_te <- find_te(aipw_scores_send_true)
aipw_st_te_learned <- find_te(aipw_scores_send_true_learned)
aipw_st_te_alternative <- find_te(aipw_scores_send_true_alternative)
aipw_st_te <- bind_rows(aipw_st_te[1:4,],
                        aipw_st_te_learned[1,],
                        aipw_st_te_alternative[1,])

## false
aipw_tf_est <- find_est(aipw_scores_timeline_false)
aipw_tf_est_learned <- find_est(aipw_scores_timeline_false_learned)
aipw_tf_est_alternative <- find_est(aipw_scores_timeline_false_alternative)
aipw_tf_est <- bind_rows(aipw_tf_est[1:5,],
                         aipw_tf_est_learned[2,],
                         aipw_tf_est_alternative[2,])

aipw_tf_te <- find_te(aipw_scores_timeline_false)
aipw_tf_te_learned <- find_te(aipw_scores_timeline_false_learned)
aipw_tf_te_alternative <- find_te(aipw_scores_timeline_false_alternative)
aipw_tf_te <- bind_rows(aipw_tf_te[1:4,],
                        aipw_tf_te_learned[1,],
                        aipw_tf_te_alternative[1,])


aipw_sf_est <- find_est(aipw_scores_send_false)
aipw_sf_est_learned <- find_est(aipw_scores_send_false_learned)
aipw_sf_est_alternative <- find_est(aipw_scores_send_false_alternative)
aipw_sf_est <- bind_rows(aipw_sf_est[1:5,],
                         aipw_sf_est_learned[2,],
                         aipw_sf_est_alternative[2,])

aipw_sf_te <- find_te(aipw_scores_send_false)
aipw_sf_te_learned <- find_te(aipw_scores_send_false_learned)
aipw_sf_te_alternative <- find_te(aipw_scores_send_false_alternative)
aipw_sf_te <- bind_rows(aipw_sf_te[1:4,],
                        aipw_sf_te_learned[1,],
                        aipw_sf_te_alternative[1,])


aipw_est$term <- 
  aipw_t_est$term <-  
  aipw_f_est$term <-  
  aipw_tt_est$term <- aipw_tf_est$term <- 
  aipw_st_est$term <- aipw_sf_est$term <-
  treatment_levels

aipw_te$term <- 
  aipw_f_te$term <-  
  aipw_t_te$term <-  
  aipw_t_te$term <-  
  aipw_tt_te$term <- aipw_tf_te$term <- 
  aipw_st_te$term <- aipw_sf_te$term <-
  treatment_levels[-1]

```


## Other manipulations
```{r marg_scores, cache = TRUE}
# Save marginalized scores
colnames(aipw_scoresRmarg_learn) <- paste0(WR_levels, '_scores')
colnames(aipw_scoresHmarg_learn) <- paste0(WH_levels, '_scores')

df_learn <- cbind(df_learn, as.data.frame(aipw_scoresHmarg_learn), as.data.frame(aipw_scoresRmarg_learn))

aipw_scores_marg <- aipw_scores[,1] + cbind(0,  aipw_scores[,2:5])
colnames(aipw_scores_marg) <- paste0(c(WR_levels[1], WH_levels[2], WH_levels[5], WR_levels[2], WR_levels[7]), '_scores')

df_eval <- cbind(df_eval, as.data.frame(aipw_scores_marg))
```

```{r addvars}
df_learn <- df_learn %>% 
  mutate(median_age = 1*(age>median(df_treat$age)),
         median_dli = 1*(dli>= median(df_treat$dli)),
         age_dli = interaction(as.factor(median_age),  as.factor(median_dli)),
         median_science = 1*(science> median(df_treat$science)),
         median_crt = 1*(crt> median(df_treat$crt)),
         median_ed = 1*(ed> median(df_treat$ed)),
         median_locus = 1*(locus> median(df_treat$locus)),
         median_religiosity = 1*(religiosity> median(df_treat$religiosity)),
         science_crt = interaction(as.factor(median_science),  as.factor(median_crt)),
         median_fb_post = 1*(fb_post> median(df_treat$fb_post)),
         median_fb_msg = 1*(fb_msg> median(df_treat$fb_msg)),
         fb_active = fb_post+fb_msg,
         median_fb_active = 1 * ((fb_post + fb_msg) > median(df_treat$fb_post+df_treat$fb_msg))
  )

df_eval <- df_eval %>% 
  mutate(median_age = 1*(age>median(df_treat$age)),
         median_dli = 1*(dli>= median(df_treat$dli)),
         median_science = 1*(science> median(df_treat$science)),
         median_crt = 1*(crt> median(df_treat$crt)),
         median_religiosity = 1*(religiosity> median(df_treat$religiosity)),
         median_ed = 1*(ed> median(df_treat$ed)),
         median_fb_post = 1*(fb_post> median(df_treat$fb_post)),
         median_fb_msg = 1*(fb_msg> median(df_treat$fb_msg)),
         fb_active = fb_post+fb_msg,
         median_fb_active = 1 * ((fb_post + fb_msg) > median(df_treat$fb_post+df_treat$fb_msg))
  )
```


# Secondary Analysis

## Hypotheses
To test hypotheses regarding specific heterogeneous response, as described in PAP, Section 4.1.2, we average across the relevant scores, and compare estimates across the two groups. Given that testing these treatment-covariate combinations will result in a large number of unique tests, we will adjust for multiple hypothesis testing for response heterogeneity by reporting tests under both Bonferroni and Benjamini-Hochberg corrections.

#### General hypotheses

```{r pilot_figures, cache = TRUE}

#### Age DLI ####


mean_mat <- aggregate(aipw_scoresRmarg_learn, by = list(df_learn$age_dli),  mean)
se_mat <- aggregate(aipw_scoresRmarg_learn, by = list(df_learn$age_dli), function(x) sd(x)/sqrt(length(x)))
counts <- table(df_learn$age_dli)

ggmat <- reshape2::melt(mean_mat, variable.name = 'Best', value.name = 'Response')
ggmat2 <- reshape2::melt(se_mat, variable.name = 'Best', value.name = 'SE')
ggmat <- merge(ggmat, ggmat2) %>% 
  filter(Best %in% levels(Best)[c(1,2,7)]) %>% 
  mutate(Group = factor(Group.1, labels = c(paste0('Low Age, Low DLI \n(N = ', counts[1], ')'), 
                                            paste0('Low Age x High DLI \n(N = ', counts[2], ')'),
                                            paste0('High Age x Low DLI \n(N = ', counts[3], ')'),
                                            paste0('High Age x High DLI \n(N = ', counts[4], ')'))),
         Best = factor(Best, labels = c('Control', 'Accuracy', 'Facebook_Tips')),
         c.lower = Response-1.96*SE, 
         c.upper = Response+1.96*SE)

gg <- ggplot(data = ggmat, aes(x = Best, y = Response, fill = Best)) + 
  geom_bar(stat = "identity", width = 1) +
  facet_grid(~Group, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside",
        legend.position = "none") + 
  scale_x_discrete(guide = guide_axis(n.dodge=3)) + 
  xlab("Category")+
  # ylim(-1, 1) +
  geom_errorbar(aes(x=Best, ymin=c.lower, ymax=c.upper), 
                width = 0.1,
                position=position_dodge(0.9))


# Substituting in emotion suppression for Facebook tips
ggmat <- reshape2::melt(mean_mat, variable.name = 'Best', value.name = 'Response')
ggmat2 <- reshape2::melt(se_mat, variable.name = 'Best', value.name = 'SE')
ggmat <- merge(ggmat, ggmat2) %>% 
  filter(Best %in% levels(Best)[c(1,2,4)]) %>% 
  mutate(Group = factor(Group.1, labels = c(paste0('Low Age, Low DLI \n(N = ', counts[1], ')'), 
                                            paste0('Low Age x High DLI \n(N = ', counts[2], ')'),
                                            paste0('High Age x Low DLI \n(N = ', counts[3], ')'),
                                            paste0('High Age x High DLI \n(N = ', counts[4], ')'))),
         Best = factor(Best, labels = c('Control', 'Accuracy', 'Emotion')),
         c.lower = Response-1.96*SE, 
         c.upper = Response+1.96*SE)

gg <- ggplot(data = ggmat, aes(x = Best, y = Response, fill = Best)) + 
  geom_bar(stat = "identity", width = 1) +
  facet_grid(~Group, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside",
        legend.position = "none") + 
  scale_x_discrete(guide = guide_axis(n.dodge=3)) + 
  xlab("Category")+
  # ylim(-1, 1) +
  geom_errorbar(aes(x=Best, ymin=c.lower, ymax=c.upper), 
                width = 0.1,
                position=position_dodge(0.9))

gg

ggsave(
  filename = '../figures/age_dli_emotion.png',
  plot = gg,
  width = 8,
  height = 4
)

# Science CRT

mean_mat <- aggregate(aipw_scoresRmarg_learn, by = list(df_learn$science_crt),  mean)
se_mat <- aggregate(aipw_scoresRmarg_learn, by = list(df_learn$science_crt), function(x) sd(x)/sqrt(length(x)))
counts <- table(df_learn$science_crt)

ggmat <- reshape2::melt(mean_mat, variable.name = 'Best', value.name = 'Response')
ggmat2 <- reshape2::melt(se_mat, variable.name = 'Best', value.name = 'SE')
ggmat <- merge(ggmat, ggmat2) %>% 
  filter(Best %in% levels(Best)[c(1, 2, 6, 8)]) %>% 
  mutate(Group = factor(Group.1, labels = c(paste0('Low Science x Low CRT \n(N = ', counts[1], ')'), 
                                            paste0('Low Science x High CRT \n(N = ', counts[2], ')'),
                                            paste0('High Science x Low CRT \n(N = ', counts[3], ')'),
                                            paste0('High Science x High CRT \n(N = ', counts[4], ')'))),
         Best = factor(Best, labels = c('Control', 'Accuracy', 'AfricaCheck_Tips', 'Video')),
         c.lower = Response-1.96*SE, 
         c.upper = Response+1.96*SE)

gg <- ggplot(data = ggmat, aes(x = Best, y = Response, fill = Best)) + 
  geom_bar(stat = "identity", width = 1) +
  facet_grid(~Group, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside",
        legend.position = "none") +
  scale_x_discrete(guide = guide_axis(n.dodge=4)) + 
  xlab("Category") +
  # ylim(-1, 1) +
  geom_errorbar(aes(x=Best, ymin=c.lower, ymax=c.upper), 
                width = 0.1,
                position=position_dodge(0.9))

gg

ggsave(
  filename = '../figures/science_crt.png',
  plot = gg,
  width = 8,
  height = 4
)

```


#### Industry focused

We select the below treatments because these are currently, or were previously, used by social media companies including Facebook and Twitter. The below covariates were selected as those that social media companies directly collect or have access to, and therefore could more easily use for targeting interventions. For our covariates of interest we will divide these into two groups for any binary variables (i.e. indicator for male) and split on the median value for continuous variables to test two subgroups' difference in scores/outcomes (i.e. age $\geq$ median and age $<$ median).

*Treatments:*

* Facebook tips (respondent)
* AfricaCheck tips (respondent)
* Factcheck (headline)
* More information (headline)
* Related articles (headline)

*Covariates:*

* Age
* Male
* Education

```{r heterogeneity_industry, cache = TRUE}
full_xmat <- c()


treatments_industry <- c("R_tips_facebook", "R_tips_africacheck", "H_factcheck", "H_more_info", "H_related")
covariates_industry <- c("median_age", "median_ed", "male")

lm_fit <- list()
for (t in treatments_industry){
  for (c in covariates_industry){
    form <- as.formula(paste0(t, "_scores ~ ", c))
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_fit[[lm_name]] <- lm(form, data = df_learn)
  }
}

lm_est <- list()
lm_se <- list()
for (t in treatments_industry){
  for (c in covariates_industry){
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_est[[lm_name]] <- coef(lm_fit[[lm_name]])[[2]]
    lm_se[[lm_name]] <- coef(summary(lm_fit[[lm_name]]))[2,2]
  }
}


xmat <- round(unlist(lm_est), 3)
xmat_se <- round(unlist(lm_se), 3)
xmat_tstat <-round(xmat / xmat_se,3)
xmat_pval <-2 * (1 - pnorm(abs(xmat_tstat)))
xmat_pval_bonferroni <- round(p.adjust(xmat_pval, "bonferroni"),3)
xmat_pval_hochberg <- round(p.adjust(xmat_pval, "hochberg"),3)
xmat_se <- sapply(xmat_se, function(x) paste0('(', round(x,3), ')'))
xmat_pval <- round(xmat_pval, 3)

xmat <- cbind(xmat, xmat_se, xmat_tstat, xmat_pval, xmat_pval_bonferroni, xmat_pval_hochberg)
colnames(xmat) <- c("estimate", "se", "tstat", "p-value", "bonferroni p-value", "hochberg p-value")
full_xmat <- rbind(full_xmat, xmat)

as.data.frame(xmat, col.names = c("estimate", "se", "tstat", "bonferroni p-value", "hochberg p-value"))

xmat <- xtable(xmat)
align(xmat) <- rep('c', ncol(xmat)+1)

print(
  xmat,
  include.rownames = TRUE,
  floating = FALSE,
  file = '../tables/hte_industry.tex') 
```

#### Social science theory

Previous studies have hypothesized and tested the role that deliberation plays in mitigating belief and sharing of online misinforma- tion (Bago et al., 2020; Pennycook et al., 2020). Drawing on these findings, we anticipate that our **accuracy nudge** and **deliberation nudge** respondent-level treatments may help shift respondents from system I, intuitive reactions, to system II, more deliberative thinking by nudging respondents to stop and think about the accuracy of the headline, in the former, and about why they share posts, in the latter. We anticipate that these treatments will perform comparatively better among respondents who score low on our **CRT measure** by getting these intuitive thinkers to stop and reflect. Alternatively, these treatments could perform best among high CRT respondents if they are better able to engage with these treatments in the desired way.

```{r heterogeneity_theory, cache = TRUE}
treatments_theory <- c("R_accuracy", "R_deliberation")
covariates_theory <- c("median_crt")

lm_fit <- list()
for (t in treatments_theory){
  for (c in covariates_theory){
    form <- as.formula(paste0(t, "_scores ~ ", c))
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_fit[[lm_name]] <- lm(form, data = df_learn)
  }
}


lm_est <- list()
lm_se <- list()
for (t in treatments_theory){
  for (c in covariates_theory){
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_est[[lm_name]] <- coef(lm_fit[[lm_name]])[[2]]
    lm_se[[lm_name]] <- coef(summary(lm_fit[[lm_name]]))[2,2]
  }
}

xmat <- round(unlist(lm_est), 3)
xmat_se <- round(unlist(lm_se), 3)
xmat_tstat <-round(xmat / xmat_se,3)
xmat_pval <-2 * (1 - pnorm(abs(xmat_tstat)))
xmat_pval_bonferroni <- round(p.adjust(xmat_pval, "bonferroni"),3)
xmat_pval_hochberg <- round(p.adjust(xmat_pval, "hochberg"),3)
xmat_se <- sapply(xmat_se, function(x) paste0('(', round(x,3), ')'))
xmat_pval <- round(xmat_pval, 3)

xmat <- cbind(xmat, xmat_se, xmat_tstat, xmat_pval, xmat_pval_bonferroni, xmat_pval_hochberg)
colnames(xmat) <- c("estimate", "se", "tstat", "p-value", "bonferroni p-value", "hochberg p-value")
full_xmat <- rbind(full_xmat, xmat)

as.data.frame(xmat, col.names = c("estimate", "se", "tstat", "bonferroni p-value", "hochberg p-value"))

xmat <- xtable(xmat)
align(xmat) <- rep('c', ncol(xmat)+1)

print(
  xmat,
  include.rownames = TRUE,
  floating = FALSE,
  file = '../tables/hte_theory.tex') 
```

### Best Uniform Treatment

In addition to the above hypotheses related to treatment heterogeneity, we  test heterogeneity with respect to the best performing respondent-level and headline-level treatments. To estimate these we again take the median as the splitting point of continuous covariates to create “high” and “low” categories:
Specifically, we will test:

1. How **locus of control** and **age** interact with the best uniform respondent-level treatment.

2. How **CRT** and **education** interact with the best uniform headline-level treatment.

#### Best respondent

```{r heterogeneity_best_R, cache = TRUE}

df_eval <- df_eval %>% 
  mutate(median_age = 1*(age>median(df_treat$age)),
         median_dli = 1*(dli>= median(df_treat$dli)),
         median_dli = 1*(dli>= median(df_treat$dli)),
         median_crt = 1*(crt> median(df_treat$crt)),
         median_locus = 1*(locus> median(df_treat$locus)),
  )

df_eval <- df_eval %>% 
  mutate(median_locus = 1*(locus > median(locus)))

treatments_best_respondent <- c('R_accuracy', 'R_tips_facebook')
covariates_best_respondent <- c("median_locus", "median_age")

lm_fit <- list()
for (t in treatments_best_respondent){
  for (c in covariates_best_respondent){
    form <- as.formula(paste0(t, "_scores ~ ", c))
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_fit[[lm_name]] <- lm(form, data = df_eval)
  }
}


lm_est <- list()
lm_se <- list()
for (t in treatments_best_respondent){
  for (c in covariates_best_respondent){
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_est[[lm_name]] <- coef(lm_fit[[lm_name]])[[2]]
    lm_se[[lm_name]] <- coef(summary(lm_fit[[lm_name]]))[2,2]
  }
}

xmat <- round(unlist(lm_est), 3)
xmat_se <- round(unlist(lm_se), 3)
xmat_tstat <-round(xmat / xmat_se,3)
xmat_pval <-2 * (1 - pnorm(abs(xmat_tstat)))
xmat_pval_bonferroni <- round(p.adjust(xmat_pval, "bonferroni"),3)
xmat_pval_hochberg <- round(p.adjust(xmat_pval, "hochberg"),3)
xmat_se <- sapply(xmat_se, function(x) paste0('(', round(x,3), ')'))
xmat_pval <- round(xmat_pval, 3)

xmat <- cbind(xmat, xmat_se, xmat_tstat, xmat_pval, xmat_pval_bonferroni, xmat_pval_hochberg)
colnames(xmat) <- c("estimate", "se", "tstat", "p-value", "bonferroni p-value", "hochberg p-value")
full_xmat <- rbind(full_xmat, xmat)

as.data.frame(xmat, col.names = c("estimate", "se", "tstat", "bonferroni p-value", "hochberg p-value"))

xmat <- xtable(xmat)
align(xmat) <- rep('c', ncol(xmat)+1)

print(
  xmat,
  include.rownames = TRUE,
  floating = FALSE,
  file = '../tables/hte_best_respondent.tex') 

```

#### Best headline

```{r heterogeneity_best_H, cache = TRUE}

treatments_best_headline <- c('H_factcheck', 'H_related')
covariates_best_headline <- c("median_crt", "median_ed")

lm_fit <- list()
for (t in treatments_best_headline){
  for (c in covariates_best_headline){
    form <- as.formula(paste0(t, "_scores ~ ", c))
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_fit[[lm_name]] <- lm(form, data = df_eval)
  }
}

lm_est <- list()
lm_se <- list()
for (t in treatments_best_headline){
  for (c in covariates_best_headline){
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_est[[lm_name]] <- coef(lm_fit[[lm_name]])[[2]]
    lm_se[[lm_name]] <- coef(summary(lm_fit[[lm_name]]))[2,2]
  }
}

xmat <- round(unlist(lm_est), 3)
xmat_se <- round(unlist(lm_se), 3)
xmat_tstat <-round(xmat / xmat_se,3)
xmat_pval <-2 * (1 - pnorm(abs(xmat_tstat)))
xmat_pval_bonferroni <- round(p.adjust(xmat_pval, "bonferroni"),3)
xmat_pval_hochberg <- round(p.adjust(xmat_pval, "hochberg"),3)
xmat_se <- sapply(xmat_se, function(x) paste0('(', round(x,3), ')'))
xmat_pval <- round(xmat_pval, 3)

xmat <- cbind(xmat, xmat_se, xmat_tstat, xmat_pval, xmat_pval_bonferroni, xmat_pval_hochberg)
colnames(xmat) <- c("estimate", "se", "tstat", "p-value","bonferroni p-value", "hochberg p-value")
full_xmat <- rbind(full_xmat, xmat)

as.data.frame(xmat, col.names = c("estimate", "se", "tstat", "bonferroni p-value", "hochberg p-value"))

xmat <- xtable(xmat)
align(xmat) <- rep('c', ncol(xmat)+1)

print(
  xmat,
  include.rownames = TRUE,
  floating = FALSE,
  file = '../tables/hte_best_headline.tex') 

```

### Pledge analysis

We expect the **pledge respondent-level treatment** to be more effective among people who *more frequently post and interact with friends on Facebook*, those who are *more religious* (i.e. those who attend religious services more frequently), and those with *high CRT scores*. Among respondents who are randomly assigned the *public* pledge treatment, we anticipate this treatment to be more effective among respondents who engage on Facebook regularly (as measured by the number of times they posted in the past 7 days and their frequency of communication with friends on the platform during the same period). In other words, we expect that people who are more engaged on social media, and therefore likely have more meaningful connections on the platform, will face higher audience costs to pledging to fight misinformation and then sharing dubious posts and will therefore reduce their sharing of misinformation. We also hypothesize that more religious respondents and those with high CRT scores, compared to their counterparts, may have stronger motivations to remain consistent with their own behavior. Meaning if they have pledged to helps spot misinformation, they will be less inclined to share it – at least compared to those who may care less about commitment and consistency with their own previous actions. We evaluate heterogeneity with respect to intention to treat, i.e., individuals who were assigned to the pledge treatment, irrespective of whether they actually took the pledge. However, we will also report rates at which respondents clicked the button to share the pledge across groups under comparison.

```{r pledge, cache = TRUE}
treatments_pledge <- "R_pledge"
covariates_pledge <- c("median_crt", "median_fb_post", "median_fb_msg", "median_religiosity")

lm_fit <- list()
for (t in treatments_pledge){
  for (c in covariates_pledge){
    form <- as.formula(paste0(t, "_scores ~ ", c))
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_fit[[lm_name]] <- lm(form, data = df_learn)
  }
}

output <- list()
for (t in treatments_pledge){
  for (c in covariates_pledge){
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    output[[lm_name]] <- predict(lm_fit[[lm_name]], df_learn)
  }
}

lm_est <- list()
lm_se <- list()
for (t in treatments_pledge){
  for (c in covariates_pledge){
    lm_name <- paste0(t,"_", gsub("_median", "", c))
    lm_est[[lm_name]] <- coef(lm_fit[[lm_name]])[[2]]
    lm_se[[lm_name]] <- coef(summary(lm_fit[[lm_name]]))[2,2]
  }
}

df_pledge <- df_learn[df_learn$treatment_r == "pledge",]

post_rate <- t(cbind(df_pledge %>% 
                       group_by(median_fb_post) %>% 
                       summarise(seen = sum(pledge_seen, na.rm = T),
                                 post= sum(pledge_post, na.rm = T),
                                 post_rate = post/seen) %>%
                       select(post_rate), 
                     df_pledge %>% 
                       group_by(median_fb_msg) %>% 
                       summarise(seen = sum(pledge_seen, na.rm = T),
                                 post= sum(pledge_post, na.rm = T),
                                 post_rate = post/seen) %>%
                       select(post_rate),
                     df_pledge %>% 
                       group_by(median_crt) %>% 
                       summarise(seen = sum(pledge_seen, na.rm = T),
                                 post= sum(pledge_post, na.rm = T),
                                 post_rate = post/seen) %>%
                       select(post_rate),
                     df_pledge %>% 
                       group_by(median_religiosity) %>% 
                       summarise(seen = sum(pledge_seen, na.rm = T),
                                 post= sum(pledge_post, na.rm = T),
                                 post_rate = post/seen) %>%
                       select(post_rate)))

post_rate_diff <- round(post_rate[,2] - post_rate[,1], 3)

xmat <- round(unlist(lm_est), 3)
xmat_se <- round(unlist(lm_se), 3)
xmat_tstat <-round(xmat / xmat_se,3)
xmat_pval <-2 * (1 - pnorm(abs(xmat_tstat)))
xmat_pval_bonferroni <- round(p.adjust(xmat_pval, "bonferroni"),3)
xmat_pval_hochberg <- round(p.adjust(xmat_pval, "hochberg"),3)
xmat_se <- sapply(xmat_se, function(x) paste0('(', round(x,3), ')'))
xmat_pval <- round(xmat_pval, 3)

xmat <-cbind(xmat, xmat_se, xmat_tstat, xmat_pval, xmat_pval_bonferroni, xmat_pval_hochberg, post_rate_diff)
colnames(xmat) <- c("estimate", "se", "tstat", "p-value","bonferroni p-value", "hochberg p-value", "post rate difference")
full_xmat <- cbind(full_xmat, rep("", nrow(full_xmat)))
full_xmat <- rbind(full_xmat, xmat)

as.data.frame(xmat, col.names = c("estimate", "se", "tstat", "bonferroni p-value", "hochberg p-value", "post rate difference"))

xmat <- xtable(xmat)
align(xmat) <- rep('c', ncol(xmat)+1)

print(
  xmat,
  include.rownames = TRUE,
  floating = FALSE,
  file = '../tables/hte_pledge.tex') 
```


## Secondary outcome{.tabset}

**True stimuli tab**

We report the click-through-rates for the share button for *true* articles as the percent of true stimuli that the respondent said they wanted to share during the survey. (We do not differentiate between stimuli presented pre- and post- treatment here, since the behavioral response measurement for all stimuli is all post-treatment.) To provide some insight into the extent to which respondents followed up on an intention to share, we report the *aggregate* number of times the associated post for each stimuli was shared.

**False stimuli tab**

For the false stimuli that were shown to the respondents, instead of allowing respondents to share these headlines, we provide links to tips for spotting misinformation online; we measure click-through-rates on these links.



### True stimuli

```{r outcome2_true, cache = TRUE}
TK <- sapply(1:6, function (x) paste0("TK", x))
TN <- sapply(1:6, function (x) paste0("TN", x))
TB <- sapply(1:5, function (x) paste0("TB", x))

FK <- sapply(1:13, function (x) paste0("FK", x))
FN <- sapply(1:16, function (x) paste0("FN", x))

stimuli_T <- c(TK, TN, TB)
stimuli_F <- c(FK, FN)

stimuli_T_data <- df_secondary %>% select(intersect(sapply(stimuli_T, function(x) paste0("share_", x)), colnames(df_secondary)))
stimuli_T_data <- suppressWarnings(apply(stimuli_T_data, 2, as.numeric))
aggregate_T <- colSums(stimuli_T_data, na.rm = T)

aggregate_T_full <- table(toupper(unlist(df_secondary[,grepl("dv_stimulus_", colnames(df_secondary))], use.names = FALSE)))[stimuli_T]
T_names <- intersect(toupper(names(aggregate_T_full)), str_sub(names(aggregate_T), -3, -1))
T_summary <- data.frame(matrix(nrow = 3, ncol = length(T_names)))
colnames(T_summary) <- T_names
rownames(T_summary) <- c("aggregated total", "aggregated share", "rate")
for (t in T_names){
  T_summary[1, t] <- aggregate_T_full[t]
  T_summary[2, t] <- aggregate_T[paste0("share_", t)]
}
T_summary[3, ] <- round(T_summary[2,] / T_summary[1,], 3)


T_summary
```

### False stimuli

```{r outcome2_false, warning=FALSE, cache = TRUE}
# clicks on factcheck links shown in debrief with false stimuli
stimuli_F_data_link <- df_secondary %>% select(intersect(sapply(stimuli_F, function(x) paste0("link_", x)), colnames(df_secondary)))
stimuli_F_data_link <- suppressWarnings(apply(stimuli_F_data_link, 2, as.numeric))
aggregate_F_link <- colSums(stimuli_F_data_link, na.rm = TRUE)

aggregate_F_full <- table(toupper(unlist(df_secondary[,grepl("dv_stimulus_", colnames(df_secondary))], use.names = FALSE)))[stimuli_F]
F_names_link <- intersect(names(aggregate_F_full), gsub("link_", "",names(aggregate_F_link)))
F_summary_link <- data.frame(matrix(nrow = 3, ncol = length(F_names_link)))
colnames(F_summary_link) <- F_names_link
rownames(F_summary_link) <- c("aggregated total", "aggregated link", "link rate")
for (f in F_names_link){
  F_summary_link[1, f] <- aggregate_F_full[f]
  F_summary_link[2, f] <- aggregate_F_link[paste0("link_", f)]
}
F_summary_link[3, ] <- round(F_summary_link[2,] / F_summary_link[1,], 3)
F_summary_link
```



## Baseline Level

We expect that baseline rates of sharing false posts (compared to true posts) will be higher among these subgroups (pre-treatment):

* young
* male
* less educated 
* low CRT
* more religious

In the analyses below, *1* represents above median in each category and *0* represents below median in each category. Baseline rates are calculated by the percentage of false stimuli sharing over the percentage of true stimuli sharing, which means that the lower baseline rates the better.

```{r baseline, message = FALSE, cache = TRUE}
df_treat <- df_treat %>%
  group_by(nigeria) %>% 
  mutate(median_age = 1* (age > median(age)),
         median_ed = 1* (ed > median(ed) ),
         median_crt = 1* (ed > median(crt) ),
         median_religiosity = 1* (ed > median(religiosity) ))

# young
df_treat %>% 
  filter(W == "H_control_R_control") %>%
  group_by(median_age) %>%
  summarise(true = mean(pre_true/4),
            false = mean(pre_false/4),
            baseline_rate = false/true)
# male
df_treat %>% 
  filter(W == "H_control_R_control") %>%
  group_by(male) %>%
  summarise(true = mean(pre_true/4),
            false = mean(pre_false/4),
            baseline_rate = false/true)

# less_educated
df_treat %>% 
  filter(W == "H_control_R_control") %>%
  group_by(median_ed) %>%
  summarise(true = mean(pre_true/4),
            false = mean(pre_false/4),
            baseline_rate = false/true)

# low_crt
df_treat %>% 
  filter(W == "H_control_R_control") %>%
  group_by(median_crt) %>%
  summarise(true = mean(pre_true/4),
            false = mean(pre_false/4),
            baseline_rate = false/true)

# more_religious
df_treat %>% 
  filter(W == "H_control_R_control") %>%
  group_by(median_religiosity) %>%
  summarise(true = mean(pre_true/4),
            false = mean(pre_false/4),
            baseline_rate = false/true)
```


## Conversion to LaTeX

```{r latex, cache = TRUE}
full_xmat <- cbind(rownames(full_xmat), full_xmat)
rownames(full_xmat) <- c(rep("Industry Focused", 15), 
                         rep("Social Science Theory", 2),
                         rep("Best Respondent", 4),
                         rep("Best Headline", 4),
                         rep("Pledge Analysis", 4))

to_remove <- c("_male", "_age", "_ed", "_crt", "_locus", "_fb_post", "_fb_msg", "_religiosity")
treatname <- sapply(full_xmat[,1], function(x) 
  gsub(paste(to_remove, collapse = '|'), '', x))

treatment_type <- sapply(treatname, function(x) substring(x, 1, 1))
treatment_name <- sapply(treatname, function(x) substring(x, 3))
treatment_name <- sapply(treatment_name, function(x) str_to_title(gsub("_", " ", x)))
treatment_col <- sapply(1:nrow(full_xmat), function(i)
  paste0(treatment_name[i], " (", treatment_type[i], ")"))

variable_name <- sapply(full_xmat[,1], function(x) 
  gsub(paste(paste0(c(WR_levels, WH_levels), "_"), collapse = '|'), '', x))

full_xmat <- cbind(treatment_col, variable_name, full_xmat[,2:ncol(full_xmat)])
cleanf <- function(x){ 
  oldx <- c(FALSE, x[-1]==x[-length(x)])  # is the value equal to the previous?
  res <- x
  res[oldx] <- NA        
  return(res)
}
full_xmat <- cbind(row.names(full_xmat), full_xmat)
full_xmat[, 1:2] <- do.call(cbind, lapply(1:2, function(x){ 
  oldx <- c(FALSE, full_xmat[,x][-1]==full_xmat[,x][-length(full_xmat[,x])])  
  res <- full_xmat[,x]
  res[oldx] <- NA        
  return(res)
}))



full_xmat_se_transformed <- do.call(rbind, lapply(1:nrow(full_xmat), function(i) rbind(full_xmat[i, -5], c(NA, NA, "", full_xmat[i, 5], "", "", "", "", ""))))
colnames(full_xmat_se_transformed) <- c("Type of analysis", "Treatment", "Variable", "mean (se)", "tstat", "p-value", "Bonferroni p-value", "Hochberg p-value", "Post rate difference")

xmat <- xtable(full_xmat_se_transformed)
align(xmat) <- rep('c', ncol(full_xmat_se_transformed)+1)

print(
  xmat,
  include.rownames = FALSE,
  floating = FALSE,
  file = '../tables/full_secondary_table.tex') 
```


```{r load_cached, eval = FALSE}
qwraps2::lazyload_cache_dir(path = "misinformation_replication_secondar_cache/html")
source('utils.R')
```

