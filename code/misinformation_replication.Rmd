---
title: 'Facebook Misinformation Study, pre-analysis replication script'
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_folding: show
    number_sections: true
---



# Data reading
```{r paths, message = FALSE}
set.seed(60637)
source('utils.R') 

dir.create(file.path('..', 'tables'), showWarnings = FALSE)
dir.create(file.path('..', 'figures'), showWarnings = FALSE)
dir.create(file.path('objects'), showWarnings = FALSE)
```




## Load Data
Load most recent download of data; the file name indicates the download date. 
```{r data, cache = TRUE}
files <- list.files('../data', 
                    pattern = '^cleaned-data.*rds$', 
                    full.names = TRUE)

(INPUT_FILENAME <- files[which.max(file.info(files)$mtime)])
df_treat <- readRDS(INPUT_FILENAME)

context_cols <- c('male', 
                  'age', 
                  'age_flag',
                  'age_check_flag',
                  'ed', 'ed_flag', 
                  'urban',
                  'rel_christian', 'rel_muslim',
                  'denom_pentecostal', 
                  'religiosity', 'religiosity_flag',
                  'locus', 'locus_flag',
                  'science', 'science_flag',
                  'dli',
                  'fb_post', 'fb_post_flag',
                  'fb_msg', 'fb_msg_flag',
                  'crt',
                  'hhi', 'hhi_flag',
                  'cash',
                  'hh', 'hh_flag',
                  'pol',
                  'cov_concern', 'cov_concern_flag',
                  'cov_efficacy', 'cov_efficacy_flag',
                  'nigeria')

demos_cols <- c('male', 
                'age', 'age_flag',
                'ed', 'ed_flag', 
                'urban', 
                'rel_none', 'rel_christian', 'rel_muslim', 'rel_traditionalist', 'rel_other', 'denom_pentecostal', 'religiosity',
                'religiosity_flag',
                'god',
                'locus', 'locus_flag',
                'science', 'science_flag',
                'dli',
                'fb_post', 'fb_post_flag',
                'fb_msg', 'fb_msg_flag',
                'crt',
                'hhi', 'hhi_flag',
                'cash',
                'hh', 'hh_flag',
                'pol',
                'cov_concern', 
                'cov_concern_flag',
                'cov_info',
                'cov_efficacy', 
                'cov_efficacy_flag')

predv_cols <- c('strat_send_false0', 'strat_send_false1', 'strat_send_false2', 
                'strat_send_true0', 'strat_send_true1', 'strat_send_true2', 
                'strat_timeline_false0', 'strat_timeline_false1', 'strat_timeline_false2', 
                'strat_timeline_true0', 'strat_timeline_true1', 'strat_timeline_true2')

# names for treatment levels
W_terms <- c('Fact check', 'More information', 'Real information', 'Related articles', 'Control', 'Accuracy nudge', 'Deliberation nudge', 'Emotion suppression', 'Pledge', 'AfricaCheck Tips', 'Facebook Tips', 'Video training') 
WC_terms <- c('Control', W_terms) # with control

# names for respondent-level treatments
WR_terms <- c('Accuracy nudge', 'Deliberation nudge', 'Emotion suppression', 'Pledge', 'AfricaCheck tips', 'Facebook tips', 'Video training')
WCR_terms <- c('Control', WR_terms) # with control

# names for headline-level treatments
WH_terms <- c('Fact check', 'More information', 'Real information', 'Related articles')
WCH_terms <- c('Control', WH_terms) # with control

# evaluation treatment levels
treatment_levels <- c('Control', 
                      'Headline\nFact check', 
                      'Headline\nRelated articles', 
                      'Respondent\nAccuracy', 
                      'Respondent\nFacebook tips', 
                      'Respondent\nLearned targeted',
                      'Respondent\nRestricted targeted')

covariate_list <- c('age', 'male', 'pol', 'dli', 'science')
stimuli_types <- c('true', 'false')
channel_types <- c('send', 'timeline')
```


```{r datasets, cache = TRUE, cache.lazy=FALSE}
df_eval <- df_treat[which(df_treat$batch == 5),]
df_learn <- df_treat[which(df_treat$batch<5 & df_treat$attrited == 0),]

# saved contextual probabilities 
contextual_probs <- readRDS('objects/contextual_probabilities.RDS')
contextual_probs <- contextual_probs[which(df_treat$batch<5 & df_treat$attrited == 0), 
                                     which(df_treat$batch<5 & df_treat$attrited == 0), ]
```

```{r attrition, cache = TRUE, cache.lazy=FALSE}
# Accounting for attrition
uncens_prob <- probability_forest(X = as.matrix(df_eval[, c(context_cols, predv_cols)]),
                                  Y = as.factor(1*(df_eval$attrited == 0)))$predictions[which(df_eval$attrited == 0),]

ws_eval <- as.factor(case_when(as.numeric(df_eval$W) == 1 ~ 1, # control
                               as.numeric(df_eval$W) == 2 ~  2, # headline fact check,
                               as.numeric(df_eval$W) == 5 ~ 3, # headline related,
                               as.numeric(df_eval$W) == 6 ~ 4, # respondent accuracy
                               as.numeric(df_eval$W) == 11 ~ 5, # facebook tips,
                               # combine optimal with small groups
                               TRUE ~ 6 # other optimal respondent (8/12)
)) 
treat_uncens <- factor(case_when(df_eval$attrited == 0 ~ as.numeric(ws_eval),
                                 TRUE ~ 7))
treat_uncens_prob <- probability_forest(X = as.matrix(df_eval[, c(context_cols, predv_cols)]),
                                        Y = treat_uncens)$predictions[which(df_eval$attrited == 0),]

balwts_uncens <- (1/uncens_prob)[, 2]

balwts_treat_uncens <- (1/treat_uncens_prob)[cbind(1:nrow(treat_uncens_prob), treat_uncens[which(df_eval$attrited == 0)])]
balwts_treat_uncens[which(balwts_treat_uncens>quantile(balwts_treat_uncens, .999))] <- quantile(balwts_treat_uncens, .999)

df_eval <- df_eval[which(df_eval$attrited == 0),]
ws_eval <- ws_eval[which(df_eval$attrited == 0)]
```


```{r hyperparameters, cache = TRUE}
## Hyperparameters
num_batches <- 3
# times at which the model is updated (applied in following observation)
update_times <- sapply(1:4, function(x) length(which(df_learn$batch == x)))
update_times <- cumsum(update_times)
num_init_draws <- update_times[1]
A <- update_times[4] # no. observations in learning split/ last model update
N <- nrow(df_learn) + nrow(df_eval)
K <- length(unique((df_learn$W)))
```



```{r data_components, cache = TRUE}
xs_learn <- as.matrix(df_learn[, c(context_cols, predv_cols)])
yobs_learn <- df_learn$Y
ws_learn <- as.numeric(df_learn$W)

xs_eval <- as.matrix(df_eval[, c(context_cols, predv_cols)])
yobs_eval <- df_eval$Y
ws_eval <- as.factor(case_when(as.numeric(df_eval$W) == 1 ~ 1, # control
                               as.numeric(df_eval$W) == 2 ~  2, # headline fact check,
                               as.numeric(df_eval$W) == 5 ~ 3, # headline related,
                               as.numeric(df_eval$W) == 6 ~ 4, # respondent accuracy
                               as.numeric(df_eval$W) == 11 ~ 5, # facebook tips,
                               # combine optimal with small groups
                               TRUE ~ 6 # other optimal respondent (8/12)
)) 

```


# Analysis Overview

## Response
The response function is:

$$Y_i = -M_i^{\text{post-treat}} + 0.5T_i^{\text{post-treat}}$$

It is composed of $M_i^{\text{post-treat}}\in \{0,1,2,3,4 \}$, the sum of times the respondent said they would share *misinformation stimuli*, and $T_i^{\text{post-treat}}\in \{0,1,2,3,4 \}$, the sum of times the respondent said they would share *true stimuli*, both post-treatment. There are two types of each stimuli, and for each two questions about sharing: whether they would share directly on Messenger, and whether they woudld share on their timeline. 

We assign greater weight to the sharing of *misinformation* in our response function, because our primary objective is to curb the spread of misinformation, although we would like to do so at minimal cost to the sharing of true information. 

For example, response value of $Y_i = -1$ indicates that the respondent responded yes to two of the questions about sharing the misinformation stimuli and two of the questions about sharing true stimuli. 

## Treatments

Treatment is composed of a respondent-level treatment and a headline-level treatment. In the adaptive learning portion of the experiment, respondent-level treatments and headline-level treatments are implemented as separate factors, each of which has an empty baseline level that is the control. So respondents may be assigned the pure control condition, one of the respondent-level treatments but no headline-level treatment, one of the headline-level treatments but no respondent-level treatment, or one of the respondent-level treatments *and* one of the headline-level treatments. 

**Respondent-level treatments:**

* Control
* Facebook tips
* AfricaCheck tips
* Video training
* Emotion suppression
* Pledge
* Accuracy nudge
* Deliberation nudge

**Headline-level treatments**

* Control
* Related articles
* Third-party fact check
* More information link
* Real information statement

## Response under unique treatments

For use in analysis of the adaptive design, we calculate doubly robust scores. Scores are composed of a conditional means model, which is estimated by fitting $K$ separate causal forests, and a weighting term, which here are inverse probability weights using known probability of treatment assignment. 

$$
\Gamma_{i,w} = \mu_{w}(X_{i}) + 1 \{W_i = w \} \xi_w(X_i)(Y_{i} - \mu_w(X_i))
$$

$$
\mu_{w}(x)  = \textrm{E}[Y_i(w) | X_i = x]
$$

$$
\xi^{IPW}_w(X_i) = \frac{ 1 }{\Pr[W_i = w|X_i = x]}
$$

## Calculating scores

```{r treament_levels, cache=TRUE}
# For learning split only
df_learn['treatment_r'] <- relevel(as.factor(gsub('H_.*_|R_', '', df_learn$W)),
                                   ref = 'control')
df_learn['treatment_h'] <- relevel(as.factor(gsub('H_|_R_.*', '', df_learn$W)),
                                   ref = 'control')

W_levels <- levels(df_learn$W)
# Decompose treatment levels into separate factors
WH_levels <- unique(sub('_R_.*', '', W_levels))
WR_levels <- unique(sub('H_[a-z]*_*[a-z]*_*', '', W_levels))

# Identify treatment locations where each respective factor level is represented
WH_idx <- lapply(WH_levels, function(x) grep(x, W_levels))
WR_idx <- lapply(WR_levels, function(x) grep(x, W_levels))


ws_r <- as.numeric(df_learn$treatment_r) # respondent-level treatment only
ws_h <- as.numeric(df_learn$treatment_h) # headline-level treatment only
K_r <- length(unique(ws_r))
K_h <- length(unique(ws_h))
# Include headline as context
xs_h <- cbind(xs_learn, 
              model.matrix(lm(Y~ treatment_h-1, data = df_learn)))
# Predict when headline == control
xs_h_new <- xs_h
treat_cols <- grepl(pattern = 'treatment', colnames(xs_h))
xs_h_new[, treat_cols] <- matrix(c(1, rep(0, sum(treat_cols) -1 )), 
                                 nrow = nrow(df_learn), 
                                 ncol = sum(treat_cols), byrow = TRUE)

# Include respondent as context
xs_r <- cbind(xs_learn, 
              model.matrix(lm(Y~ treatment_r-1, data = df_learn)))
# Predict when headline == control
xs_r_new <- xs_r
treat_cols <- grepl(pattern = 'treatment', colnames(xs_r))
xs_r_new[, treat_cols] <- matrix(c(1, rep(0, sum(treat_cols) -1 )), 
                                 nrow = nrow(df_learn), 
                                 ncol = sum(treat_cols), byrow = TRUE)

```

### Learning scores
```{r probs_learning, cache = TRUE}
# For learning
probs_learn <- as.matrix(df_learn[, paste0('probs_', 0:39)])
balwts_learn <- (1/probs_learn)[cbind(1:A, ws_learn)]

# Re-calculate probs to aggregate across headline level
# Conditional on being assigned a given headline level, what is the probability of being assigned a given respondent condition?
probs_rwide <- probs_learn
for(x in WH_idx){
  probs_rwide[,x] <- probs_learn[,x]/rowSums(probs_learn[,x])
}
balwts_r <- (1/probs_rwide)[matrix(c(1:nrow(df_learn),ws_learn), ncol = 2)]


probs_r <- t(sapply(1:nrow(df_learn), function(x){
  hval <- ws_h[x]
  colidx <- WH_idx[[hval]]
  probs_rwide[x, colidx]
} ))

# combined probability of being assigned a given respondent treatment
probs_ralt <- sapply(WR_idx, function(x){
  rowSums(probs_learn[,x])
})

# combined probability of being assigned a given headline treatment
probs_halt <- sapply(WH_idx, function(x){
  rowSums(probs_learn[,x])
})

# Re-calculate probs to aggregate across respondent level
probs_hwide <- probs_learn
for(x in WR_idx){
  probs_hwide[,x] <- probs_learn[,x]/rowSums(probs_learn[,x])
}
balwts_h <- (1/probs_hwide)[matrix(c(1:nrow(df_learn),ws_learn), ncol = 2)]


probs_h <- t(sapply(1:nrow(df_learn), function(x){
  rval <- ws_r[x]
  colidx <- WR_idx[[rval]]
  probs_hwide[x, colidx]
} ))
```

For scores in the learning split, we are interested in making comparisons across levels within the two types of factors: respondent-level treatments, and headline-level treatments. To share information across treatment conditions, for our conditional means model, we run separate multi-arm causal forests for each factor type. 

- For the respondent type factor, in the multi-arm causal forest model each *respondent* treatment is an arm, with the reference condition set as control. Headline treatments are treated as contexts. There are `r sum((df_learn$treatment_r=='control'))` observations in the control group, and a minimum and maximum of `r min(table(df_learn$treatment_r)[2:8])` and `r max(table(df_learn$treatment_r)[2:8])` in a given treatment group, respectively.
- For the headline type factor, in the multi-arm causal forest model each *headline* treatment is an arm, with the reference condition set as control. Respondent treatments are treated as contexts. There are `r sum((df_learn$treatment_h=='control'))` observations in the control group, and a minimum and maximum of `r min(table(df_learn$treatment_h)[2:5])` and `r max(table(df_learn$treatment_h)[2:5])` in a given treatment group, respectively.

```{r learn_scores, cache=TRUE}

ws_learn_r <- factor(df_learn$treatment_r, 
                     levels = c('control', 'accuracy', 'deliberation',
                                'emotion', 'pledge', 'africacheck',
                                'facebook', 'video'))
ws_learn_h <- factor(df_learn$treatment_h, 
                     levels = c('control', 'factcheck', 'more_info',
                                'real_info', 'related'))

if(file.exists('objects/aipw_scores_learn.RDS')){ # read in scores if already generated
  aipw_scores_learn <- readRDS('objects/aipw_scores_learn.RDS')
  aipw_scoresR_learn <- aipw_scores_learn[[1]]
  aipw_scoresRmarg_learn <- aipw_scores_learn[[2]]
  aipw_scoresH_learn <- aipw_scores_learn[[3]]
  aipw_scoresHmarg_learn <- aipw_scores_learn[[4]]
  
}else{
  aipw_scores_learn <- aw_scores_learn(xs_h = xs_h, xs_r = xs_r,
                                       ws_h = ws_learn_h, 
                                       ws_r = ws_learn_r, 
                                       ws = ws_learn,
                                       yobs = yobs_learn,
                                       K_h = K_h, K_r = K_r, K = K,
                                       balwts = balwts_learn,
                                       balwts_r = balwts_r, balwts_h = balwts_h,
                                       probs_r = probs_r, probs_h = probs_h,
                                       probsK = probs_learn,
                                       chunks = update_times)
  
  aipw_scoresR_learn <- aipw_scores_learn[[1]]
  aipw_scoresRmarg_learn <- aipw_scores_learn[[2]]
  aipw_scoresH_learn <- aipw_scores_learn[[3]]
  aipw_scoresHmarg_learn <- aipw_scores_learn[[4]]
  
  saveRDS(aipw_scores_learn, 'objects/aipw_scores_learn.RDS')
  
}
```


For the evaluation scores, we consider only respondents who are assigned policies of interest:

- control
- headline: related articles
- headline: fact check
- respondent: accuracy nudge
- respondent: Facebook tips
- respondent: contextual policy, composed of accuracy nudge, Facebook tips, emotion nudge, and video treatment

To calculate scores, our conditional means model is a multi-arm causal forest, with the reference condition set as the pure control. We include five arms for each of the non-contextual policies; because the contextual policy is composed of treatments that overlap with the non-contextual policies, we do not include a contextual policy condition, but rather a condition for the contextual assignments that are not accounted for in the non-contextual arms, the emotion nudge and video treatment. 


### Evalution Scores

```{r optimal_policy_learning, cache=TRUE, warning=FALSE, message=FALSE}
train_idx <- ws_r %in%c(2,6) # note that ordering does not match probs_r
probs_eval <- as.matrix(df_eval[, paste0('probs_', 0:39)])

cf.priority <- causal_forest(
  X = xs_learn[train_idx, ],
  Y = df_learn$post_false_prop[train_idx],
  W = 1*(ws_r[train_idx]==2),
  W.hat = probs_r[train_idx, 2]/(rowSums(probs_r[train_idx, c(2,7)])),
  seed = 60637)

optimal_assignment <- ifelse(predict(cf.priority, xs_eval)$predictions<0, 4, 5)

df_eval$optimal_assignment <- factor(optimal_assignment,
                                     labels = c('Optimal policy == accuracy',
                                                'Optimal policy == FB tips'))

optimal_assignment_original <- case_when(df_eval$optimal0 == 6 ~ 4,
                                         df_eval$optimal0 == 8 ~ 6, #8/12 collapsed
                                         df_eval$optimal0 == 11 ~ 5,
                                         df_eval$optimal0 == 12 ~ 6)

```


```{r combined_eval_scores, cache=TRUE, warning=FALSE, message=FALSE}
## Combined response function scores 
if(file.exists('objects/aipw_scores.RDS')){ # read in scores if already generated
  aipw_scores <- readRDS('objects/aipw_scores.RDS')
  
}else{
  aipw_scores <- aw_scores_eval(xs = xs_eval,
                                yobs = yobs_eval, 
                                ws = ws_eval, 
                                sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores, 'objects/aipw_scores.RDS')
  
}


# learned optimal policy
if(file.exists('objects/aipw_scores_learned.RDS')){ # read in scores if already generated
  aipw_scores_learned <- readRDS('objects/aipw_scores_learned.RDS')
  
}else{
  aipw_scores_learned <- aw_scores_eval(xs = xs_eval,
                                        yobs = yobs_eval, 
                                        ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                 ws_eval == optimal_assignment_original ~ 2,
                                                                 TRUE ~ 3)), 
                                        sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_learned, 'objects/aipw_scores_learned.RDS')
  
}

# Restricted optimal policy
if(file.exists('objects/aipw_scores_restricted.RDS')){ # read in scores if already generated
  aipw_scores_restricted <- readRDS('objects/aipw_scores_restricted.RDS')
  
}else{
  aipw_scores_restricted <- aw_scores_eval(xs = xs_eval,
                                           yobs = yobs_eval, 
                                           ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                    ws_eval == optimal_assignment ~ 2,
                                                                    TRUE ~ 3)), 
                                           sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_restricted, 'objects/aipw_scores_restricted.RDS')
  
}
```

```{r any_eval_scores, cache = TRUE, warning=FALSE, message=FALSE}
## Any share scores
any_true <- df_eval$post_true_prop
any_false<- df_eval$post_false_prop

if(file.exists('objects/aipw_scores_any_true.RDS')){ # read in scores if already generated
  aipw_scores_any_true <- readRDS('objects/aipw_scores_any_true.RDS')
  
}else{
  aipw_scores_any_true <- aw_scores_eval(xs = xs_eval,
                                         yobs = any_true, 
                                         ws = ws_eval,
                                         sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_true, 'objects/aipw_scores_any_true.RDS')
}

# learned optimal policy
if(file.exists('objects/aipw_scores_any_true_learned.RDS')){ # read in scores if already generated
  aipw_scores_any_true_learned <- readRDS('objects/aipw_scores_any_true_learned.RDS')
  
}else{
  aipw_scores_any_true_learned <- aw_scores_eval(xs = xs_eval,
                                                 yobs = any_true, 
                                                 ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                          ws_eval == optimal_assignment_original ~ 2,
                                                                          TRUE ~ 3)), 
                                                 sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_true_learned, 'objects/aipw_scores_any_true_learned.RDS')
}


# restricted optimal policy
if(file.exists('objects/aipw_scores_any_true_restricted.RDS')){ # read in scores if already generated
  aipw_scores_any_true_restricted <- readRDS('objects/aipw_scores_any_true_restricted.RDS')
  
}else{
  aipw_scores_any_true_restricted <- aw_scores_eval(xs = xs_eval,
                                                    yobs = any_true, 
                                                    ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                             ws_eval == optimal_assignment ~ 2,
                                                                             TRUE ~ 3)), 
                                                    sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_true_restricted, 'objects/aipw_scores_any_true_restricted.RDS')
}


if(file.exists('objects/aipw_scores_any_false.RDS')){ # read in scores if already generated
  aipw_scores_any_false <- readRDS('objects/aipw_scores_any_false.RDS')
  
}else{
  aipw_scores_any_false <- aw_scores_eval(xs = xs_eval,
                                          yobs = any_false, 
                                          ws = ws_eval, 
                                          sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_false, 'objects/aipw_scores_any_false.RDS')
}


if(file.exists('objects/aipw_scores_any_false_learned.RDS')){ # read in scores if already generated
  aipw_scores_any_false_learned <- readRDS('objects/aipw_scores_any_false_learned.RDS')
  
}else{
  aipw_scores_any_false_learned <- aw_scores_eval(xs = xs_eval,
                                                  yobs = any_false, 
                                                  ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                           ws_eval == optimal_assignment_original ~ 2,
                                                                           TRUE ~ 3)), 
                                                  sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_false_learned, 'objects/aipw_scores_any_false_learned.RDS')
}

# restricted optimal policy
if(file.exists('objects/aipw_scores_any_false_restricted.RDS')){ # read in scores if already generated
  aipw_scores_any_false_restricted <- readRDS('objects/aipw_scores_any_false_restricted.RDS')
  
}else{
  aipw_scores_any_false_restricted <- aw_scores_eval(xs = xs_eval,
                                                     yobs = any_false, 
                                                     ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                              ws_eval == optimal_assignment ~ 2,
                                                                              TRUE ~ 3)), 
                                                     sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_false_restricted, 'objects/aipw_scores_any_false_restricted.RDS')
}
```

```{r channel_eval_scores, cache = TRUE, message=FALSE, warning=FALSE}
## Channel scores
timeline_true <- df_eval$post_true_timeline_prop
timeline_false <- df_eval$post_false_timeline_prop
send_true <- df_eval$post_true_send_prop
send_false <- df_eval$post_false_send_prop

if(file.exists('objects/aipw_scores_timeline_true.RDS')){ # read in scores if already generated
  aipw_scores_timeline_true <- readRDS('objects/aipw_scores_timeline_true.RDS')
  
}else{
  
  aipw_scores_timeline_true <- aw_scores_eval(xs = xs_eval,
                                              yobs = timeline_true, 
                                              ws = ws_eval, 
                                              sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_true, 'objects/aipw_scores_timeline_true.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_true_learned.RDS')){ # read in scores if already generated
  aipw_scores_timeline_true_learned <- readRDS('objects/aipw_scores_timeline_true_learned.RDS')
  
}else{
  
  aipw_scores_timeline_true_learned <- aw_scores_eval(xs = xs_eval,
                                                      yobs = timeline_true, 
                                                      ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                               ws_eval == optimal_assignment_original ~ 2,
                                                                               TRUE ~ 3)), 
                                                      sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_true_learned, 'objects/aipw_scores_timeline_true_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_true_restricted.RDS')){ # read in scores if already generated
  aipw_scores_timeline_true_restricted <- readRDS('objects/aipw_scores_timeline_true_restricted.RDS')
  
}else{
  
  aipw_scores_timeline_true_restricted <- aw_scores_eval(xs = xs_eval,
                                                         yobs = timeline_true, 
                                                         ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                                  ws_eval == optimal_assignment ~ 2,
                                                                                  TRUE ~ 3)), 
                                                         sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_true_restricted, 'objects/aipw_scores_timeline_true_restricted.RDS')
  
}



if(file.exists('objects/aipw_scores_timeline_false.RDS')){ # read in scores if already generated
  aipw_scores_timeline_false <- readRDS('objects/aipw_scores_timeline_false.RDS')
  
}else{
  
  aipw_scores_timeline_false <- aw_scores_eval(xs = xs_eval,
                                               yobs = timeline_false, 
                                               ws = ws_eval, 
                                               sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_false, 'objects/aipw_scores_timeline_false.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_false_learned.RDS')){ # read in scores if already generated
  aipw_scores_timeline_false_learned <- readRDS('objects/aipw_scores_timeline_false_learned.RDS')
  
}else{
  
  aipw_scores_timeline_false_learned <- aw_scores_eval(xs = xs_eval,
                                                       yobs = timeline_false, 
                                                       ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                                ws_eval == optimal_assignment_original ~ 2,
                                                                                TRUE ~ 3)), 
                                                       sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_false_learned, 'objects/aipw_scores_timeline_false_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_false_restricted.RDS')){ # read in scores if already generated
  aipw_scores_timeline_false_restricted <- readRDS('objects/aipw_scores_timeline_false_restricted.RDS')
  
}else{
  
  aipw_scores_timeline_false_restricted <- aw_scores_eval(xs = xs_eval,
                                                          yobs = timeline_false, 
                                                          ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                                   ws_eval == optimal_assignment ~ 2,
                                                                                   TRUE ~ 3)), 
                                                          sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_false_restricted, 'objects/aipw_scores_timeline_false_restricted.RDS')
  
}


if(file.exists('objects/aipw_scores_send_true.RDS')){ # read in scores if already generated
  aipw_scores_send_true <- readRDS('objects/aipw_scores_send_true.RDS')
  
}else{
  
  aipw_scores_send_true <- aw_scores_eval(xs = xs_eval,
                                          yobs = send_true, 
                                          ws = ws_eval, 
                                          sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_true, 'objects/aipw_scores_send_true.RDS')
}

if(file.exists('objects/aipw_scores_send_true_learned.RDS')){ # read in scores if already generated
  aipw_scores_send_true_learned <- readRDS('objects/aipw_scores_send_true_learned.RDS')
  
}else{
  
  aipw_scores_send_true_learned <- aw_scores_eval(xs = xs_eval,
                                                  yobs = send_true, 
                                                  ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                           ws_eval == optimal_assignment_original ~ 2,
                                                                           TRUE ~ 3)), 
                                                  sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_true_learned, 'objects/aipw_scores_send_true_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_send_true_restricted.RDS')){ # read in scores if already generated
  aipw_scores_send_true_restricted <- readRDS('objects/aipw_scores_send_true_restricted.RDS')
  
}else{
  
  aipw_scores_send_true_restricted <- aw_scores_eval(xs = xs_eval,
                                                     yobs = send_true, 
                                                     ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                              ws_eval == optimal_assignment ~ 2,
                                                                              TRUE ~ 3)), 
                                                     sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_true_restricted, 'objects/aipw_scores_send_true_restricted.RDS')
  
}

if(file.exists('objects/aipw_scores_send_false.RDS')){ # read in scores if already generated
  aipw_scores_send_false <- readRDS('objects/aipw_scores_send_false.RDS')
  
}else{
  aipw_scores_send_false <- aw_scores_eval(xs = xs_eval,
                                           yobs = send_false, 
                                           ws = ws_eval, 
                                           sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_false, 'objects/aipw_scores_send_false.RDS')
}


if(file.exists('objects/aipw_scores_send_false_learned.RDS')){ # read in scores if already generated
  aipw_scores_send_false_learned <- readRDS('objects/aipw_scores_send_false_learned.RDS')
  
}else{
  
  aipw_scores_send_false_learned <- aw_scores_eval(xs = xs_eval,
                                                   yobs = send_false, 
                                                   ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                            ws_eval == optimal_assignment_original ~ 2,
                                                                            TRUE ~ 3)), 
                                                   sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_false_learned, 'objects/aipw_scores_send_false_learned.RDS')
  
}

if(file.exists('objects/aipw_scores_send_false_restricted.RDS')){ # read in scores if already generated
  aipw_scores_send_false_restricted <- readRDS('objects/aipw_scores_send_false_restricted.RDS')
  
}else{
  
  aipw_scores_send_false_restricted <- aw_scores_eval(xs = xs_eval,
                                                      yobs = send_false, 
                                                      ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                               ws_eval == optimal_assignment ~ 2,
                                                                               TRUE ~ 3)), 
                                                      sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_false_restricted, 'objects/aipw_scores_send_false_restricted.RDS')
  
}
```

### Evalution Estimation
```{r response_eval_estimation, cache=TRUE}
# Scores estimates
# mean response
aipw_est <- find_est(aipw_scores)
aipw_est_learned <- find_est(aipw_scores_learned)
aipw_est_restricted <- find_est(aipw_scores_restricted)
aipw_est <- bind_rows(aipw_est[1:5,],
                      aipw_est_learned[2,],
                      aipw_est_restricted[2,])
# treatment effects
aipw_te <- find_te(aipw_scores)
aipw_te_learned <- find_te(aipw_scores_learned)
aipw_te_restricted <- find_te(aipw_scores_restricted)
aipw_te <- bind_rows(aipw_te[1:4,],
                     aipw_te_learned[1,],
                     aipw_te_restricted[1,])

# Any
## true
aipw_t_est <- find_est(aipw_scores_any_true)
aipw_t_est_learned <- find_est(aipw_scores_any_true_learned)
aipw_t_est_restricted <- find_est(aipw_scores_any_true_restricted)
aipw_t_est <- bind_rows(aipw_t_est[1:5,],
                        aipw_t_est_learned[2,],
                        aipw_t_est_restricted[2,])

aipw_t_te <- find_te(aipw_scores_any_true)
aipw_t_te_learned <- find_te(aipw_scores_any_true_learned)
aipw_t_te_restricted <- find_te(aipw_scores_any_true_restricted)
aipw_t_te <- bind_rows(aipw_t_te[1:4,],
                       aipw_t_te_learned[1,],
                       aipw_t_te_restricted[1,])

## false
aipw_f_est <- find_est(aipw_scores_any_false)
aipw_f_est_learned <- find_est(aipw_scores_any_false_learned)
aipw_f_est_restricted <- find_est(aipw_scores_any_false_restricted)
aipw_f_est <- bind_rows(aipw_f_est[1:5,],
                        aipw_f_est_learned[2,],
                        aipw_f_est_restricted[2,])

aipw_f_te <- find_te(aipw_scores_any_false)
aipw_f_te_learned <- find_te(aipw_scores_any_false_learned)
aipw_f_te_restricted <- find_te(aipw_scores_any_false_restricted)
aipw_f_te <- bind_rows(aipw_f_te[1:4,],
                       aipw_f_te_learned[1,],
                       aipw_f_te_restricted[1,])

# Channel
## true
aipw_tt_est <- find_est(aipw_scores_timeline_true)
aipw_tt_est_learned <- find_est(aipw_scores_timeline_true_learned)
aipw_tt_est_restricted <- find_est(aipw_scores_timeline_true_restricted)
aipw_tt_est <- bind_rows(aipw_tt_est[1:5,],
                         aipw_tt_est_learned[2,],
                         aipw_tt_est_restricted[2,])

aipw_tt_te <- find_te(aipw_scores_timeline_true)
aipw_tt_te_learned <- find_te(aipw_scores_timeline_true_learned)
aipw_tt_te_restricted <- find_te(aipw_scores_timeline_true_restricted)
aipw_tt_te <- bind_rows(aipw_tt_te[1:4,],
                        aipw_tt_te_learned[1,],
                        aipw_tt_te_restricted[1,])


aipw_st_est <- find_est(aipw_scores_send_true)
aipw_st_est_learned <- find_est(aipw_scores_send_true_learned)
aipw_st_est_restricted <- find_est(aipw_scores_send_true_restricted)
aipw_st_est <- bind_rows(aipw_st_est[1:5,],
                         aipw_st_est_learned[2,],
                         aipw_st_est_restricted[2,])

aipw_st_te <- find_te(aipw_scores_send_true)
aipw_st_te_learned <- find_te(aipw_scores_send_true_learned)
aipw_st_te_restricted <- find_te(aipw_scores_send_true_restricted)
aipw_st_te <- bind_rows(aipw_st_te[1:4,],
                        aipw_st_te_learned[1,],
                        aipw_st_te_restricted[1,])

## false
aipw_tf_est <- find_est(aipw_scores_timeline_false)
aipw_tf_est_learned <- find_est(aipw_scores_timeline_false_learned)
aipw_tf_est_restricted <- find_est(aipw_scores_timeline_false_restricted)
aipw_tf_est <- bind_rows(aipw_tf_est[1:5,],
                         aipw_tf_est_learned[2,],
                         aipw_tf_est_restricted[2,])

aipw_tf_te <- find_te(aipw_scores_timeline_false)
aipw_tf_te_learned <- find_te(aipw_scores_timeline_false_learned)
aipw_tf_te_restricted <- find_te(aipw_scores_timeline_false_restricted)
aipw_tf_te <- bind_rows(aipw_tf_te[1:4,],
                        aipw_tf_te_learned[1,],
                        aipw_tf_te_restricted[1,])


aipw_sf_est <- find_est(aipw_scores_send_false)
aipw_sf_est_learned <- find_est(aipw_scores_send_false_learned)
aipw_sf_est_restricted <- find_est(aipw_scores_send_false_restricted)
aipw_sf_est <- bind_rows(aipw_sf_est[1:5,],
                         aipw_sf_est_learned[2,],
                         aipw_sf_est_restricted[2,])

aipw_sf_te <- find_te(aipw_scores_send_false)
aipw_sf_te_learned <- find_te(aipw_scores_send_false_learned)
aipw_sf_te_restricted <- find_te(aipw_scores_send_false_restricted)
aipw_sf_te <- bind_rows(aipw_sf_te[1:4,],
                        aipw_sf_te_learned[1,],
                        aipw_sf_te_restricted[1,])


aipw_est$term <- 
  aipw_t_est$term <-  
  aipw_f_est$term <-  
  aipw_tt_est$term <- aipw_tf_est$term <- 
  aipw_st_est$term <- aipw_sf_est$term <-
  treatment_levels

aipw_te$term <- 
  aipw_f_te$term <-  
  aipw_t_te$term <-  
  aipw_t_te$term <-  
  aipw_tt_te$term <- aipw_tf_te$term <- 
  aipw_st_te$term <- aipw_sf_te$term <-
  treatment_levels[-1]

```


# Figure 1: Learning stage estimates 

```{r contextual_estimates, cache = TRUE, cache.lazy = FALSE}
# Get estimates for all 40 counterfactual policies
out_full <- lapply(1:K, function(x) {
  policy1 <- matrix(0, nrow = nrow(aipw_scoresR_learn),
                    ncol = ncol(aipw_scoresR_learn))
  policy1[, x] <- 1/length(x)
  outmat <- output_estimates(
    policy1 = policy1,
    gammahat = aipw_scoresR_learn, 
    contextual_probs = contextual_probs)
  outmat
})


# Get estimates for headline polices

out_H <- lapply(WH_idx, function(x) {
  policy1 <- matrix(0, nrow = nrow(aipw_scoresR_learn),
                    ncol = ncol(aipw_scoresR_learn))
  policy1[, x] <- 1/length(x)
  outmat <- output_estimates(
    policy1 = policy1,
    gammahat = aipw_scoresR_learn, 
    contextual_probs = contextual_probs)
  outmat
})

# Get estimates for respondent policies

out_R <- lapply(WR_idx, function(x) {
  policy1 <- matrix(0, nrow = nrow(aipw_scoresR_learn),
                    ncol = ncol(aipw_scoresR_learn))
  policy1[, x] <- 1/length(x)
  outmat <- output_estimates(
    policy1 = policy1,
    gammahat = aipw_scoresR_learn, 
    contextual_probs = contextual_probs)
  outmat
})

```


```{r learning_grid, cache = TRUE}
df_grid <- do.call(rbind.data.frame, c(out_full, 
                                       out_R, 
                                       out_H))
colnames(df_grid) <- c('estimate', 'std.error')



df_grid <- df_grid %>%
  mutate(
    Headline = factor(c(WCH_terms, 
                        rep(WCH_terms, each = 7),
                        rep('Equally\nweighted', 8),
                        WCH_terms), 
                      levels = c(WCH_terms, 'Equally\nweighted')),
    Respondent = factor(c(rep(WCR_terms[1],5),
                          rep(WCR_terms[-1], times = 5),
                          WCR_terms,
                          rep('Equally\nweighted', 5)),
                        levels = c('Equally\nweighted', rev(WCR_terms))),
    level = factor(case_when(Headline =='Equally\nweighted' ~ 'Respondent: Headline equally weighted', 
                             Respondent =='Equally\nweighted' ~ 'Headline: Respondent equally weighted', 
                             TRUE ~ 'Interactions: Respondent x headline'),
                   levels = c('Interactions: Respondent x headline', 
                              'Headline: Respondent equally weighted', 
                              'Respondent: Headline equally weighted')),
    Probabilities = c(
      colMeans(probs_learn[which(df_learn$batch == 4),]),
      colMeans(probs_ralt[which(df_learn$batch == 4),]),
      colMeans(probs_halt[which(df_learn$batch == 4),]))
  )

estimate_order <- c('Control',
                    as.character(
                      df_grid[which(df_grid$Headline =='Equally\nweighted' & df_grid$Respondent!='Control'), 'Respondent'][
                        order(df_grid[which(df_grid$Headline =='Equally\nweighted' & df_grid$Respondent!='Control'), 'estimate'], decreasing = FALSE)]),
                    as.character(
                      df_grid[which(df_grid$Respondent =='Equally\nweighted' & df_grid$Headline!='Control'), 'Headline'][
                        order(df_grid[which(df_grid$Respondent =='Equally\nweighted' & df_grid$Headline!='Control'), 'estimate'], decreasing = FALSE)]))

df_grid <- df_grid %>%
  mutate(term = factor(case_when(Headline =='Equally\nweighted' ~ Respondent, 
                                 Respondent =='Equally\nweighted'~ Headline,
                                 TRUE ~ Respondent),
                       levels = estimate_order),
         colors = factor(case_when(Headline =='Equally\nweighted' ~ 'Respondent\nHeadline equally weighted', 
                                   Respondent =='Equally\nweighted'~ 'Headline\nRespondent equally weighted',
                                   TRUE ~ Headline),
                         levels =estimate_order[c(1, 9:12)]),
         position_x = 0.5 + c(seq(0.5, 0, -0.125)[order(estimate_order[c(1, 9:12)])], 
                              rep(seq(0.5, 0, -0.125)[order(estimate_order[c(1, 9:12)])], each = 7),
                              rep(0.25, 8 + 5)))


gg1 <- ggplot(df_grid[which(df_grid$level == 'Interactions: Respondent x headline'),], 
              aes(x = estimate, y = term, group = colors, color = colors,
                  xmin = estimate - 1.96*std.error,
                  xmax = estimate + 1.96*std.error)) +
  stat_gradientinterval(
    aes(xdist = distributional::dist_normal(estimate, std.error), 
        color=colors, fill = colors), 
    position = position_dodge(width=0.5), .width = 0, size = 0) + 
  geom_point(position=position_dodge(width=0.5), 
             size = 1, fill = 'white') + # change size, fill here
  geom_errorbar(aes(xmin = estimate - 1.96*std.error, xmax = estimate + 1.96*std.error), 
                width = 0.05, position=position_dodge(width=0.5)) + 
  theme_bw() +   
  xlab('Estimate') +
  ylab('Policy') +
  scale_color_manual(values = cbPalette[c(1,3,4,2,6)], breaks = estimate_order[c(1, 9:12)]) +
  scale_fill_manual(values = cbPalette[c(1,3,4,2,6)], breaks = estimate_order[c(1, 9:12)]) +
  ggforce::facet_col(vars(level), scales = 'free_y', space = 'free') +
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'white'),
        plot.background = element_rect(fill = 'white', color = 'white'),
        strip.background = element_blank(),
        legend.position = 'bottom') + 
  guides(color=guide_legend(title='Headline level', reverse = TRUE, 
                            title.position = 'top', title.hjust = 0.5), 
         fill=guide_legend(title='Headline level', reverse = TRUE, 
                           title.position = 'top', title.hjust = 0.5)) + 
  geom_text(aes(x = position_x, y = term, label = round(Probabilities,3)),
            position=position_dodge(width=1.1), 
            size = 2.75,
            hjust = 0) + 
  scale_x_continuous(sec.axis = sec_axis(~ .,
                                         breaks =c(0.75),
                                         labels = c('Batch 4\nProbabilities'))) +
  coord_cartesian(xlim = c(-1.5, 1.4))

gg2 <- ggplot(df_grid[which(df_grid$level != 'Interactions: Respondent x headline'),], 
              aes(x = estimate, y = term,
                  xmin = estimate - 1.96*std.error,
                  xmax = estimate + 1.96*std.error)) +
  stat_gradientinterval(
    aes(xdist = distributional::dist_normal(estimate, std.error)),
    .width = 0, size = 0) + 
  geom_point(size = 1, fill = 'white') + # change size, fill here
  geom_errorbar(aes(xmin = estimate - 1.96*std.error, xmax = estimate + 1.96*std.error), 
                width = 0.05, position=position_dodge(width=0.5)) + 
  theme_bw() +   
  xlab('Estimate') +
  ylab(NULL) +
  ggforce::facet_col(vars(level), scales = 'free_y', space = 'free') +
  geom_vline(data = df_grid[which(df_grid$level == 'Respondent: Headline equally weighted'),], aes(xintercept=df_grid[which(df_grid$level == 'Respondent: Headline equally weighted' & df_grid$Respondent == 'Control'),'estimate']), 
             colour='grey60', linetype = 'dashed') +
  geom_vline(data = df_grid[which(df_grid$level == 'Headline: Respondent equally weighted'),], aes(xintercept=df_grid[which(df_grid$level == 'Headline: Respondent equally weighted' & df_grid$Headline == 'Control'),'estimate']), 
             colour='grey60', linetype = 'dashed') +
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'white'),
        plot.background = element_rect(fill = 'white', color = 'white'),
        strip.background = element_blank()) + 
  geom_text(aes(x = position_x, y = term, label = round(Probabilities,3)),
            size = 2.75,
            hjust = 0) + 
  scale_x_continuous(sec.axis = sec_axis(~ .,
                                         breaks =c(0.75),
                                         labels = c('Batch 4\nProbabilities'))) +
  coord_cartesian(xlim = c(-1.5, 1.4))


gt <- plot_grid(
  plot_grid(
    gg1 + theme(legend.position="none"), 
    gg2), 
  plot_grid(get_legend(gg1), NULL, nrow = 1, rel_widths = c(2.4,1)),
  nrow = 2, rel_heights = c(10,1)
)


ggsave('../figures/joint_scores.png', plot = gt, height = 6, width = 8)

```

```{r learning_grid_alt, cache = TRUE}
df_grid_alt <- df_grid[which(df_grid$level != 'Interactions: Respondent x headline'),]

df_grid_alt$best <- factor(case_when(
  df_grid_alt$Respondent %in% c('Accuracy nudge',
                                'Facebook tips') ~ 'Respondent', 
  
  df_grid_alt$Headline %in% c('Fact check',
                              'Related articles') ~ 'Headline', 
  TRUE ~ 'Neither'))

gg2_alt <- ggplot(df_grid_alt, 
                  aes(x = estimate, y = term,
                      xmin = estimate - 1.96*std.error,
                      xmax = estimate + 1.96*std.error, color = best)) +
  stat_gradientinterval(
    aes(xdist = distributional::dist_normal(estimate, std.error), color = best, fill = best),
    .width = 0, size = 0) + 
  geom_point(size = 1, fill = 'white') + # change size, fill here
  geom_errorbar(aes(xmin = estimate - 1.96*std.error, xmax = estimate + 1.96*std.error), 
                width = 0.05, position=position_dodge(width=0.5)) + 
  theme_bw() +   
  xlab('Estimate') +
  ylab(NULL) +
  ggforce::facet_col(vars(level), scales = 'free_y', space = 'free') +
  geom_vline(data = df_grid[which(df_grid$level == 'Respondent: Headline equally weighted'),], aes(xintercept=df_grid[which(df_grid$level == 'Respondent: Headline equally weighted' & df_grid$Respondent == 'Control'),'estimate']), 
             colour='grey60', linetype = 'dashed') +
  geom_vline(data = df_grid[which(df_grid$level == 'Headline: Respondent equally weighted'),], aes(xintercept=df_grid[which(df_grid$level == 'Headline: Respondent equally weighted' & df_grid$Headline == 'Control'),'estimate']), 
             colour='grey60', linetype = 'dashed') +
  scale_color_manual(values = cbPalette[c(7,1,7)]) +
  scale_fill_manual(values = cbPalette[c(7,1,7)]) +
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'white'),
        plot.background = element_rect(fill = 'white', color = 'white'),
        strip.background = element_blank(),
        legend.position = 'none') + 
  geom_text(aes(x = position_x, y = term, label = round(Probabilities,3)),
            size = 2.75,
            hjust = 0) + 
  scale_x_continuous(sec.axis = sec_axis(~ .,
                                         breaks =c(0.75),
                                         labels = c('Batch 4\nProbabilities'))) +
  coord_cartesian(xlim = c(-1.5, 1.4))


gt <- cowplot::plot_grid(
  cowplot::plot_grid(
    gg1 + theme(legend.position="none"), 
    gg2_alt), 
  cowplot::plot_grid(get_legend(gg1), NULL, nrow = 1, rel_widths = c(2.4,1)),
  nrow = 2, rel_heights = c(10,1)
)


ggsave('../figures/joint_scores_alt.png', plot = gt, height = 6, width = 8)
```



# Table 1: Heterogeneity in response under control

```{r control_heterogeneity_primary, cache = TRUE}
table <- sapply(covariate_list, function(x) {
  covariate <- x
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores[,1]  ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores[,1] ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores[,1] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores[,1] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, -ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(NA, NA, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
},
simplify = FALSE)
table <- do.call(rbind, table)

table_combined <- table %>% 
  mutate(
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

```

```{r control_heterogeneity_any, cache = TRUE}

apply_mat <- expand.grid(stimuli_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[2]
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores_any_',stimuli_type,
                            '[,1] ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type,
                            '[,1] ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores_any_',stimuli_type, 
                            '[,1] ~  factor(',covariate, 
                            '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type, 
                            '[,1] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, -ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(NA, NA, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})
table <- do.call(rbind, table)

table_any <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

# save for in-text results reporting
table_any_control <- table_any
```

```{r control_heterogeneity_channel, cache = TRUE, warning = FALSE, message=FALSE}
apply_mat <- expand.grid(stimuli_types, channel_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[3]
  channel <- x[2]
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores_', channel, '_', stimuli_type, '[,1]', 
                            
                            ' ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores_', channel, '_', stimuli_type, '[,1]', 
                            ' ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores_', channel, '_',stimuli_type, '[,1]',
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores_', channel, '_',stimuli_type, '[,1]',
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, -ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(NA, NA, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      `Channel` = channel,
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})


table <- do.call(rbind, table)

table_channel <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )



```

```{r control_combined_heterogeneity, cache = TRUE, message=FALSE, warning=FALSE}
# Mean response estimates
models <- list(
  `Sharing\nDiscernment` = list(tidy = table_combined),
  `False: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'False'),]),
  `False: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                         table_channel$Channel == 'send'),]),
  `False: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                        table_channel$Channel == 'timeline'),]),
  `True: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'True'),]),
  `True: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                        table_channel$Channel == 'send'),]),
  `True: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                       table_channel$Channel == 'timeline'),])
)

models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  x
})

rows <- as.data.frame(matrix(c('', '\\textbf{Sharing}', '', '\\textbf{False}', '', '', '\\textbf{True}', '',
                               '', '\\textbf{Discernment}', 'Any sharing', 'Messenger', 'Timeline', 'Any sharing', 'Messenger', 'Timeline',
                               'row3', rep('', 7),
                               'row8', rep('', 7),
                               'row11', rep('', 7),
                               'row16', rep('', 7),
                               'row19', rep('', 7),
                               'row24', rep('', 7),
                               'row27', rep('', 7),
                               'row32', rep('', 7),
                               'row35', rep('', 7),
                               'row40', rep('', 7)),
                             byrow = TRUE, ncol = 8
))

row3 <- '\\cmidrule(lr){2-2} \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\multicolumn{4}{l}{\\textbf{Age}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row8 <- '\\cmidrule(lr){2-8}'
row11 <- '\\multicolumn{4}{l}{\\textbf{Gender}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row16 <- '\\cmidrule(lr){2-8}'
row19 <- '\\multicolumn{4}{l}{\\textbf{Supports governing party}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row24 <- '\\cmidrule(lr){2-8}'
row27 <- '\\multicolumn{4}{l}{\\textbf{Digital literacy index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row32 <- '\\cmidrule(lr){2-8}'
row35 <- '\\multicolumn{4}{l}{\\textbf{Scientific knowledge index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row40 <- '\\cmidrule(lr){2-8}'

attr(rows, 'position') <- c(1,2,3,8,11,16,19,24,27,32,35,40)

xx <- modelsummary(models, 
                   # # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL,
                   coef_rename = c('Age: Below median (n = 5,300)' = r'(\hspace{1em} Below median)',
                                   'Age: Above median (n = 5,231)' = r'(\hspace{1em} Above median)',
                                   'Age: Difference' = r'(\hspace{1em} Difference)',
                                   'Male:  Not male (n = 4,915)' = r'(\hspace{1em} Not male)',
                                   'Male: Male (n = 5,616)' = r'(\hspace{1em} Male)',
                                   'Male: Difference' = r'(\hspace{1em} Difference )',
                                   'Supports governing party:  Not aligned (n = 7,360)' = r'(\hspace{1em} Not aligned)',
                                   'Supports governing party: Aligned (n = 3,171)' = r'(\hspace{1em} Aligned)',
                                   'Supports governing party: Difference' = r'(\hspace{1em} Difference  )',
                                   'Digital literacy index: Below median (n = 5,418)' = r'(\hspace{1em} Below median )',
                                   'Digital literacy index: Above median (n = 5,113)' = r'(\hspace{1em} Above median )',
                                   'Digital literacy index: Difference' = r'(\hspace{1em}  Difference)',
                                   'Scientific knowledge index: Below median (n = 5,560)' = r'(\hspace{1em} Below median  )',
                                   'Scientific knowledge index: Above median (n = 4,971)' = r'(\hspace{1em} Above median  )',
                                   'Scientific knowledge index: Difference' = r'(\hspace{1em} Difference   )'),
                   output = 'latex_tabular')

xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '', xx[1], fixed = TRUE)

xx <- gsub('\nrow3 &  &  &  &  &  &  & \\\\', 
           row3, xx, fixed = TRUE)
xx <- gsub('\nrow8 &  &  &  &  &  &  & \\\\', 
           row8, xx, fixed = TRUE)
xx <- gsub('\nrow11 &  &  &  &  &  &  & \\\\', 
           row11, xx, fixed = TRUE)
xx <- gsub('\nrow16 &  &  &  &  &  &  & \\\\', 
           row16, xx, fixed = TRUE)
xx <- gsub('\nrow19 &  &  &  &  &  &  & \\\\', 
           row19, xx, fixed = TRUE)
xx <- gsub('\nrow24 &  &  &  &  &  &  & \\\\', 
           row24, xx, fixed = TRUE)
xx <- gsub('\nrow27 &  &  &  &  &  &  & \\\\', 
           row27, xx, fixed = TRUE)
xx <- gsub('\nrow32 &  &  &  &  &  &  & \\\\', 
           row32, xx, fixed = TRUE)
xx <- gsub('\nrow35 &  &  &  &  &  &  & \\\\', 
           row35, xx, fixed = TRUE)
xx <- gsub('\nrow40 &  &  &  &  &  &  & \\\\', 
           row40, xx, fixed = TRUE)

# ns for each subgroup
ns <- gsub('^[[:alpha:] : /]*', '', models$`Sharing\nDiscernment`$tidy$term)

for(i in 1:length(ns)){
  xx <- sub('\\\\\n & (', 
            paste0('\\\\\n\\hspace{2em}',ns[i], ' & ('), xx, fixed = TRUE)  
}


writeLines(xx, '../tables/heterogeneity_control.tex')

```
# Figure 2: Response estimates
```{r unified_eval_scoresplot, echo = FALSE, message = FALSE, cache=TRUE, warning=FALSE, message=FALSE}



all_scores <- bind_rows(list(
  `Any` = bind_rows(list(`Sharing\nDiscernment` = aipw_est), 
                    .id = 'Response measure'), 
  `Timeline` = bind_rows(list(`True` = aipw_tt_est,
                              `False` = aipw_tf_est), 
                         .id = 'Response measure'),
  `Messenger` = bind_rows(list(`True` = aipw_st_est,
                               `False` = aipw_sf_est), 
                          .id = 'Response measure')), 
  .id = 'Channel') %>% 
  mutate(`Response measure` = factor(`Response measure`,
                                     levels = c('False','True', 'Sharing\nDiscernment')),
         Channel = relevel(as.factor(`Channel`),
                           ref = 'Timeline'),
         Aggregation = factor(case_when(
           `Response measure` == 'Sharing\nDiscernment' ~ 'Sharing\nDiscernment',
           TRUE ~ 'Disaggregated'),
           levels = c('Disaggregated', 'Sharing\nDiscernment')),
         Intervention = factor(rep(c('Control', rep(c('Headline', 'Respondent'), times = c(2,4))),5)),
         term = factor(term, levels = c(
           'Control', 
           'Headline\nRelated articles', 
           'Headline\nFact check',
           'Respondent\nRestricted targeted',
           'Respondent\nLearned targeted',
           'Respondent\nFacebook tips',
           'Respondent\nAccuracy'
         )))


ggplot(all_scores, aes(x = estimate, y =term, color=`Response measure`, 
                       shape = Channel)) +
  stat_gradientinterval(
    data = all_scores %>% filter(Channel != 'Any'),
    aes(y = term, 
        xdist = distributional::dist_normal(estimate, std.error), 
        color=`Response measure`, fill = `Response measure`), 
    position = position_dodge(width=0.5), .width = 0, size = 0) +
  stat_gradientinterval(
    data = all_scores %>% filter(Channel == 'Any'),
    aes(y = term, 
        xdist = distributional::dist_normal(estimate, std.error), 
        color=`Response measure`, fill = `Response measure`), 
    .width = 0, size = 0, height = 0.2)  +
  geom_point(data = all_scores %>% filter(Channel != 'Any'),
             position=position_dodge(width=0.5), 
             size = 4, fill = 'white') + # change size, fill here
  geom_point(data = all_scores %>% filter(Channel == 'Any'), 
             size = 4, fill = 'white') + # change size, fill here
  geom_errorbar(data = all_scores %>% filter(Channel != 'Any'),
                aes(xmin = estimate - 1.96*std.error, xmax = estimate + 1.96*std.error), 
                width = 0.05, position=position_dodge(width=0.5)) + 
  geom_errorbar(data = all_scores %>% filter(Channel == 'Any'),
                aes(xmin = estimate - 1.96*std.error, xmax = estimate + 1.96*std.error), 
                width = 0) + 
  scale_shape_manual(values = c(24, 22, 21), breaks = c('Timeline', 'Messenger', 'Any')) + # change shape here
  facet_grid(rows = vars(Intervention), 
             cols = vars(Aggregation),
             scales = 'free', space = 'free') + 
  xlab('Estimate') +
  ylab('Policy') +
  scale_color_manual(values = cbPalette[c(7,6,2)], breaks = c('False', 'True', 'Sharing\nDiscernment')) +
  scale_fill_manual(values = cbPalette[c(7,6,2)], breaks = c('False', 'True', 'Sharing\nDiscernment')) +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'white'),
        plot.background = element_rect(fill = 'white', color = 'white'),
        strip.text.y = element_blank(),
        strip.text.x = element_blank())

ggsave('../figures/evaluated_scores_all.png', width = 8, height = 4)
```


# Table 2: Control response and treatment effect estimates

```{r response_eval_tables, warning=FALSE}
# Mean response estimates
models <- list(
  `Sharing\nDiscernment` = list(
    tidy = bind_rows(aipw_te[1:6,],
                     aipw_est[1,]),
    pval = 'p.value.upper'),
  `False: Any sharing` = list(
    tidy = bind_rows(aipw_f_te[1:6,],
                     aipw_f_est[1,]),
    pval = 'p.value.lower'),
  `False: Messenger` = list(
    tidy = bind_rows(aipw_sf_te[1:6,],
                     aipw_sf_est[1,]),
    pval = 'p.value.lower'),
  `False: Timeline` = list(
    tidy = bind_rows(aipw_tf_te[1:6,],
                     aipw_tf_est[1,]),
    pval = 'p.value.lower'),
  `True: Any sharing` = list(
    tidy = bind_rows(aipw_t_te[1:6,],
                     aipw_t_est[1,]),
    pval = 'p.value.upper'),
  `True: Messenger` = list(
    tidy = bind_rows(aipw_st_te[1:6,],
                     aipw_st_est[1,]),
    pval = 'p.value.upper'),
  `True: Timeline` = list(
    tidy = bind_rows(aipw_tt_te[1:6,],
                     aipw_tt_est[1,]),
    pval = 'p.value.upper'
  )
)


models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  pvals <- x$tidy[,x$pval]
  pvals[length(pvals)] <- NA
  x$tidy$p.value <- pvals
  x
})

rows <- as.data.frame(matrix(c('', '\\textbf{Sharing}', '', '\\textbf{False}', '', '', '\\textbf{True}', '',
                               '', '\\textbf{Discernment}', 'Any sharing', 'Messenger', 'Timeline', 'Any sharing', 'Messenger', 'Timeline',
                               'row3', rep('', 7),
                               'row8', rep('', 7),
                               'row17', rep('', 7)),
                             byrow = TRUE, ncol = 8
))
row3 <- '\\cmidrule(lr){2-2} \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\multicolumn{4}{l}{\\textbf{Headline treatment effects}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row8 <- '\\multicolumn{4}{l}{\\textbf{Respondent treatment effects}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row17 <- '\\hline'

attr(rows, 'position') <- c(1,2,3,8,17)

xx <- modelsummary(models, 
                   # # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL,
                   
                   coef_rename = c('Headline\nFact check' = r'(\hspace{1em}Fact check)',
                                   'Headline\nRelated articles' = r'(\hspace{1em}Related articles)',
                                   'Respondent\nAccuracy' = r'(\hspace{1em}Accuracy)',
                                   'Respondent\nFacebook tips' = r'(\hspace{1em}Facebook tips)',
                                   'Respondent\nRestricted targeted' = r'(\hspace{1em}Restricted Targeted Policy)',
                                   'Respondent\nLearned targeted' = r'(\hspace{1em}Learned Targeted Policy)',
                                   'Control' = r'(\hspace{1em}Control mean)'),
                   output = 'latex_tabular')
xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '', xx[1], fixed = TRUE)

xx <- gsub('\nrow3 &  &  &  &  &  &  & \\\\', 
           row3, xx, fixed = TRUE)
xx <- gsub('\nrow8 &  &  &  &  &  &  & \\\\', 
           row8, xx, fixed = TRUE)
xx <- gsub('\nrow17 &  &  &  &  &  &  & \\\\', 
           row17, xx, fixed = TRUE)


yy <- gregexec('Learned Targeted Policy[& -\\{num}{0-9.*}]*', xx)

xx_substr <- substr(xx, yy[[1]][,1], yy[[1]][,1]+attr(yy[[1]], "match.length"))

xx <- gsub(xx_substr,
           paste0(xx_substr, ' \\hspace{1.5em}(maximizing sharing discernment)'),
           xx, fixed = TRUE)

yy <- gregexec('Restricted Targeted Policy[& -\\{num}{0-9.*}]*', xx)

xx_substr <- substr(xx, yy[[1]][,1], yy[[1]][,1]+attr(yy[[1]], "match.length"))

xx <- gsub(xx_substr,
           paste0(xx_substr, ' \\hspace{1.5em}(minimizing any false sharing)'),
           xx, fixed = TRUE)


writeLines(xx, '../tables/main_results.tex')


```

# Table 3: Response under counterfactual uniform respondent treatment
```{r policy_heterogeneity_combined, cache = TRUE, warning=FALSE, message = FALSE}

combined_df <- data.frame(
  combined = c(aipw_scores[,4] + aipw_scores[,1],
               aipw_scores[,5] + aipw_scores[,1]),
  condition = rep(4:5, each = nrow(df_eval)),
  optimal = rep(optimal_assignment, 2)
)


table <- {
  outcome <- 'combined'
  
  fmla0 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal) -1'))
  fmla1 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal)'))
  fmla2 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal==4) -1'))
  fmla3 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal==4)'))
  ns <- table(optimal_assignment)
  ols0 <- tidy(lm_robust(fmla0, data=combined_df))
  ols1 <- tidy(lm_robust(fmla1, data=combined_df))
  ols2 <- tidy(lm_robust(fmla2, data=combined_df))
  ols3 <- tidy(lm_robust(fmla3, data=combined_df))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate[1:2], -ols1$estimate[2],
                ols2$estimate[1:2], -ols3$estimate[2])
  est_std.err <- c(ols0$std.error[1:2], ols1$std.error[2],
                   ols2$std.error[1:2], ols3$std.error[2])
  p_value <- c(NA, NA, ols1$p.value[2],
               NA, NA, ols3$p.value[2])
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = c(rep(ns, each = 3)),
                      `Policy type` = c(rep('Accuracy nudge', 3), rep('Facebook tips', 3)),
                      Type = rep(0:2, times = 2),
                      check.names = FALSE)
  
  outdf
  
}

table_combined <- table %>% 
  mutate(
    term = paste0(`Policy type`, ': ', 
                  case_when(Type == 0 ~ 'Accuracy nudge',
                            Type == 1 ~ 'Facebook tips',
                            Type == 2 ~ 'Difference',
                            TRUE ~ 'Grand difference'))
  )

```

```{r policy_heterogeneity_any, cache = TRUE, warning=FALSE, message=FALSE}

any_df <- data.frame(
  any_false = c(aipw_scores_any_false[,4] + aipw_scores_any_false[,1],
                aipw_scores_any_false[,5] + aipw_scores_any_false[,1]),
  any_true = c(aipw_scores_any_true[,4] + aipw_scores_any_true[,1],
               aipw_scores_any_true[,5] + aipw_scores_any_true[,1]),
  condition = rep(4:5, each = nrow(df_eval)),
  optimal = rep(optimal_assignment, 2)
)

apply_mat <- expand.grid(stimuli_types)

table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  outcome <- paste0('any_', stimuli_type)
  
  fmla0 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal) -1'))
  fmla1 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal)'))
  fmla2 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal==4) -1'))
  fmla3 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal==4)'))
  ns <- table(optimal_assignment)
  ols0 <- tidy(lm_robust(fmla0, data=any_df))
  ols1 <- tidy(lm_robust(fmla1, data=any_df))
  ols2 <- tidy(lm_robust(fmla2, data=any_df))
  ols3 <- tidy(lm_robust(fmla3, data=any_df))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate[1:2], -ols1$estimate[2],
                ols2$estimate[1:2], -ols3$estimate[2])
  est_std.err <- c(ols0$std.error[1:2], ols1$std.error[2],
                   ols2$std.error[1:2], ols3$std.error[2])
  p_value <- c(NA, NA, ols1$p.value[2],
               NA, NA, ols3$p.value[2])
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = c(rep(ns, each = 3)),
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Policy type` = c(rep('Accuracy nudge', 3), rep('Facebook tips', 3)),
                      Type = rep(0:2, times = 2),
                      check.names = FALSE)
  
  outdf
  
})

table <- do.call(rbind, table)

table_any <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    term = paste0(`Policy type`, ': ', 
                  case_when(Type == 0 ~ 'Accuracy nudge',
                            Type == 1 ~ 'Facebook tips',
                            Type == 2 ~ 'Difference'))
  )

```




```{r policy_heterogeneity_channel, cache = TRUE, warning=FALSE, message=FALSE}
apply_mat <- expand.grid(stimuli_types, channel_types)

channel_df <- data.frame(
  channel_false_send = c(aipw_scores_send_false[,4] + aipw_scores_send_false[,1],
                         aipw_scores_send_false[,5] + aipw_scores_send_false[,1]),
  channel_false_timeline = c(aipw_scores_timeline_false[,4] + aipw_scores_timeline_false[,1],
                             aipw_scores_timeline_false[,5] + aipw_scores_timeline_false[,1]),
  channel_true_send = c(aipw_scores_send_true[,4] + aipw_scores_send_true[,1],
                        aipw_scores_send_true[,5] + aipw_scores_send_true[,1]),
  channel_true_timeline = c(aipw_scores_timeline_true[,4] + aipw_scores_timeline_true[,1],
                            aipw_scores_timeline_true[,5] + aipw_scores_timeline_true[,1]),
  condition = rep(4:5, each = nrow(df_eval)),
  optimal = rep(optimal_assignment, 2)
)

table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  channel <- x[2]
  outcome <- paste0('channel_', stimuli_type, '_', channel)
  
  fmla0 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal) -1'))
  fmla1 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal)'))
  fmla2 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal==4) -1'))
  fmla3 <- formula(paste(outcome, ' ~  factor(condition)*factor(optimal==4)'))
  ns <- table(optimal_assignment)
  ols0 <- tidy(lm_robust(fmla0, data=channel_df))
  ols1 <- tidy(lm_robust(fmla1, data=channel_df))
  ols2 <- tidy(lm_robust(fmla2, data=channel_df))
  ols3 <- tidy(lm_robust(fmla3, data=channel_df))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate[1:2], -ols1$estimate[2],
                ols2$estimate[1:2], -ols3$estimate[2])
  est_std.err <- c(ols0$std.error[1:2], ols1$std.error[2],
                   ols2$std.error[1:2], ols3$std.error[2])
  p_value <- c(NA, NA, ols1$p.value[2],
               NA, NA, ols3$p.value[2])
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = c(rep(ns, each = 3)),
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Channel` = channel,
                      `Policy type` = c(rep('Accuracy nudge', 3), rep('Facebook tips', 3)),
                      Type = rep(0:2, times = 2),
                      check.names = FALSE)
  
  outdf
  
})

table <- do.call(rbind, table)

table_channel <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    term = paste0(`Policy type`, ': ', 
                  case_when(Type == 0 ~ 'Accuracy nudge',
                            Type == 1 ~ 'Facebook tips',
                            Type == 2 ~ 'Difference'))
  )
```

```{r policy_heterogeneity_combined_tables, cache = TRUE, warning=FALSE, message=FALSE}
# Mean response estimates

models <- list(
  `Sharing\nDiscernment` = list(tidy = table_combined), 
  `False: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'False'),]),
  `False: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                         table_channel$Channel == 'send'),]),
  `False: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                        table_channel$Channel == 'timeline'),]),
  `True: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'True'),]),
  `True: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                        table_channel$Channel == 'send'),]),
  `True: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                       table_channel$Channel == 'timeline'),])
)

models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  x
})


rows <- as.data.frame(matrix(c('', '\\textbf{Sharing}', '', '\\textbf{False}', '', '', '\\textbf{True}', '',
                               '', '\\textbf{Discernment}', 'Any sharing', 'Messenger', 'Timeline', 'Any sharing', 'Messenger', 'Timeline',
                               'row3', rep('', 7),
                               'row8', rep('', 7),
                               'row11', rep('', 7),
                               'row16', rep('', 7)),
                             byrow = TRUE, ncol = 8
))

row3 <- paste0('\\cmidrule(lr){2-2} \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\multicolumn{4}{l}{\\textbf{Optimal assignment == Accuracy nudge (n = ', prettyNum(table(optimal_assignment)[1], big.mark = ","),
               ')}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\')
row8 <- '\\cmidrule(lr){2-8}'
row11 <- paste0('\\multicolumn{4}{l}{\\textbf{Optimal assignment == Facebook tips (n = ', prettyNum(table(optimal_assignment)[2], big.mark = ","),
                ')}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\')
row16 <- '\\cmidrule(lr){2-8}'

attr(rows, 'position') <- c(1,2,3,8,11,16)

xx <- modelsummary(models, 
                   # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL,
                   coef_rename = c('Accuracy nudge: Accuracy nudge' = r'(\hspace{1em}Accuracy)',
                                   'Accuracy nudge: Facebook tips' = r'(\hspace{1em}Facebook Tips)',
                                   'Accuracy nudge: Difference' = r'(\hspace{1em}Difference)',
                                   'Facebook tips: Accuracy nudge' = r'(\hspace{1em} Accuracy)',
                                   'Facebook tips: Facebook tips' = r'(\hspace{1em} Facebook Tips)',
                                   'Facebook tips: Difference' = r'(\hspace{1em} Difference)'),
                   output = 'latex_tabular')

xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '', xx[1], fixed = TRUE)

xx <- gsub('\nrow3 &  &  &  &  &  &  & \\\\', 
           row3, xx, fixed = TRUE)
xx <- gsub('\nrow8 &  &  &  &  &  &  & \\\\', 
           row8, xx, fixed = TRUE)
xx <- gsub('\nrow11 &  &  &  &  &  &  & \\\\', 
           row11, xx, fixed = TRUE)
xx <- gsub('\nrow16 &  &  &  &  &  &  & \\\\', 
           row16, xx, fixed = TRUE)

writeLines(xx, '../tables/heterogeneity_policy.tex')

```



# Figure 3: Selected covariate means by restricted optimal policy assignment
```{r covariates_in_optimal}

.df <- df_eval %>% 
  mutate(leaf = optimal_assignment) %>% 
  group_by(leaf) %>% 
  mutate(leaf = factor(paste0(leaf, "\n ", "(n = ", prettyNum(n(), big.mark = ",") , ")"))) %>% 
  as.data.frame() 

covs_of_interest <- c('age', 'dli', 'male', 'pol', 'science')
plot_covariate_means_by_group(
  .df,
  .title = NULL,
  rowvars = covs_of_interest)

ggsave('../figures/covariate_optimal.png', 
       width = 6.25, height = 4)

```

# Table S1: Comparing Facebook and Afrobarometer samples

```{r ABdata, cache = TRUE, warning=FALSE, message=FALSE}
files <- list.files('../data', 
                    pattern = '^cleaned-data-AB.*rds$', 
                    full.names = TRUE)

(INPUT_FILENAME <- files[which.max(file.info(files)$mtime)])
df_fb <- readRDS(INPUT_FILENAME)
df_fb <- df_fb[which(df_fb$attrited == 0),]

# Use AB recoded versions of hhi pol
df_fb$hhi <- df_fb$hhi_AB
df_fb$pol <- df_fb$pol_AB

## get variables of interest in survey data ## 
# get variables want to compare - #AB col names for corresponding variables in comments
compare_cols <- c('male', #Q101
                  'age', #Q1 
                  'ed', #Q97 - same levels (1-10)
                  'urban', #URBRUR
                  'rel_christian', 'rel_muslim', #Q98 - need to code categories
                  'hhi', #Q89A-F = own index (0-6) 
                  'cash', #Q94
                  'pol', # feel close to = Q88A/Q88B(which), voted for <-  AB asks prospective voting... so can just use same question and note diff in fn of table
                  'country')


## get Afrobarometer data from kenya/nigeria and demographic vars want to compare ##

# load afrobarometer data (download merged R7 dataset from afrobarometer.org)
ab_dat <- read.spss("../data/r7_merged_data_34ctry_release.sav", to.data.frame=TRUE)

# subset to Kenya and Nigeria #
ab <- ab_dat[ab_dat$COUNTRY %in% c("Kenya","Nigeria"),]

# clean ab variables of interest #
ab$male <- ifelse(ab$Q101 == "Male",1,0)

ab$age <- as.numeric(as.character(ab$Q1))

ab$ed <- ifelse(ab$Q97 %in% c("Refused","Don’t know","Missing"),NA,as.numeric(ab$Q97)-1)

ab$urban <- ifelse(ab$URBRUR=="Urban",1,0)

ab$rel_christian <- ifelse(ab$Q98 %in% c("Christian only","Roman Catholic","Pentecostal",
                                         "Anglican","Seventh Day Adventist",
                                         "Evangelical","Presbyterian","Methodist","Orthodox",
                                         "Baptist","Church of Christ","Zionist Christian Church",
                                         "Lutheran"),1,0)

ab$rel_muslim <- ifelse(ab$Q98 %in% c("Muslim only","Sunni only","Tijaniya Brotherhood","Shia",
                                      "Ismaeli","Mouridiya Brotherhood","Qadiriya Brotherhood"),1,0)

# for all index items == 1 if "Yes, someone else owns" / "Yes, do own", 0 otherwise

hhi_cols <- c(
  'Q89A',
  'Q89B',
  'Q89C',
  'Q89D',
  'Q89E',
  'Q89F'
)

ab$hhi <- rowSums(as.data.frame(lapply(ab[hhi_cols], function(x) {ifelse(x %in% c("Yes, someone else owns","Yes, do own"),1,0)})))

ab$cash <- ifelse(ab$Q94 %in% c("Yes, part time","Yes, full time"),1,0) # coding yes partime or fulltime as 1 here (not sure what done in our coding)

ab$pol <- ifelse(ab$COUNTRY=="Nigeria" & ab$Q88B=="All Progressive Congres (APC)" |
                   ab$COUNTRY=="Kenya" & ab$Q88B=="Jubilee Alliance Party (JAP)/Jubilee Party",1,0)

# add country variable
df_fb$country <- ifelse(df_fb$nigeria ==1 , "Nigeria", "Kenya")
ab$country <- ab$COUNTRY

# subset experimental + AB data to variables of interest
df_treat_dem <- df_fb[,c(compare_cols, 'batch')]
ab_dem <- ab[,(compare_cols)]

# ad label for data set
df_treat_dem$df <- "Facebook sample"
ab_dem$df <- "Afrobarometer sample"


# merge AB + our data
ab.fb <- smartbind(df_treat_dem,ab_dem)

nvals <- ab.fb %>% 
  group_by(country, df, batch == 5) %>% 
  count()

## KENYA TABLE ##
baltest_out_KY <- ab.fb %>% filter(country == "Kenya") %>%
  gather(key = var, value = outcome, -country,-df, -batch) %>%
  group_by(var) %>%
  do({
    ## Run t-test of mean balance
    t_out <- try(t.test(outcome ~ df, data = .), silent = TRUE)
    t_out_split <- try(t.test(outcome ~ (batch == 5), data = .), silent = TRUE)
    stderr <- tapply(.$outcome,.$df, function(x) sd(x, na.rm = TRUE)/sqrt(length(x)))
    stderr_split <- tapply(.$outcome,.$df, function(x) sd(x, na.rm = TRUE)/sqrt(length(x)))
    data.frame(
      mean_group1 = t_out$estimate[1], mean_group2 = t_out$estimate[2],
      diff_means = t_out$estimate[2]-t_out$estimate[1],
      sd1 = stderr[1],
      sd2 = stderr[2],
      pvalue = t_out$p.value,
      learning_mean = t_out_split$estimate[1],
      evaluation_mean = t_out_split$estimate[2],
      sd1_split = stderr_split[1],
      sd2_split = stderr_split[2]
    )
  }) 

baltest_out_KY$var <- c("age","has cash income","education level","household asset index",
                        "male","supports governing party","christian","muslim","urban")

## NIGERIA TABLE ##
baltest_out_NG <- ab.fb %>% filter(country == "Nigeria") %>%
  gather(key = var, value = outcome, -country,-df, -batch) %>%
  group_by(var) %>%
  do({
    ## Run t-test of mean balance
    t_out <- try(t.test(outcome ~ df, data = .), silent = TRUE)
    t_out_split <- try(t.test(outcome ~ (batch == 5), data = .), silent = TRUE)
    stderr <- tapply(.$outcome,.$df, function(x) sd(x, na.rm = TRUE)/sqrt(length(x)))
    stderr_split <- tapply(.$outcome,.$df, function(x) sd(x, na.rm = TRUE)/sqrt(length(x)))
    data.frame(
      mean_group1 = t_out$estimate[1], mean_group2 = t_out$estimate[2],
      diff_means = t_out$estimate[2]-t_out$estimate[1],
      sd1 = stderr[1],
      sd2 = stderr[2],
      pvalue = t_out$p.value,
      learning_mean = t_out_split$estimate[1],
      evaluation_mean = t_out_split$estimate[2],
      sd1_split = stderr_split[1],
      sd2_split = stderr_split[2]
    )
  }) 

baltest_out_NG$var <- c("age","has cash income","education level","household asset index",
                        "male","supports governing party","christian","muslim","urban")

## make latex tables
#kenya
baltest_out_KY %>% 
  ungroup() %>% 
  mutate(var = c('Age', 'Has cash income', 'Education level', 'Index of household possessions', 'Male', 'Supports governing party', 'Christian', 'Muslim', 'Urban')) %>% 
  select(var, learning_mean, sd1_split, evaluation_mean, sd2_split, mean_group2, sd2, mean_group1, sd1, diff_means) %>%
  kbl(align = c('r','c','c','c','c|', 'c','c','c','c','c'),
      format = "latex",
      booktabs = TRUE,
      toprule = NULL, 
      bottomrule = paste('n', prettyNum(nvals[nvals[,'country']=='Kenya','n', drop =TRUE][2], big.mark = ','),
                         ' ',
                         prettyNum(nvals[nvals[,'country']=='Kenya','n', drop =TRUE][3], big.mark = ','),
                         ' ',
                         prettyNum(nvals[nvals[,'country']=='Kenya','n', drop =TRUE][2] + 
                                     nvals[nvals[,'country']=='Kenya','n', drop =TRUE][3], big.mark = ','),
                         '',
                         prettyNum(nvals[nvals[,'country']=='Kenya','n', drop =TRUE][1], big.mark = ','), 
                         ' ', ' ',
                         sep = ' & '),
      midrule = '\\cmidrule(lr){2-2}  \\cmidrule(lr){3-3}  \\cmidrule(lr){4-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-7} \\cmidrule(lr){8-8} \\cmidrule(lr){9-9} \\cmidrule(lr){10-10}',
      linesep = '',
      col.names = c('', 'Learning Mean', 'Learning SE', 'Evaluation Mean', 'Evaluation SE' , 'Overall Facebook Mean', 'Facebook SE', 'Afrobarometer Mean', 'Afrobarometer SE', 'Difference'),
      digits =2,
      table.envir = NULL) %>%
  writeLines('../tables/abKY.tex')

#nigeria
baltest_out_NG %>% 
  ungroup() %>% 
  mutate(var = c('Age', 'Has cash income', 'Education level', 'Index of household possessions', 'Male', 'Supports governing party', 'Christian', 'Muslim', 'Urban')) %>% 
  select(var, learning_mean, sd1_split, evaluation_mean, sd2_split, mean_group2, sd2, mean_group1, sd1, diff_means) %>%
  kbl(align = c('r','c','c','c','c|', 'c','c','c','c','c'),
      format = "latex",
      booktabs = TRUE,
      toprule = NULL, 
      bottomrule = paste('N', prettyNum(nvals[nvals[,'country']=='Nigeria','n', drop =TRUE][2], big.mark = ','),
                         ' ',
                         prettyNum(nvals[nvals[,'country']=='Nigeria','n', drop =TRUE][3], big.mark = ','),
                         ' ',
                         prettyNum(nvals[nvals[,'country']=='Nigeria','n', drop =TRUE][2] + 
                                     nvals[nvals[,'country']=='Nigeria','n', drop =TRUE][3], big.mark = ','),
                         '',
                         prettyNum(nvals[nvals[,'country']=='Nigeria','n', drop =TRUE][1], big.mark = ','), 
                         ' ', ' ',
                         sep = ' & '),
      midrule = '\\cmidrule(lr){2-2}  \\cmidrule(lr){3-3}  \\cmidrule(lr){4-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-7} \\cmidrule(lr){8-8} \\cmidrule(lr){9-9} \\cmidrule(lr){10-10}',
      linesep = '',
      col.names = c('', 'Learning Mean', 'Learning SE', 'Evaluation Mean', 'Evaluation SE' , 'Overall Facebook Mean', 'Facebook SE', 'Afrobarometer Mean', 'Afrobarometer SE', 'Difference'),
      digits =2,
      table.envir = NULL) %>% 
  writeLines('../tables/abNG.tex')

```

# Table S2: Shares of pre-test stimuli across timeline and Messenger by batch

```{r batchwise_shares}
cbind(0:4, matrix(prop.table(table(df_treat$pre_false, df_treat$batch), margin = 2), nrow = 5)) %>% 
  kbl(align = c('r','c','c','c','c', 'c'),
      format = "latex",
      booktabs = TRUE,
      toprule = NULL, 
      bottomrule = paste0(c('N', prettyNum(table(df_treat$batch), big.mark = ',')), collapse = ' & '),
      midrule = ' \\cmidrule(lr){2-2}  \\cmidrule(lr){3-3}  \\cmidrule(lr){4-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} ',
      linesep = '',
      col.names = c('Shares', 'Batch 1', 'Batch 2', 'Batch 3', 'Batch 4' , 'Batch 5'),
      digits =2,
      table.envir = NULL) %>% 
  writeLines('../tables/false_shares_batchwise.tex')

cbind(0:4, matrix(prop.table(table(df_treat$pre_true, df_treat$batch), margin = 2), nrow = 5)) %>% 
  kbl(align = c('r','c','c','c','c', 'c'),
      format = "latex",
      booktabs = TRUE,
      toprule = NULL, 
      bottomrule = paste0(c('N', prettyNum(table(df_treat$batch), big.mark = ',')), collapse = ' & '),
      midrule = ' \\cmidrule(lr){2-2}  \\cmidrule(lr){3-3}  \\cmidrule(lr){4-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} ',
      linesep = '',
      col.names = c('Shares', 'Batch 1', 'Batch 2', 'Batch 3', 'Batch 4' , 'Batch 5'),
      digits =2,
      table.envir = NULL) %>% 
  writeLines('../tables/true_shares_batchwise.tex')

```
# Figure S3: Cumulative treatment assignment in learning phase

```{r assignment_on_time_simple, cache=TRUE}
xx <- sapply(WH_idx[[1]], function(x) ws_learn %in% x)
xx <- apply(xx, 2, cumsum)
xx <- reshape(data.frame(xx), direction = 'long', varying = 1:8, 
              v.names = "Cumulative assignment counts",
              idvar = "Total observations",
              timevar = "Factor level")
xx$`Factor level` <- factor(xx$`Factor level`, 
                            labels = WCR_terms)

ggplot(data = xx[which(xx$`Total observations`<A),], aes(y = `Cumulative assignment counts`, 
                                                         x = `Total observations`, 
                                                         group = `Factor level`, 
                                                         color = `Factor level`)) + 
  geom_line() +
  ggtitle('Adaptive assignment, simple respondent treatments')  +
  scale_colour_manual(values = cbPalette[c(1:4, 6,5,7:8)]) +
  theme_minimal() +
  theme(panel.background = element_rect(fill = 'white'),
        plot.background = element_rect(fill = 'white', color = 'white'))
ggsave('../figures/respondent_base_assignment_on_time.png', width = 6, height = 4.5)



xx <- sapply(WR_idx[[1]], function(x) ws_learn %in% x)
xx <- apply(xx, 2, cumsum)
xx <- reshape(data.frame(xx), direction = 'long', varying = 1:5, 
              v.names = "Cumulative assignment counts",
              idvar = "Total observations",
              timevar = "Factor level")
xx$`Factor level` <- factor(xx$`Factor level`, 
                            labels = WCH_terms)


ggplot(data = xx[which(xx$`Total observations`<A),], aes(y = `Cumulative assignment counts`, 
                                                         x = `Total observations`, 
                                                         group = `Factor level`, 
                                                         color = `Factor level`)) + 
  geom_line() +
  ggtitle('Adaptive assignment, simple headline treatments') +
  scale_colour_manual(values = cbPalette[c(1:4, 6,5,7:8)]) +
  theme_minimal() +
  theme(panel.background = element_rect(fill = 'white'),
        plot.background = element_rect(fill = 'white', color = 'white'))
ggsave('../figures/headline_base_assignment_on_time.png', width = 6, height = 4.5)


```



# Table S6:  Evolution of on-policy probabilities during learning stage
```{r arm_assignment, warning=FALSE, message=FALSE}

gg_df <- tibble(batch = df_learn$batch,
                y_on = ifelse(predict(cf.priority, xs_learn)$predictions<0, probs_ralt[,2], probs_ralt[,7]),
                optimal_learned = case_when(df_learn$optimal0 == 6 ~ 2,
                                            df_learn$optimal0 == 8 ~ 4, 
                                            df_learn$optimal0 == 11 ~ 7,
                                            df_learn$optimal0 == 12 ~ 8),
                optimal_restricted = ifelse(predict(cf.priority, xs_learn)$predictions<0,2,7), 
                y_learned = probs_ralt[cbind(1:nrow(probs_ralt), optimal_learned )])

new_gg <- list(
  `Learned` = list(tidy = tidy(lm_robust(y_on ~ as.factor(batch) -1, data = gg_df))),
  `Restricted` = list(tidy = tidy(lm_robust(y_learned ~ as.factor(batch) -1, data = gg_df))))

new_gg <- lapply(new_gg, function(x){
  class(x) <- "modelsummary_list"
  # pvals <- x$tidy[,x$pval]
  # pvals[length(pvals)] <- NA
  # x$tidy$p.value <- pvals
  x
})

xx <- modelsummary(new_gg, 
                   stars = FALSE,  
                   escape = FALSE,
                   col.names = NULL, 
                   coef_rename = paste('Batch', 1:4),
                   gof_omit = '.*',
                   output = 'latex_tabular')

xx <- gsub('\\toprule', ' & \\textbf{Learned}& \\textbf{Restricted} \\\\ \n \\cmidrule(lr){2-2} \\cmidrule(lr){3-3}', xx[1], fixed = TRUE)

writeLines(xx, '../tables/on_policy.tex')

```

# Table S7 & S8: Interaction Effects

```{r interaction_effects}

# compare interaction to Headline average
headline_comparisons <- lapply(WCH_terms, function(x){
  diff <- df_grid[which(df_grid$Headline == x & df_grid$level == 'Interactions: Respondent x headline'), 'estimate'] - df_grid[which(df_grid$Headline == x & df_grid$level == 'Headline: Respondent equally weighted'), 'estimate']
  se_diff <- sqrt(df_grid[which(df_grid$Headline == x & df_grid$level == 'Interactions: Respondent x headline'), 'std.error']^2 + df_grid[which(df_grid$Headline == x & df_grid$level == 'Headline: Respondent equally weighted'), 'std.error']^2)
  data.frame(estimate= diff, std.error = se_diff, col = x, term = df_grid[which(df_grid$Headline == x & df_grid$level == 'Interactions: Respondent x headline'),'Respondent'], 
             p.value = 2*(pt(abs(diff/se_diff), df = nrow(df_eval)-1, lower = FALSE)))
})

headline_comparisons <- lapply(headline_comparisons, function(x){
  x <- list(tidy = x)
  class(x) <- "modelsummary_list"
  x
})


xx <- modelsummary(headline_comparisons, 
                   # stars = TRUE,  
                   escape = FALSE,
                   col.names = NULL, 
                   gof_omit = '.*',
                   output = 'latex_tabular')

xx <- gsub('\\toprule', paste0(paste0(' & \\textbf{', WCH_terms, '}', collapse = ''), 
                               '\\\\ \n \\cmidrule(lr){2-2} \\cmidrule(lr){3-3}\\cmidrule(lr){4-4}\\cmidrule(lr){5-5}\\cmidrule(lr){6-6}'), xx[1], fixed = TRUE)

writeLines(xx, '../tables/learning_interactions_headline.tex')

respondent_comparisons <- lapply(WCR_terms, function(x){
  diff <- df_grid[which(df_grid$Respondent == x & df_grid$level == 'Interactions: Respondent x headline'), 'estimate'] - df_grid[which(df_grid$Respondent == x & df_grid$level == 'Respondent: Headline equally weighted'), 'estimate']
  se_diff <- sqrt(df_grid[which(df_grid$Respondent == x & df_grid$level == 'Interactions: Respondent x headline'), 'std.error']^2 + df_grid[which(df_grid$Respondent == x & df_grid$level == 'Respondent: Headline equally weighted'), 'std.error']^2)
  data.frame(estimate= diff, 
             std.error = se_diff, 
             col = x, term = df_grid[which(df_grid$Respondent == x & df_grid$level == 'Interactions: Respondent x headline'),'Headline'], 
             p.value = 2*(pt(abs(diff/se_diff), df = nrow(df_eval)-1, lower = FALSE)) )
})


respondent_comparisons <- lapply(respondent_comparisons, function(x){
  x <- list(tidy = x)
  class(x) <- "modelsummary_list"
  x
})

xx <- modelsummary(respondent_comparisons, 
                   # stars = TRUE,  
                   escape = FALSE,
                   col.names = NULL, 
                   gof_omit = '.*',
                   output = 'latex_tabular')

xx <- gsub('\\toprule', paste0(paste0(' & \\textbf{', WCR_terms, '}', collapse = ''), 
                               '\\\\ \n \\cmidrule(lr){2-2} \\cmidrule(lr){3-3}\\cmidrule(lr){4-4}\\cmidrule(lr){5-5}\\cmidrule(lr){6-6}\\cmidrule(lr){7-7}\\cmidrule(lr){8-8}\\cmidrule(lr){9-9}'), xx[1], fixed = TRUE)

writeLines(xx, '../tables/learning_interactions_respondent.tex')

```



# Figure S4: Selected covariate means by learned optimal policy assignment
```{r covariates_in_optimal_learned, cache = TRUE}

.df <- df_eval %>% 
  mutate(leaf = factor(optimal_assignment_original,
                       labels = c('Optimal policy == accuracy',
                                  'Optimal policy == FB tips',
                                  'Optimal policy == other'))) %>% 
  group_by(leaf) %>% 
  mutate(leaf = factor(paste0(leaf, "\n ", "(n = ", prettyNum(n(), big.mark = ",") , ")"))) %>% 
  as.data.frame() 

covs_of_interest <- c('age', 'dli', 'male', 'pol', 'science')
plot_covariate_means_by_group(
  .df,
  .title = NULL,
  rowvars = covs_of_interest)

ggsave('../figures/covariate_optimal_original.png', 
       width = 6.25, height = 4)

```


# Figure S5: RATE
```{r RATE_accuracy_vs_facebook, cache=TRUE, warning=FALSE, message=FALSE}

# Compute a prioritization based on estimated treatment effects.
test_idx <- ws_eval %in%c(4,5)
priority.cate <- predict(cf.priority, xs_eval[test_idx,])$predictions

# Estimate AUTOC on held out data.
cf.eval <- causal_forest(
  X = xs_eval[test_idx,], 
  Y = -df_eval$post_false_prop[test_idx], 
  W = 1*(ws_eval[test_idx]==4), 
  W.hat = rowSums(probs_eval[test_idx, c(6), drop = FALSE])/rowSums(probs_eval[test_idx, c(6, 11)]),
  sample.weights = balwts_uncens[test_idx],
)
rate <- rank_average_treatment_effect(cf.eval, priority.cate, 
                                      q = seq(0.01, 1, by = 0.01))
rate

ggplot(rate$TOC, aes(x = q, y = estimate)) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey60") + 
  geom_line() + 
  geom_ribbon(aes(ymax =  estimate + 1.96 *std.err, 
                  ymin =  estimate - 1.96 *std.err), alpha = .1, fill = cbPalette[7]) +
  theme_minimal() + 
  scale_x_continuous(limits = c(0.1, 1), breaks = seq(0.2, 1, 0.1)) + 
  coord_cartesian(ylim = c(-0.1, 0.05)) + 
  scale_y_continuous(breaks= seq(-0.1, 0.1, 0.05)) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.background = element_rect(fill = 'white'),
    plot.background = element_rect(fill = 'white', color = 'white'),
    axis.title.y = element_text(vjust = 0.65), 
    panel.grid.minor.x = element_blank()) + 
  labs(title = "Targeting Operator Characteristic,\nAccuracy nudge vs. Facebook tips", 
       y = "Estimate", 
       x = "Proportion of the population assigned accuracy nudge as compared to Facebook tips"
       #, subtitle = "Shaded region shows 95% CI"
  )

ggsave('../figures/rate_accuracy_vs_facebook.png', height = 5, width = 8)

# Benefit at 30%

rate$TOC[which(rate$TOC$q == 0.3),]
```



# Table S9: Alternative specifications
```{r additional_scores, cache = TRUE}
# shorthand for treatments
ws_original <- as.factor(case_when(ws_eval == 1 ~ 1,
                                   ws_eval == optimal_assignment_original ~ 2,
                                   TRUE ~ 3))

ws_restricted <- as.factor(case_when(ws_eval == 1 ~ 1,
                                     ws_eval == optimal_assignment ~ 2,
                                     TRUE ~ 3))

df_eval0 <- df_treat[which(df_treat$batch == 5),]

ws_eval0 <- as.factor(case_when(as.numeric(df_eval0$W) == 1 ~ 1, # control
                                     as.numeric(df_eval0$W) == 2 ~  2, # headline fact check,
                                     as.numeric(df_eval0$W) == 5 ~ 3, # headline related,
                                     as.numeric(df_eval0$W) == 6 ~ 4, # respondent accuracy
                                     as.numeric(df_eval0$W) == 11 ~ 5, # facebook tips,
                                     # combine optimal with small groups
                                     TRUE ~ 6 # other optimal respondent (8/12)
)) 

# get appropriate balwts


# factors for assignment or missing
treat_uncens_learned <- factor(
  case_when(
    df_eval0$attrited == 0  ~ 
      as.numeric(case_when(ws_eval0 == 1 ~ 1,
                           as.numeric(df_eval0$W) == df_eval0$optimal0 ~ 2,
                           TRUE ~ 3)),
    TRUE ~ 4))

# probability of getting assignment AND responding
treat_uncens_prob_learned <- probability_forest(X = as.matrix(df_eval0[,c(context_cols, predv_cols)]),
                                                Y = treat_uncens_learned)$predictions[which(df_eval0$attrited == 0),]

# inverse probabilities to get balwts
balwts_treat_uncens_learned <- (1/treat_uncens_prob_learned)[cbind(1:nrow(treat_uncens_prob_learned), treat_uncens_learned[which(df_eval0$attrited == 0)])]
# # trim balwts
balwts_treat_uncens_learned[which(balwts_treat_uncens_learned>quantile(balwts_treat_uncens_learned, .999))] <- quantile(balwts_treat_uncens_learned, .999)




# factors for assignment or missing
treat_uncens_restricted <- factor(
  case_when(
    df_eval0$attrited == 0 ~ as.numeric(case_when(ws_eval0 == 1 ~ 1,
                                                                                         ws_eval0 == ifelse(predict(cf.priority, df_eval0[, c(context_cols, predv_cols)])$predictions<0,4,5) ~ 2,
                                                                                         TRUE ~ 3)),
                                            TRUE ~ 4))
# probability of getting assignment AND responding
treat_uncens_prob_restricted <- probability_forest(X = as.matrix(df_eval0[, c(context_cols, predv_cols)]),
                                                   Y = treat_uncens_restricted)$predictions[which(df_eval0$attrited == 0),]

# inverse probabilities to get balwts
balwts_treat_uncens_restricted<- (1/treat_uncens_prob_restricted)[cbind(1:nrow(treat_uncens_prob_restricted), treat_uncens_restricted[which(df_eval0$attrited == 0)])]
# trim balwts
balwts_treat_uncens_restricted[which(balwts_treat_uncens_restricted>quantile(balwts_treat_uncens_restricted, .999))] <- quantile(balwts_treat_uncens_restricted, .999)


# with no pre-test
if(file.exists('objects/aipw_scores_nopretest.RDS')){ # read in scores if already generated
  aipw_scores_nopretest.RDS <- readRDS('objects/aipw_scores_nopretest.RDS')
  
}else{
  aipw_scores_nopretest <- aw_scores_eval(xs = xs_eval[,-which(grepl('strat', colnames(xs_eval)))],
                                          yobs = yobs_eval, 
                                          ws = ws_eval, 
                                          sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_nopretest, 'objects/aipw_scores_nopretest.RDS')
  
}

# learned optimal policy
if(file.exists('objects/aipw_scores_learned_nopretest.RDS')){ # read in scores if already generated
  aipw_scores_learned_nopretest <- readRDS('objects/aipw_scores_learned_nopretest.RDS')
  
}else{
  aipw_scores_learned_nopretest <- aw_scores_eval(xs = xs_eval[,-which(grepl('strat', colnames(xs_eval)))],
                                                  yobs = yobs_eval, 
                                                  ws = ws_original,
                                                  sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_learned_nopretest, 'objects/aipw_scores_learned_nopretest.RDS')
  
}

# restricted optimal policy
if(file.exists('objects/aipw_scores_restricted_nopretest.RDS')){ # read in scores if already generated
  aipw_scores_restricted_nopretest <- readRDS('objects/aipw_scores_restricted_nopretest.RDS')
  
}else{
  aipw_scores_restricted_nopretest <- aw_scores_eval(xs = xs_eval[,-which(grepl('strat', colnames(xs_eval)))],
                                                     yobs = yobs_eval, 
                                                     ws = ws_restricted,
                                                     sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_restricted_nopretest, 'objects/aipw_scores_restricted_nopretest.RDS')
}

# with no covariates
if(file.exists('objects/aipw_scores_nocovariates.RDS')){ # read in scores if already generated
  aipw_scores_nocovariates.RDS <- readRDS('objects/aipw_scores_nocovariates.RDS')

}else{
  aipw_scores_nocovariates <- aw_scores(yobs = yobs_eval,
                                        ws = ws_eval,
                                        balwts = balwts_treat_uncens,
                                        K = length(unique(ws_eval)))
  aipw_scores_nocovariates <- cbind(aipw_scores_nocovariates[,1], aipw_scores_nocovariates[,-1]-aipw_scores_nocovariates[,1])

  saveRDS(aipw_scores_nocovariates, 'objects/aipw_scores_nocovariates.RDS')

}

# learned optimal policy
if(file.exists('objects/aipw_scores_learned_nocovariates.RDS')){ # read in scores if already generated
  aipw_scores_learned_nocovariates <- readRDS('objects/aipw_scores_learned_nocovariates.RDS')

}else{
  aipw_scores_learned_nocovariates <- aw_scores(yobs = yobs_eval,
                                                ws = ws_original,
                                                balwts = balwts_treat_uncens_learned,
                                                K = length(unique(ws_original)))

  aipw_scores_learned_nocovariates <- cbind(aipw_scores_learned_nocovariates[,1], aipw_scores_learned_nocovariates[,-1]-aipw_scores_learned_nocovariates[,1])

  saveRDS(aipw_scores_learned_nocovariates, 'objects/aipw_scores_learned_nocovariates.RDS')

}

# restricted optimal policy
if(file.exists('objects/aipw_scores_restricted_nocovariates.RDS')){ # read in scores if already generated
  aipw_scores_restricted_nocovariates <- readRDS('objects/aipw_scores_restricted_nocovariates.RDS')

}else{


  aipw_scores_restricted_nocovariates <- aw_scores(yobs = yobs_eval,
                                                   ws = ws_restricted,
                                                   balwts = balwts_treat_uncens_restricted,
                                                   K = length(unique(ws_restricted)))

  aipw_scores_restricted_nocovariates <- cbind(aipw_scores_restricted_nocovariates[,1], aipw_scores_restricted_nocovariates[,-1]-aipw_scores_restricted_nocovariates[,1])

  saveRDS(aipw_scores_restricted_nocovariates, 'objects/aipw_scores_restricted_nocovariates.RDS')
}




if(file.exists('objects/aipw_scores_unbalanced.RDS')){ # read in scores if already generated
  aipw_scores_unbalanced <- readRDS('objects/aipw_scores_unbalanced.RDS')
  
}else{
  aipw_scores_unbalanced <- aw_scores_eval(xs = xs_eval,
                                           yobs = yobs_eval, 
                                           ws = ws_eval)
  
  saveRDS(aipw_scores_unbalanced, 'objects/aipw_scores_unbalanced.RDS')
  
}

# learned optimal policy
if(file.exists('objects/aipw_scores_learned_unbalanced.RDS')){ # read in scores if already generated
  aipw_scores_learned_unbalanced <- readRDS('objects/aipw_scores_learned_unbalanced.RDS')
  
}else{
  aipw_scores_learned_unbalanced <- aw_scores_eval(xs = xs_eval,
                                                   yobs = yobs_eval, 
                                                   ws = ws_original)
  
  saveRDS(aipw_scores_learned_unbalanced, 'objects/aipw_scores_learned_unbalanced.RDS')
  
}

# restricted optimal policy
if(file.exists('objects/aipw_scores_restricted_unbalanced.RDS')){ # read in scores if already generated
  aipw_scores_restricted_unbalanced <- readRDS('objects/aipw_scores_restricted_unbalanced.RDS')
  
}else{
  aipw_scores_restricted_unbalanced <- aw_scores_eval(xs = xs_eval,
                                                      yobs = yobs_eval, 
                                                      ws = ws_restricted)
  
  saveRDS(aipw_scores_restricted_unbalanced, 'objects/aipw_scores_restricted_unbalanced.RDS')
  
}


if(file.exists('objects/aipw_scores_imputed.RDS')){ # read in scores if already generated
  aipw_scores_imputed <- readRDS('objects/aipw_scores_imputed.RDS')
  
}else{
  
  aipw_scores_imputed <- aw_scores_eval(
    xs = as.matrix(df_treat[which(df_treat$batch == 5), c(context_cols, predv_cols)]),
    yobs = df_treat[which(df_treat$batch == 5),'Y'],
    ws = as.factor(case_when(as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 1 ~ 1, # control
                             as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 2 ~  2, # headline fact check,
                             as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 5 ~ 3, # headline related,
                             as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 6 ~ 4, # respondent accuracy
                             as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 11 ~ 5, # facebook tips,
                             # combine optimal with small groups
                             TRUE ~ 6 # other optimal respondent (8/12)
    ))
  )
  
  saveRDS(aipw_scores_imputed, 'objects/aipw_scores_imputed.RDS')
  
}

# learned optimal policy
if(file.exists('objects/aipw_scores_learned_imputed.RDS')){ # read in scores if already generated
  aipw_scores_learned_imputed <- readRDS('objects/aipw_scores_learned_imputed.RDS')
  
}else{
  aipw_scores_learned_imputed <- aw_scores_eval(
    xs = as.matrix(df_treat[which(df_treat$batch == 5), c(context_cols, predv_cols)]),
    yobs = df_treat[which(df_treat$batch == 5),'Y'], 
    ws = 
      as.factor(case_when(as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 1 ~ 1,
                          as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 
                            df_treat[which(df_treat$batch == 5),'optimal0'] ~ 2,
                          TRUE ~ 3))
  )
  
  saveRDS(aipw_scores_learned_imputed, 'objects/aipw_scores_learned_imputed.RDS')
  
}

# restricted optimal policy
if(file.exists('objects/aipw_scores_restricted_imputed.RDS')){ # read in scores if already generated
  aipw_scores_restricted_imputed <- readRDS('objects/aipw_scores_restricted_imputed.RDS')
  
}else{
  aipw_scores_restricted_imputed <- aw_scores_eval(
    xs = as.matrix(df_treat[which(df_treat$batch == 5), c(context_cols, predv_cols)]),
    yobs = df_treat[which(df_treat$batch == 5),'Y'], 
    ws = 
      as.factor(case_when(as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 1 ~ 1,
                          as.numeric(df_treat[which(df_treat$batch == 5),'W']) == 
                            ifelse(predict(
                              cf.priority, 
                              as.matrix(df_treat[which(df_treat$batch == 5), c(context_cols, predv_cols)])
                            )$predictions<0, 6, 11) ~ 2,
                          TRUE ~ 3))
  )
  
  saveRDS(aipw_scores_restricted_imputed, 'objects/aipw_scores_restricted_imputed.RDS')
  
}


# Adjust scores for differences between learning and evaluation splits;
# target is eval pop reweighted to learning distribution
ws_learn_eval <- rep(1, N)
ws_learn_eval[1:A] <- 0 # 0 for learning, 1 for evaluation split
learn_eval_forest <- multi_arm_causal_forest(X = rbind(xs_learn, xs_eval), 
                                             Y = c(yobs_learn, yobs_eval), 
                                             W = as.factor(ws_learn_eval))
probs_adjusted <- learn_eval_forest$W.hat

# probability of being in your own split over probability of being in learning split
# Weight is 1 for observations in the learning split
what_eval_adjustment <- (probs_adjusted[matrix(c(1:N, ws_learn_eval+1), ncol = 2)]/probs_adjusted[,1])[(A+1):N]
# Standardize to appropriate group size
what_eval_adjustment <- what_eval_adjustment*(N-A)/sum(what_eval_adjustment)


if(file.exists('objects/aipw_scores_eval_adjusted.RDS')){ # read in scores if already generated
  aipw_scores_adjusted <- readRDS('objects/aipw_scores_eval_adjusted.RDS')
  
}else{
  aipw_scores_adjusted <- aw_scores_eval(xs = xs_eval,
                                         yobs = yobs_eval, 
                                         ws = ws_eval, 
                                         sample.weights = what_eval_adjustment)
  
  saveRDS(aipw_scores_adjusted, 'objects/aipw_scores_eval_adjusted.RDS')
}


# learned optimal policy
if(file.exists('objects/aipw_scores_learned_adjusted.RDS')){ # read in scores if already generated
  aipw_scores_learned_adjusted <- readRDS('objects/aipw_scores_learned_adjusted.RDS')
  
}else{
  aipw_scores_learned_adjusted <- aw_scores_eval(xs = xs_eval,
                                                 yobs = yobs_eval, 
                                                 ws = ws_original, 
                                                 sample.weights = what_eval_adjustment)
  
  saveRDS(aipw_scores_learned_adjusted, 'objects/aipw_scores_learned_adjusted.RDS')
  
}

# restricted optimal policy
if(file.exists('objects/aipw_scores_restricted_adjusted.RDS')){ # read in scores if already generated
  aipw_scores_restricted_adjusted <- readRDS('objects/aipw_scores_restricted_adjusted.RDS')
  
}else{
  aipw_scores_restricted_adjusted <- aw_scores_eval(xs = xs_eval,
                                                    yobs = yobs_eval, 
                                                    ws = ws_restricted, 
                                                    sample.weights = what_eval_adjustment)
  
  saveRDS(aipw_scores_restricted_adjusted, 'objects/aipw_scores_restricted_adjusted.RDS')
  
}

```



```{r alternative_estimates, cache = TRUE}
balwts_eval <- (1/probs_eval)[cbind(1:nrow(df_eval), df_eval$W)]

# formatting for table
aipw_te_nopretest <- find_te(aipw_scores_nopretest)
aipw_te_learned_nopretest <- find_te(aipw_scores_learned_nopretest)
aipw_te_restricted_nopretest <- find_te(aipw_scores_restricted_nopretest)

aipw_est_nopretest <- find_est(aipw_scores_nopretest)
aipw_te_nopretest <- bind_rows(aipw_te_nopretest[1:4,],
                                aipw_te_learned_nopretest[1,],
                                aipw_te_restricted_nopretest[1,])


aipw_te_nocovariates <- find_te(aipw_scores_nocovariates)
aipw_te_learned_nocovariates <- find_te(aipw_scores_learned_nocovariates)
aipw_te_restricted_nocovariates <- find_te(aipw_scores_restricted_nocovariates)

aipw_est_nocovariates <- find_est(aipw_scores_nocovariates)
aipw_te_nocovariates <- bind_rows(aipw_te_nocovariates[1:4,],
                                aipw_te_learned_nocovariates[1,],
                                aipw_te_restricted_nocovariates[1,])


aipw_te_unbalanced <- find_te(aipw_scores_unbalanced)
aipw_te_learned_unbalanced <- find_te(aipw_scores_learned_unbalanced)
aipw_te_restricted_unbalanced <- find_te(aipw_scores_restricted_unbalanced)

aipw_est_unbalanced <- find_est(aipw_scores_unbalanced)
aipw_te_unbalanced <- bind_rows(aipw_te_unbalanced[1:4,],
                                aipw_te_learned_unbalanced[1,],
                                aipw_te_restricted_unbalanced[1,])

aipw_te_imputed <- find_te(aipw_scores_imputed)
aipw_te_learned_imputed <- find_te(aipw_scores_learned_imputed)
aipw_te_restricted_imputed <- find_te(aipw_scores_restricted_imputed)

aipw_est_imputed <- find_est(aipw_scores_imputed)
aipw_te_imputed <- bind_rows(aipw_te_imputed[1:4,],
                             aipw_te_learned_imputed[1,],
                             aipw_te_restricted_imputed[1,])


aipw_te_adjusted <- find_te(aipw_scores_adjusted)
aipw_te_learned_adjusted <- find_te(aipw_scores_learned_adjusted)
aipw_te_restricted_adjusted <- find_te(aipw_scores_restricted_adjusted)

aipw_est_adjusted <- find_est(aipw_scores_adjusted)
aipw_te_adjusted <- bind_rows(aipw_te_adjusted[1:4,],
                              aipw_te_learned_adjusted[1,],
                              aipw_te_restricted_adjusted[1,])

# Robust estimation with no covariates
l0 <- lm_robust(Y~W, data = df_eval,
                weights = balwts_eval)

l0l <- lm_robust(Y~ws_original, data = df_eval,
                 weights = balwts_eval)
l0a <- lm_robust(Y~ws_restricted, data = df_eval,
                 weights = balwts_eval)

l0 <- bind_rows(tidy(l0)[2:4,], tidy(l0)[6,], tidy(l0l)[2,], tidy(l0a)[2,], tidy(l0)[1,])
l0$p.value.upper <- pt(l0$estimate/l0$std.error, df = l0$df, lower = FALSE)


# Lin estimator adjusting for pre-test response
l1 <- lm_lin(Y~W, data = df_eval,
             weights = balwts_eval, 
             covariates = formula(' ~ pre_false + pre_true'))

l1l <- lm_lin(Y~ws_original, data = df_eval,
              weights = balwts_eval, 
              covariates = formula(' ~ pre_false + pre_true'))

l1a <- lm_lin(Y~ws_restricted, data = df_eval,
              weights = balwts_eval, 
              covariates = formula(' ~ pre_false + pre_true'))


l1 <- bind_rows(tidy(l1)[2:4,], tidy(l1)[6,], tidy(l1l)[2,], tidy(l1a)[2,], tidy(l1)[1,])
l1$p.value.upper <- pt(l1$estimate/l1$std.error, df = l1$df, lower = FALSE)

# 
# Lin by optimal0
l2 <- lm_lin(Y~W, data = df_eval,
             weights = balwts_eval, 
             covariates = formula(' ~ as.factor(optimal0)'))

l2l <- lm_lin(Y~ws_original, data = df_eval,
              weights = balwts_eval, 
              covariates = formula(' ~ as.factor(optimal0)'))

l2a <- lm_lin(Y~ws_restricted, data = df_eval,
              weights = balwts_eval, 
              covariates = formula(' ~ as.factor(optimal0)'))

l2 <- bind_rows(tidy(l2)[2:4,], tidy(l2)[6,], tidy(l2l)[2,], tidy(l2a)[2,], tidy(l2)[1,])
l2$p.value.upper <- pt(l2$estimate/l2$std.error, df = l2$df, lower = FALSE)

l0$term <- l1$term <- l2$term <- c(treatment_levels[-1], treatment_levels[1])
aipw_te_nopretest$term <- aipw_te_nocovariates$term <- aipw_te_unbalanced$term <- aipw_te_imputed$term <- aipw_te_adjusted$term <-
  treatment_levels[-1]

aipw_est_nopretest$term <- aipw_est_nocovariates$term <- aipw_est_unbalanced$term <- aipw_est_imputed$term <- aipw_est_adjusted$term <-
  treatment_levels[1]

# Mean response estimates
models <- list(
  `No pretest` = list(
    tidy = bind_rows(aipw_te_nopretest[1:6,],
                     aipw_est_nopretest[1,]),
    pval = 'p.value.upper'),
  `No covariates` = list(
    tidy = bind_rows(aipw_te_nocovariates[1:6,],
                     aipw_est_nocovariates[1,]),
    pval = 'p.value.upper'),
    `No covariate adjustment` = list(
    tidy = l0,
    pval = 'p.value'),
  `Pre-test response adjusted` = list(
    tidy = l1,
    pval = 'p.value'),
  `Block strata adjusted` = list(
    tidy = l2,
    pval = 'p.value'),
  # Missing data/ re-weighting
  `Unweighted` = list(
    tidy = bind_rows(aipw_te_unbalanced[1:6,],
                     aipw_est_unbalanced[1,]),
    pval = 'p.value.upper'),
  `Imputed` = list(
    tidy = bind_rows(aipw_te_imputed[1:6,],
                     aipw_est_imputed[1,]),
    pval = 'p.value.upper'),
  `Weighted to learning` = list(
    tidy = bind_rows(aipw_te_adjusted[1:6,],
                     aipw_est_adjusted[1,]),
    pval = 'p.value.upper')
)


models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  pvals <- x$tidy[,x$pval]
  pvals[length(pvals)] <- NA
  x$tidy$p.value <- pvals
  x
})

rows <- as.data.frame(matrix(c('', '(1)', '(2)', '(3)', '(4)', '(5)', '(6)', '(7)', '(8)',
                               'row2', rep('', 8),
                               'row7', rep('', 8),
                               'row16', rep('', 8)),
                             byrow = TRUE, ncol = 9
))

row2 <- '& \\multicolumn{5}{c}{Alternative covariate adjustment} & \\multicolumn{3}{c}{Missing data/ reweighting}\\\\ 
\\cmidrule(lr){2-6} \\cmidrule(lr){7-9} \\multicolumn{4}{l}{\\textbf{Headline treatment effects}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row7 <- '\\multicolumn{4}{l}{\\textbf{Respondent treatment effects}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row16 <- '\\hline'

attr(rows, 'position') <- c(1,2,7,16)

xx <- modelsummary(models, 
                   # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL,
                   
                   coef_rename = c('Headline\nFact check' = r'(\hspace{1em}Fact check)',
                                   'Headline\nRelated articles' = r'(\hspace{1em}Related articles)',
                                   'Respondent\nAccuracy' = r'(\hspace{1em}Accuracy)',
                                   'Respondent\nFacebook tips' = r'(\hspace{1em}Facebook tips)',
                                   'Respondent\nRestricted targeted' = r'(\hspace{1em}Restricted Targeted Policy)',
                                   'Respondent\nLearned targeted' = r'(\hspace{1em}Learned Targeted Policy)',
                                   'Control' = r'(\hspace{1em}Control mean)'),
                   output = 'latex_tabular')
xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '\\hline
\\hline\n
{\\textbf{Covariates}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\\n
\\hspace{1em} All & $-$ & $-$ & $-$ &  $-$ &  $-$ & Yes & Yes & Yes \\\\\n
\\hspace{1em} Pre-test response only & $-$  & $-$& $-$ & Yes &  $-$ &  $-$ &  $-$ &  $-$ \\\\\n
\\hspace{1em} Learned policy strata only & $-$ & $-$ &  $-$ &  $-$ &  Yes &  $-$ &  $-$ & $-$  \\\\\n
\\hspace{1em} None & $-$ &Yes &  Yes &$-$ &   $-$ &  $-$ &  $-$ &  $-$ \\\\\n
{\\textbf{Missing data}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\\n
\\hspace{1em} Imputing pre-test response & $-$ & $-$ &  $-$ &  $-$ &  $-$ &  $-$ & Yes &  $-$  \\\\\n
{\\textbf{Weights}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\\n
\\hspace{1em} Treatment assignment probability &Yes &Yes  & Yes & Yes & Yes & Yes & Yes & Yes \\\\\n
\\hspace{1em} Learning stage covariate distribution & $-$ & $-$ &  $-$ &  $-$ & $-$ &  $-$ &  $-$ &  Yes \\\\\n
\\hspace{1em} Censoring &Yes &Yes &  $-$ &  $-$ &  $-$ &  $-$ &  $-$ &  $-$ 
\\\\\n
{\\textbf{Estimator}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\\n
\\hspace{1em} (A)IPW Scores & Yes & Yes &  $-$ &  $-$ &  $-$ & Yes & Yes & Yes\\\\\n
\\hspace{1em} Robust OLS &  $-$ &  $-$ & Yes &  $-$ &  $-$ &  $-$ & $-$ &  $-$ \\\\\n
\\hspace{1em} Lin Estimator &  $-$ &  $-$ &  $-$ & Yes & Yes &  $-$ & $-$ &  $-$ \\\\\n
{\\textbf{n}} & 10,531 & 10,531 & 10,531 & 10,531 & 10,531 & 10,531 &11,534  & 10,531 
\\rule{0pt}{1.2\\normalbaselineskip}\\\\\n', xx[1], fixed = TRUE)

xx <- gsub('\nrow2 &  &  &  &  &  &  &  & \\\\', 
           row2, xx, fixed = TRUE)
xx <- gsub('\nrow7 &  &  &  &  &  &  &  & \\\\', 
           row7, xx, fixed = TRUE)
xx <- gsub('\nrow16 &  &  &  &  &  &  &  & \\\\', 
           row16, xx, fixed = TRUE)


yy <- gregexec('Learned Targeted Policy[& -\\{num}{0-9.*}]*', xx)

xx_substr <- substr(xx, yy[[1]][,1], yy[[1]][,1]+attr(yy[[1]], "match.length"))

xx <- gsub(xx_substr,
           paste0(xx_substr, ' \\hspace{1.5em}(maximizing sharing discernment)'),
           xx, fixed = TRUE)

yy <- gregexec('Restricted Targeted Policy[& -\\{num}{0-9.*}]*', xx)

xx_substr <- substr(xx, yy[[1]][,1], yy[[1]][,1]+attr(yy[[1]], "match.length"))

xx <- gsub(xx_substr,
           paste0(xx_substr, ' \\hspace{1.5em}(minimizing any false sharing)'),
           xx, fixed = TRUE)


writeLines(xx, '../tables/alternative_results.tex')


```



# Table S10: Control response and treatment effect estimates, secondary targeted policy
```{r learning_policy_combined_restricted, cache = TRUE}

cf.priority_c_alt <- causal_forest(
  X = xs_learn[train_idx, ],
  Y = df_learn$Y[train_idx],
  W = 1*(ws_r[train_idx]==2),
  W.hat = probs_r[train_idx, 2]/(rowSums(probs_r[train_idx, c(2,7)])),
  seed = 60637)

optimal_assignment_c_alt <- ifelse(predict(cf.priority_c_alt, xs_eval)$predictions>0, 4, 5)

```

```{r scores_policy_combined_restricted, cache = TRUE}
# restricted optimal policy, combined response function
if(file.exists('objects/aipw_scores_c_alt.RDS')){ # read in scores if already generated
  aipw_scores_c_alt <- readRDS('objects/aipw_scores_c_alt.RDS')
  
}else{
  aipw_scores_c_alt <- aw_scores_eval(xs = xs_eval,
                                      yobs = yobs_eval, 
                                      ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                               ws_eval == optimal_assignment_c_alt ~ 2,
                                                               TRUE ~ 3)), 
                                      sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_c_alt, 'objects/aipw_scores_c_alt.RDS')
  
}

# any true

if(file.exists('objects/aipw_scores_any_true_c_alt.RDS')){ # read in scores if already generated
  aipw_scores_any_true_c_alt <- readRDS('objects/aipw_scores_any_true_c_alt.RDS')
  
}else{
  
  aipw_scores_any_true_c_alt <- aw_scores_eval(xs = xs_eval,
                                               yobs = any_true, 
                                               ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                        ws_eval == optimal_assignment_c_alt ~ 2,
                                                                        TRUE ~ 3)), 
                                               sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_true_c_alt, 'objects/aipw_scores_any_true_c_alt.RDS')
  
}

# any false

if(file.exists('objects/aipw_scores_any_false_c_alt.RDS')){ # read in scores if already generated
  aipw_scores_any_false_c_alt <- readRDS('objects/aipw_scores_any_false_c_alt.RDS')
  
}else{
  
  aipw_scores_any_false_c_alt <- aw_scores_eval(xs = xs_eval,
                                                yobs = any_false, 
                                                ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                         ws_eval == optimal_assignment_c_alt ~ 2,
                                                                         TRUE ~ 3)), 
                                                sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_any_false_c_alt, 'objects/aipw_scores_any_false_c_alt.RDS')
  
}


# timeline true/false

if(file.exists('objects/aipw_scores_timeline_true_c_alt.RDS')){ # read in scores if already generated
  aipw_scores_timeline_true_c_alt <- readRDS('objects/aipw_scores_timeline_true_c_alt.RDS')
  
}else{
  
  aipw_scores_timeline_true_c_alt <- aw_scores_eval(xs = xs_eval,
                                                    yobs = timeline_true, 
                                                    ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                             ws_eval == optimal_assignment_c_alt ~ 2,
                                                                             TRUE ~ 3)), 
                                                    sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_true_c_alt, 'objects/aipw_scores_timeline_true_c_alt.RDS')
  
}

if(file.exists('objects/aipw_scores_timeline_false_c_alt.RDS')){ # read in scores if already generated
  aipw_scores_timeline_false_c_alt <- readRDS('objects/aipw_scores_timeline_false_c_alt.RDS')
  
}else{
  
  aipw_scores_timeline_false_c_alt <- aw_scores_eval(xs = xs_eval,
                                                     yobs = timeline_false, 
                                                     ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                              ws_eval == optimal_assignment_c_alt ~ 2,
                                                                              TRUE ~ 3)), 
                                                     sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_timeline_false_c_alt, 'objects/aipw_scores_timeline_false_c_alt.RDS')
  
}

# send true/false
if(file.exists('objects/aipw_scores_send_true_c_alt.RDS')){ # read in scores if already generated
  aipw_scores_send_true_c_alt <- readRDS('objects/aipw_scores_send_true_c_alt.RDS')
  
}else{
  
  aipw_scores_send_true_c_alt <- aw_scores_eval(xs = xs_eval,
                                                yobs = send_true, 
                                                ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                         ws_eval == optimal_assignment_c_alt ~ 2,
                                                                         TRUE ~ 3)), 
                                                sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_true_c_alt, 'objects/aipw_scores_send_true_c_alt.RDS')
  
}

if(file.exists('objects/aipw_scores_send_false_c_alt.RDS')){ # read in scores if already generated
  aipw_scores_send_false_c_alt <- readRDS('objects/aipw_scores_send_false_c_alt.RDS')
  
}else{
  
  aipw_scores_send_false_c_alt <- aw_scores_eval(xs = xs_eval,
                                                 yobs = send_false, 
                                                 ws = as.factor(case_when(ws_eval == 1 ~ 1,
                                                                          ws_eval == optimal_assignment_c_alt ~ 2,
                                                                          TRUE ~ 3)), 
                                                 sample.weights = balwts_uncens)
  
  saveRDS(aipw_scores_send_false_c_alt, 'objects/aipw_scores_send_false_c_alt.RDS')
  
}

```

```{r table_policy_combined_restricted, cache = TRUE}
# Mean response estimates
models <- list(
  `Sharing\nDiscernment` = list(
    tidy = find_te(aipw_scores_c_alt)[1,],
    pval = 'p.value.upper'),
  `False: Any sharing` = list(
    tidy = find_te(aipw_scores_any_false_c_alt)[1,],
    pval = 'p.value.lower'),
  `False: Messenger` = list(
    tidy = find_te(aipw_scores_send_false_c_alt)[1,],
    pval = 'p.value.lower'),
  `False: Timeline` = list(
    tidy = find_te(aipw_scores_timeline_false_c_alt)[1,],
    pval = 'p.value.lower'),
  `True: Any sharing` = list(
    tidy = find_te(aipw_scores_any_true_c_alt)[1,],
    pval = 'p.value.upper'),
  `True: Messenger` = list(
    tidy = find_te(aipw_scores_send_true_c_alt)[1,],
    pval = 'p.value.upper'),
  `True: Timeline` = list(
    tidy = find_te(aipw_scores_timeline_true_c_alt)[1,],
    pval = 'p.value.upper'
  )
)

models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  pvals <- x$tidy[,x$pval]
  x$tidy$p.value <- pvals
  x$tidy$term <- r'(\hspace{1em}Secondary targeted policy)'
  x
})


rows <- as.data.frame(matrix(c('', '\\textbf{Sharing}', '', '\\textbf{False}', '', '', '\\textbf{True}', '',
                               '', '\\textbf{Discernment}', 'Any sharing', 'Messenger', 'Timeline', 'Any sharing', 'Messenger', 'Timeline',
                               'row3', rep('', 7)),
                             byrow = TRUE, ncol = 8
))
row3 <- '\\cmidrule(lr){2-2} \\cmidrule(lr){3-5} \\cmidrule(lr){6-8}'

attr(rows, 'position') <- c(1,2,3)

xx <- modelsummary(models, 
                   # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL,
                   output = 'latex_tabular')
xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '', xx[1], fixed = TRUE)

xx <- gsub('\nrow3 &  &  &  &  &  &  & \\\\', 
           row3, xx, fixed = TRUE)

yy <- gregexec('Secondary targeted policy[& -\\{num}{0-9.*}]*', xx)

xx_substr <- substr(xx, yy[[1]][,1], yy[[1]][,1]+attr(yy[[1]], "match.length"))

xx <- gsub(xx_substr,
           paste0(xx_substr, ' \\hspace{1.5em}(maximizing sharing discernment)'),
           xx, fixed = TRUE)


writeLines(xx, '../tables/alternative_policy_results.tex')
```

# Figure S6: Significance of treatment effects under alternative weighting schemes

```{r post_truefalse_calcs, cache = TRUE, eval = TRUE, warning = FALSE}

false_weights <- seq(-1, -0.1, .1)
true_weights <- seq(0.1, 1, .1)

xy <- expand.grid(false_weights, true_weights)


out_l <- mapply(function(x, y) {
  yobs_z <- x*df_eval$post_false + y*df_eval$post_true
  z1 <- aw_scores_eval(xs = xs_eval,
                       yobs = yobs_z, 
                       ws = ws_eval, 
                       sample.weights = balwts_uncens)
  z2 <- aw_scores_eval(xs = xs_eval,
                       yobs = yobs_z, 
                       ws = as.factor(
                         case_when(ws_eval == 1 ~ 1,
                                   ws_eval == optimal_assignment_original ~ 2,
                                   TRUE ~ 3)), 
                       sample.weights = balwts_uncens)
  z3 <- aw_scores_eval(xs = xs_eval,
                       yobs = yobs_z, 
                       ws = as.factor(
                         case_when(ws_eval == 1 ~ 1,
                                   ws_eval == optimal_assignment ~ 2,
                                   TRUE ~ 3)), 
                       sample.weights = balwts_uncens)
  
  est_mat <- cbind(z1[, 2:5], z2[, 2], z3[, 2])
  colnames(est_mat)
  
  sapply(1:ncol(est_mat), function(i){
    z <- est_mat[,i]
    c(estimate = mean(z), 
      std.error = sd(z)/sqrt(length(z)),
      false_w = x, 
      true_w = y,
      term = i)
  }) %>% t()
},
xy[,1], 
xy[,2],
SIMPLIFY = FALSE
)


```

```{r post_truefalse_plots, cache = TRUE, eval = TRUE, warning = FALSE}
df <- do.call(rbind.data.frame, out_l)
df$Condition <- factor(treatment_levels[-1][df$term], 
                       levels = c(
                         'Headline\nFact check',
                         'Headline\nRelated articles', 
                         'Respondent\nAccuracy',
                         'Respondent\nFacebook tips',
                         'Respondent\nLearned targeted',
                         'Respondent\nRestricted targeted'
                       ))

df$`Logged negative ratio of false to true weights` <- log(-df$false_w/df$true_w)
df$Statistic <- df$estimate/df$std.error
ggplot(df, aes(x = `Logged negative ratio of false to true weights`, y = `Statistic`, color = Condition)) + 
  geom_point(size = 0.5) +
  geom_smooth(se = FALSE) + 
  # geom_line() +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'white'),
        plot.background = element_rect(fill = 'white', color = 'white')) + 
  scale_color_manual(values = cbPalette) + 
  geom_vline(xintercept = log(2), color ='grey60', linetype = 'dashed')

ggsave('../figures/alternative_weighting.png', width = 8, height = 4)
```




# Table S11: Heterogeneity, averaged respondent
```{r treatment_heterogeneity_primary, cache = TRUE}
# set outcomes
df_eval$pooled_respondent <- rowMeans(aipw_scores[, 4:5])

df_eval$pooled_respondent_any_false <- rowMeans(aipw_scores_any_false[, 4:5])
df_eval$pooled_respondent_any_true <- rowMeans(aipw_scores_any_true[, 4:5])

df_eval$pooled_respondent_send_false <- rowMeans(aipw_scores_send_false[, 4:5])
df_eval$pooled_respondent_send_true <- rowMeans(aipw_scores_send_true[, 4:5])

df_eval$pooled_respondent_timeline_false <- rowMeans(aipw_scores_timeline_false[, 4:5])
df_eval$pooled_respondent_timeline_true <- rowMeans(aipw_scores_timeline_true[, 4:5])

table <- sapply(covariate_list, function(x) {
  covariate <- x
  outcome <- 'pooled_respondent'
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste(outcome, ' ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste(outcome, ' ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0(outcome, ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0(outcome, ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
}, simplify = FALSE)
table <- do.call(rbind, table)

table_combined <- table %>% 
  mutate(
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household aealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

```


```{r treatment_heterogeneity_any, cache = TRUE}
apply_mat <- expand.grid(stimuli_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[2]
  outcome <- paste0('pooled_respondent_any_', stimuli_type)
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste(outcome, ' ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste(outcome, ' ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0(outcome, ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0(outcome, ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})
table <- do.call(rbind, table)

table_any <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

```

```{r treatment_heterogeneity_channel, cache = TRUE}
apply_mat <- expand.grid(stimuli_types, channel_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[3]
  channel <- x[2]
  outcome <- paste0('pooled_respondent_',  channel, '_', stimuli_type)
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0(outcome, 
                            ' ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0(outcome, 
                            ' ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0(outcome,
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0(outcome,
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      `Channel` = channel,
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})


table <- do.call(rbind, table)

table_channel <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )



```


```{r treatment_heterogeneity_combined, cache = TRUE}
# Mean response estimates
models <- list(
  `Sharing\nDiscernment` = list(tidy = table_combined),
  `False: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'False'),]),
  `False: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                         table_channel$Channel == 'send'),]),
  `False: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                        table_channel$Channel == 'timeline'),]),
  `True: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'True'),]),
  `True: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                        table_channel$Channel == 'send'),]),
  `True: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                       table_channel$Channel == 'timeline'),])
)

models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  x
})

rows <- as.data.frame(matrix(c('', '\\textbf{Sharing}', '', '\\textbf{False}', '', '', '\\textbf{True}', '',
                               '', '\\textbf{Discernment}', 'Any sharing', 'Messenger', 'Timeline', 'Any sharing', 'Messenger', 'Timeline',
                               'row3', rep('', 7),
                               'row8', rep('', 7),
                               'row11', rep('', 7),
                               'row16', rep('', 7),
                               'row19', rep('', 7),
                               'row24', rep('', 7),
                               'row27', rep('', 7),
                               'row32', rep('', 7),
                               'row35', rep('', 7),
                               'row40', rep('', 7)),
                             byrow = TRUE, ncol = 8
))

row3 <- '\\cmidrule(lr){2-2} \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\multicolumn{4}{l}{\\textbf{Age}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row8 <- '\\cmidrule(lr){2-8}'
row11 <- '\\multicolumn{4}{l}{\\textbf{Gender}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row16 <- '\\cmidrule(lr){2-8}'
row19 <- '\\multicolumn{4}{l}{\\textbf{Supports governing party}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row24 <- '\\cmidrule(lr){2-8}'
row27 <- '\\multicolumn{4}{l}{\\textbf{Digital literacy index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row32 <- '\\cmidrule(lr){2-8}'
row35 <- '\\multicolumn{4}{l}{\\textbf{Scientific knowledge index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row40 <- '\\cmidrule(lr){2-8}'

attr(rows, 'position') <- c(1,2,3,8,11,16,19,24,27,32,35,40)

xx <- modelsummary(models, 
                   # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL, 
                   coef_rename = c('Age: Below median (n = 5,300)' = r'(\hspace{1em} Below median)',
                                   'Age: Above median (n = 5,231)' = r'(\hspace{1em} Above Median)',
                                   'Age: Difference' = r'(\hspace{1em} Difference)',
                                   'Male:  Not male (n = 4,915)' = r'(\hspace{1em} Not male)',
                                   'Male: Male (n = 5,616)' = r'(\hspace{1em} Male)',
                                   'Male: Difference' = r'(\hspace{1em} Difference )',
                                   'Supports governing party:  Not aligned (n = 7,360)' = r'(\hspace{1em} Not aligned)',
                                   'Supports governing party: Aligned (n = 3,171)' = r'(\hspace{1em} Aligned)',
                                   'Supports governing party: Difference' = r'(\hspace{1em} Difference  )',
                                   'Digital literacy index: Below median (n = 5,418)' = r'(\hspace{1em} Below median )',
                                   'Digital literacy index: Above median (n = 5,113)' = r'(\hspace{1em} Above median )',
                                   'Digital literacy index: Difference' = r'(\hspace{1em}  Difference)',
                                   'Scientific knowledge index: Below median (n = 5,560)' = r'(\hspace{1em} Below median  )',
                                   'Scientific knowledge index: Above median (n = 4,971)' = r'(\hspace{1em} Above median  )',
                                   'Scientific knowledge index: Difference' = r'(\hspace{1em} Difference   )'),
                   output = 'latex_tabular')

xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '', xx[1], fixed = TRUE)

xx <- gsub('\nrow3 &  &  &  &  &  &  & \\\\', 
           row3, xx, fixed = TRUE)
xx <- gsub('\nrow8 &  &  &  &  &  &  & \\\\', 
           row8, xx, fixed = TRUE)
xx <- gsub('\nrow11 &  &  &  &  &  &  & \\\\', 
           row11, xx, fixed = TRUE)
xx <- gsub('\nrow16 &  &  &  &  &  &  & \\\\', 
           row16, xx, fixed = TRUE)
xx <- gsub('\nrow19 &  &  &  &  &  &  & \\\\', 
           row19, xx, fixed = TRUE)
xx <- gsub('\nrow24 &  &  &  &  &  &  & \\\\', 
           row24, xx, fixed = TRUE)
xx <- gsub('\nrow27 &  &  &  &  &  &  & \\\\', 
           row27, xx, fixed = TRUE)
xx <- gsub('\nrow32 &  &  &  &  &  &  & \\\\', 
           row32, xx, fixed = TRUE)
xx <- gsub('\nrow35 &  &  &  &  &  &  & \\\\', 
           row35, xx, fixed = TRUE)
xx <- gsub('\nrow40 &  &  &  &  &  &  & \\\\', 
           row40, xx, fixed = TRUE)

# ns for each subgroup
ns <- gsub('^[[:alpha:] : /]*', '', models$`Sharing\nDiscernment`$tidy$term)

for(i in 1:length(ns)){
  xx <- sub('\\\\\n & (', 
            paste0('\\\\\n\\hspace{2em}',ns[i], ' & ('), xx, fixed = TRUE)  
}


writeLines(xx, '../tables/heterogeneity_treatment.tex')
```


# Table S12: Heterogeneity, accuracy
```{r accuracy_heterogeneity_primary, cache = TRUE}

table <- sapply(covariate_list, function(x) {
  covariate <- x
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores[,4]  ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores[,4] ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores[,4] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores[,4] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
},
simplify = FALSE)
table <- do.call(rbind, table)

table_combined <- table %>% 
  mutate(
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

```

```{r accuracy_heterogeneity_any, cache = TRUE}

apply_mat <- expand.grid(stimuli_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[2]
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores_any_',stimuli_type,
                            '[,4] ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type,
                            '[,4] ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores_any_',stimuli_type, 
                            '[,4] ~  factor(',covariate, 
                            '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type, 
                            '[,4] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})
table <- do.call(rbind, table)

table_any <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

```

```{r accuracy_heterogeneity_channel, cache = TRUE}
apply_mat <- expand.grid(stimuli_types, channel_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[3]
  channel <- x[2]
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores_', channel, '_', stimuli_type, '[,4]', 
                            
                            ' ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type, '[,4]', 
                            ' ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores_', channel, '_',stimuli_type, '[,4]',
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores_', channel, '_',stimuli_type, '[,4]',
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      `Channel` = channel,
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})


table <- do.call(rbind, table)

table_channel <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )



```

```{r accuracy_combined_heterogeneity, cache = TRUE}
# Mean response estimates
models <- list(
  `Sharing\nDiscernment` = list(tidy = table_combined),
  `False: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'False'),]),
  `False: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                         table_channel$Channel == 'send'),]),
  `False: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                        table_channel$Channel == 'timeline'),]),
  `True: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'True'),]),
  `True: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                        table_channel$Channel == 'send'),]),
  `True: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                       table_channel$Channel == 'timeline'),])
)

models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  x
})

rows <- as.data.frame(matrix(c('', '\\textbf{Sharing}', '', '\\textbf{False}', '', '', '\\textbf{True}', '',
                               '', '\\textbf{Discernment}', 'Any sharing', 'Messenger', 'Timeline', 'Any sharing', 'Messenger', 'Timeline',
                               'row3', rep('', 7),
                               'row8', rep('', 7),
                               'row11', rep('', 7),
                               'row16', rep('', 7),
                               'row19', rep('', 7),
                               'row24', rep('', 7),
                               'row27', rep('', 7),
                               'row32', rep('', 7),
                               'row35', rep('', 7),
                               'row40', rep('', 7)),
                             byrow = TRUE, ncol = 8
))

row3 <- '\\cmidrule(lr){2-2} \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\multicolumn{4}{l}{\\textbf{Age}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row8 <- '\\cmidrule(lr){2-8}'
row11 <- '\\multicolumn{4}{l}{\\textbf{Gender}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row16 <- '\\cmidrule(lr){2-8}'
row19 <- '\\multicolumn{4}{l}{\\textbf{Supports governing party}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row24 <- '\\cmidrule(lr){2-8}'
row27 <- '\\multicolumn{4}{l}{\\textbf{Digital literacy index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row32 <- '\\cmidrule(lr){2-8}'
row35 <- '\\multicolumn{4}{l}{\\textbf{Scientific knowledge index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row40 <- '\\cmidrule(lr){2-8}'

attr(rows, 'position') <- c(1,2,3,8,11,16,19,24,27,32,35,40)

xx <- modelsummary(models, 
                   # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL, 
                   coef_rename = c('Age: Below median (n = 5,300)' = r'(\hspace{1em} Below median)',
                                   'Age: Above median (n = 5,231)' = r'(\hspace{1em} Above Median)',
                                   'Age: Difference' = r'(\hspace{1em} Difference)',
                                   'Male:  Not male (n = 4,915)' = r'(\hspace{1em} Not male)',
                                   'Male: Male (n = 5,616)' = r'(\hspace{1em} Male)',
                                   'Male: Difference' = r'(\hspace{1em} Difference )',
                                   'Supports governing party:  Not aligned (n = 7,360)' = r'(\hspace{1em} Not aligned)',
                                   'Supports governing party: Aligned (n = 3,171)' = r'(\hspace{1em} Aligned)',
                                   'Supports governing party: Difference' = r'(\hspace{1em} Difference  )',
                                   'Digital literacy index: Below median (n = 5,418)' = r'(\hspace{1em} Below median )',
                                   'Digital literacy index: Above median (n = 5,113)' = r'(\hspace{1em} Above median )',
                                   'Digital literacy index: Difference' = r'(\hspace{1em}  Difference)',
                                   'Scientific knowledge index: Below median (n = 5,560)' = r'(\hspace{1em} Below median  )',
                                   'Scientific knowledge index: Above median (n = 4,971)' = r'(\hspace{1em} Above median  )',
                                   'Scientific knowledge index: Difference' = r'(\hspace{1em} Difference   )'),
                   output = 'latex_tabular')

xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '', xx[1], fixed = TRUE)

xx <- gsub('\nrow3 &  &  &  &  &  &  & \\\\', 
           row3, xx, fixed = TRUE)
xx <- gsub('\nrow8 &  &  &  &  &  &  & \\\\', 
           row8, xx, fixed = TRUE)
xx <- gsub('\nrow11 &  &  &  &  &  &  & \\\\', 
           row11, xx, fixed = TRUE)
xx <- gsub('\nrow16 &  &  &  &  &  &  & \\\\', 
           row16, xx, fixed = TRUE)
xx <- gsub('\nrow19 &  &  &  &  &  &  & \\\\', 
           row19, xx, fixed = TRUE)
xx <- gsub('\nrow24 &  &  &  &  &  &  & \\\\', 
           row24, xx, fixed = TRUE)
xx <- gsub('\nrow27 &  &  &  &  &  &  & \\\\', 
           row27, xx, fixed = TRUE)
xx <- gsub('\nrow32 &  &  &  &  &  &  & \\\\', 
           row32, xx, fixed = TRUE)
xx <- gsub('\nrow35 &  &  &  &  &  &  & \\\\', 
           row35, xx, fixed = TRUE)
xx <- gsub('\nrow40 &  &  &  &  &  &  & \\\\', 
           row40, xx, fixed = TRUE)

# ns for each subgroup
ns <- gsub('^[[:alpha:] : /]*', '', models$`Sharing\nDiscernment`$tidy$term)

for(i in 1:length(ns)){
  xx <- sub('\\\\\n & (', 
            paste0('\\\\\n\\hspace{2em}',ns[i], ' & ('), xx, fixed = TRUE)  
}

writeLines(xx, '../tables/heterogeneity_accuracy.tex')
```

# Table S13: Heterogeneity, Facebook
```{r facebook_heterogeneity_primary, cache = TRUE}

table <- sapply(covariate_list, function(x) {
  covariate <- x
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores[,5]  ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores[,5] ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores[,5] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores[,5] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
},
simplify = FALSE)
table <- do.call(rbind, table)

table_combined <- table %>% 
  mutate(
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

```

```{r facebook_heterogeneity_any, cache = TRUE}

apply_mat <- expand.grid(stimuli_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[2]
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores_any_',stimuli_type,
                            '[,5] ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type,
                            '[,5] ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores_any_',stimuli_type, 
                            '[,5] ~  factor(',covariate, 
                            '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type, 
                            '[,5] ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})
table <- do.call(rbind, table)

table_any <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )

```

```{r facebook_heterogeneity_channel, cache = TRUE}
apply_mat <- expand.grid(stimuli_types, channel_types, covariate_list)
table <- apply(apply_mat, 1, function(x) {
  stimuli_type <- x[1]
  covariate <- x[3]
  channel <- x[2]
  
  if(length(unique(df_eval[, covariate])) <= 2){
    # binary covariates
    fmla0 <- formula(paste0('aipw_scores_', channel, '_', stimuli_type, '[,5]', 
                            
                            ' ~  factor(',covariate, ') -1'))
    fmla1 <- formula(paste0('aipw_scores_any_',stimuli_type, '[,5]', 
                            ' ~  factor(',covariate, ')'))
    ns <- table(df_eval[,covariate])
  }else{
    # continuous covariates
    adjustment <--1e-5*c(2*(median(df_eval[,covariate])==quantile(df_eval[,covariate], 1))-1)
    fmla0 <- formula(paste0('aipw_scores_', channel, '_',stimuli_type, '[,5]',
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,') -1'))
    fmla1 <- formula(paste0('aipw_scores_', channel, '_',stimuli_type, '[,5]',
                            ' ~  factor(',covariate, '> median(df_eval$', covariate, ') +', adjustment,')'))
    ns <- table(df_eval[,covariate] > median(df_eval[,covariate]) + adjustment)
  }
  ols0 <- tidy(lm_robust(fmla0, data=df_eval))
  ols1 <- tidy(lm_robust(fmla1, data=df_eval))
  
  
  # coef, standard error, n
  est_coef <- c(ols0$estimate, ols1$estimate[2])
  est_std.err <- c(ols0$std.error, ols1$std.error[2])
  p_value <- c(ols0$p.value, ols1$p.value[2])
  ns <- c(ns, sum(ns))
  
  # Tally up results
  outdf <- data.frame(estimate = est_coef,
                      std.error = est_std.err, 
                      p.value = p_value,
                      n = ns,
                      `Stimuli type` = str_to_sentence(stimuli_type),
                      `Covariate type` = str_to_sentence(covariate),
                      `Channel` = channel,
                      Type = c(0,1,2),
                      check.names = FALSE)
  
  outdf
  
})


table <- do.call(rbind, table)

table_channel <- table %>% 
  mutate(
    `Stimuli type` = factor(`Stimuli type`, 
                            levels = c('True', 'False')), 
    label = case_when(
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 0 ~ 
        paste0('Below median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Age', 'Dli','Hhi', 'Science')  & 
        Type == 1 ~ 
        paste0('Above median (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 0 ~ 
        paste0(' Not male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Male')  & 
        Type == 1 ~ 
        paste0('Male (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 0 ~ 
        paste0('Kenya (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Nigeria')  & 
        Type == 1 ~ 
        paste0('Nigeria (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 0 ~ 
        paste0(' Not aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      `Covariate type` %in%  c('Pol')  & 
        Type == 1 ~ 
        paste0('Aligned (n = ', prettyNum(n, big.mark = ','), ')'),
      TRUE ~ 'Difference'),
    `Covariate type` = case_when(`Covariate type` == 'Dli' ~ 
                                   'Digital literacy index',
                                 `Covariate type` == 'Hhi' ~ 
                                   'Household wealth Index',
                                 `Covariate type` == 'Nigeria' ~ 
                                   'Country',
                                 `Covariate type` == 'Pol' ~ 
                                   'Supports governing party',
                                 `Covariate type` == 'Science' ~ 
                                   'Scientific knowledge index',
                                 TRUE ~ `Covariate type`),
    term = paste0(`Covariate type`, ': ', label)
  )



```

```{r facebook_combined_heterogeneity, cache = TRUE}
# Mean response estimates
models <- list(
  `Sharing\nDiscernment` = list(tidy = table_combined),
  `False: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'False'),]),
  `False: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                         table_channel$Channel == 'send'),]),
  `False: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'False' &
                                                        table_channel$Channel == 'timeline'),]),
  `True: Any sharing` = list(tidy = table_any[which(table_any$`Stimuli type` == 'True'),]),
  `True: Messenger` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                        table_channel$Channel == 'send'),]),
  `True: Timeline` = list(tidy = table_channel[which(table_channel$`Stimuli type` == 'True' &
                                                       table_channel$Channel == 'timeline'),])
)

models <- lapply(models, function(x){
  class(x) <- "modelsummary_list"
  x
})

rows <- as.data.frame(matrix(c('', '\\textbf{Sharing}', '', '\\textbf{False}', '', '', '\\textbf{True}', '',
                               '', '\\textbf{Discernment}', 'Any sharing', 'Messenger', 'Timeline', 'Any sharing', 'Messenger', 'Timeline',
                               'row3', rep('', 7),
                               'row8', rep('', 7),
                               'row11', rep('', 7),
                               'row16', rep('', 7),
                               'row19', rep('', 7),
                               'row24', rep('', 7),
                               'row27', rep('', 7),
                               'row32', rep('', 7),
                               'row35', rep('', 7),
                               'row40', rep('', 7)),
                             byrow = TRUE, ncol = 8
))

row3 <- '\\cmidrule(lr){2-2} \\cmidrule(lr){3-5} \\cmidrule(lr){6-8} \\multicolumn{4}{l}{\\textbf{Age}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row8 <- '\\cmidrule(lr){2-8}'
row11 <- '\\multicolumn{4}{l}{\\textbf{Gender}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row16 <- '\\cmidrule(lr){2-8}'
row19 <- '\\multicolumn{4}{l}{\\textbf{Supports governing party}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row24 <- '\\cmidrule(lr){2-8}'
row27 <- '\\multicolumn{4}{l}{\\textbf{Digital literacy index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row32 <- '\\cmidrule(lr){2-8}'
row35 <- '\\multicolumn{4}{l}{\\textbf{Scientific knowledge index}} \\rule{0pt}{1.2\\normalbaselineskip}\\\\'
row40 <- '\\cmidrule(lr){2-8}'

attr(rows, 'position') <- c(1,2,3,8,11,16,19,24,27,32,35,40)

xx <- modelsummary(models, 
                   # stars = TRUE,  
                   add_rows = rows,
                   escape = FALSE,
                   col.names = NULL, 
                   coef_rename = c('Age: Below median (n = 5,300)' = r'(\hspace{1em} Below median)',
                                   'Age: Above median (n = 5,231)' = r'(\hspace{1em} Above Median)',
                                   'Age: Difference' = r'(\hspace{1em} Difference)',
                                   'Male:  Not male (n = 4,915)' = r'(\hspace{1em} Not male)',
                                   'Male: Male (n = 5,616)' = r'(\hspace{1em} Male)',
                                   'Male: Difference' = r'(\hspace{1em} Difference )',
                                   'Supports governing party:  Not aligned (n = 7,360)' = r'(\hspace{1em} Not aligned)',
                                   'Supports governing party: Aligned (n = 3,171)' = r'(\hspace{1em} Aligned)',
                                   'Supports governing party: Difference' = r'(\hspace{1em} Difference  )',
                                   'Digital literacy index: Below median (n = 5,418)' = r'(\hspace{1em} Below median )',
                                   'Digital literacy index: Above median (n = 5,113)' = r'(\hspace{1em} Above median )',
                                   'Digital literacy index: Difference' = r'(\hspace{1em}  Difference)',
                                   'Scientific knowledge index: Below median (n = 5,560)' = r'(\hspace{1em} Below median  )',
                                   'Scientific knowledge index: Above median (n = 4,971)' = r'(\hspace{1em} Above median  )',
                                   'Scientific knowledge index: Difference' = r'(\hspace{1em} Difference   )'),
                   output = 'latex_tabular')

xx <- gsub('\n\\toprule', '', xx[1], fixed = TRUE)
xx <- gsub('\n\\bottomrule', '', xx[1], fixed = TRUE)

xx <- gsub('\nrow3 &  &  &  &  &  &  & \\\\', 
           row3, xx, fixed = TRUE)
xx <- gsub('\nrow8 &  &  &  &  &  &  & \\\\', 
           row8, xx, fixed = TRUE)
xx <- gsub('\nrow11 &  &  &  &  &  &  & \\\\', 
           row11, xx, fixed = TRUE)
xx <- gsub('\nrow16 &  &  &  &  &  &  & \\\\', 
           row16, xx, fixed = TRUE)
xx <- gsub('\nrow19 &  &  &  &  &  &  & \\\\', 
           row19, xx, fixed = TRUE)
xx <- gsub('\nrow24 &  &  &  &  &  &  & \\\\', 
           row24, xx, fixed = TRUE)
xx <- gsub('\nrow27 &  &  &  &  &  &  & \\\\', 
           row27, xx, fixed = TRUE)
xx <- gsub('\nrow32 &  &  &  &  &  &  & \\\\', 
           row32, xx, fixed = TRUE)
xx <- gsub('\nrow35 &  &  &  &  &  &  & \\\\', 
           row35, xx, fixed = TRUE)
xx <- gsub('\nrow40 &  &  &  &  &  &  & \\\\', 
           row40, xx, fixed = TRUE)

# ns for each subgroup
ns <- gsub('^[[:alpha:] : /]*', '', models$`Sharing\nDiscernment`$tidy$term)

for(i in 1:length(ns)){
  xx <- sub('\\\\\n & (', 
            paste0('\\\\\n\\hspace{2em}',ns[i], ' & ('), xx, fixed = TRUE)  
}


writeLines(xx, '../tables/heterogeneity_facebook.tex')
```






# Additional in-text results

## Abstract
```{r abstract_values}
# Users share more discerningly when they are given tips for spotting misinformation or are nudged to consider information’s accuracy, reducing misinformation sharing by
round(colMeans(aipw_scores_any_false)[5]/colMeans(aipw_scores_any_false)[1],3)*100

round(colMeans(aipw_scores_any_false)[4]/colMeans(aipw_scores_any_false)[1],3)*100
```


## Results: Learning and evaluation stages

### Benefits from adaptivity
```{r adaptive_vs_uniform, cache = TRUE, warning=FALSE, message=FALSE}
gammahat <- aipw_scoresR_learn
policy0 <- policy1 <- matrix(0, nrow = A, ncol = ncol(gammahat))
policy1[] <- 1/40

est <- output_estimates(policy0 = policy0, 
                        policy1 = policy1, 
                        gammahat = gammahat, 
                        contextual_probs = contextual_probs)

rbind(adaptive = c(mean(yobs_learn), sd(yobs_learn)/sqrt(length(yobs_learn))),
      uniform = est)

round((mean(yobs_learn) - est[1])*length(yobs_learn)/
        sum(df_learn$post_false_send +df_learn$post_false_timeline),3)*100

x_est <- (mean(yobs_learn) - est[1])
x_se <- sqrt(var(yobs_learn)/length(yobs_learn) +  est[2]^2)
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,3), '$, ',
         's.e. = $', round(x_se,3), '$, ',
         '$Z = ', round(x_stat,3), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),3), collapse = '$, $'), '$]' )
)



write.csv(rbind(adaptive = c(mean(yobs_learn), sd(yobs_learn)/sqrt(length(yobs_learn))),
                uniform = est),
          '../tables/benefits-adaptivity.csv')
```

### Interaction sample size
```{r interaction}
# Smallest number of observations per arm
min(table(df_learn$W))
```


### Overlap
```{r overlap_policy}
# proportion of respondents in each condition in learned policy
round(prop.table(table(optimal_assignment_original))*100,1)
# proportion of respondents in each condition in restricted policy
round(prop.table(table(optimal_assignment))*100,1)
# Overlap between learned targeted policy and restricted targeted policy
sum(diag(prop.table(table(optimal_assignment_original, optimal_assignment))))
```

## Results: Discernment under control


```{r discernment_control}
# UNDER CONTROL
# Difference in sharing of any true vs. false
x <- (aipw_scores_any_true[,1] - aipw_scores_any_false[,1])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)
# ratio
round(mean(aipw_scores_any_true[,1])/mean(aipw_scores_any_false[,1]),3)



# Difference in TRUE sharing of timeline vs. messenger
x <- (aipw_scores_timeline_true[,1] - aipw_scores_send_true[,1])

x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# ratio
round(mean(aipw_scores_timeline_true[,1])/mean(aipw_scores_send_true[,1]),3)


# Difference in FALSE sharing of timeline vs. messenger
x <- (aipw_scores_timeline_false[,1] - aipw_scores_send_false[,1])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# ratio
1-round(mean(aipw_scores_timeline_false[,1])/mean(aipw_scores_send_false[,1]),3)


# men are more likely to share false posts than women, while low digital literacy are more likely to share false posts
x <- table_any_control[which(table_any_control$`Covariate type` == 'Male' & 
                          table_any_control$`Stimuli type` == 'False'), 'estimate']

round(1- x[2]/x[1],3)*100

x <- table_any_control[which(table_any_control$`Covariate type` == 'Digital literacy index' & 
                          table_any_control$`Stimuli type` == 'False'), 'estimate']

round(1- x[1]/x[2],3)*100
```

## Results: Main treatment effects

```{r results_main}
# Fact check main effects
x <- (aipw_scores_any_false[,2])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)


# Related articles main effects
x <- (aipw_scores_any_false[,3])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)


# Accuracy
x <- (aipw_scores[,4])
x_est <- mean(x)
x_se <- sd(x)/sqrt(length(x))
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,3), '$, ',
         's.e. = $', round(x_se,3), '$, ',
         '$Z = ', round(x_stat,3), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),3), collapse = '$, $'), '$]' )
)

# FB tips
x <- (aipw_scores[,5])
x_est <- mean(x)
x_se <- sd(x)/sqrt(length(x))
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,3), '$, ',
         's.e. = $', round(x_se,3), '$, ',
         '$Z = ', round(x_stat,3), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),3), collapse = '$, $'), '$]' )
)


# Accuracy
x <- (aipw_scores_any_false[,4])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)


# FB tips
x <- (aipw_scores_any_false[,5])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

```


## Results: Heterogeneity in best policy

```{r results_heterogeneity_best}

# HETEROGENEITY IN BEST
# we achieve larger magnitude treatment effects in decreasing false sharing intentions through our contextual policy as compared to either the accuracy nudge or the Facebook tips treatments assigned uniformly
# policy on its own
x <- (aipw_scores_any_false_restricted[,2])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# ratio
round(mean(x)/mean(aipw_scores_any_false_restricted[,1]),3)


# accuracy
x <- (aipw_scores_any_false_restricted[,2] - aipw_scores_any_false[,4])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# fb
x <- (aipw_scores_any_false_restricted[,2] - aipw_scores_any_false[,5])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# vs. learned targeted
x <- (aipw_scores_any_false_restricted[,2] - aipw_scores_any_false_learned[,2])
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# 
# The restricted targeted policy is also more effective at moving the combined 
# response function than the original learned targeted policy 
# accuracy
x <- (aipw_scores_restricted[,2] - aipw_scores[,4])
x_est <- mean(x)
x_se <- sd(x)/sqrt(length(x))
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,3), '$, ',
         's.e. = $', round(x_se,3), '$, ',
         '$Z = ', round(x_stat,3), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),3), collapse = '$, $'), '$]' )
)

# fb
x <- (aipw_scores_restricted[,2] - aipw_scores[,5])
x_est <- mean(x)
x_se <- sd(x)/sqrt(length(x))
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,3), '$, ',
         's.e. = $', round(x_se,3), '$, ',
         '$Z = ', round(x_stat,3), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),3), collapse = '$, $'), '$]' )
)

# vs. learned targeted
x <- (aipw_scores_restricted[,2] - aipw_scores_learned[,2])
x_est <- mean(x)
x_se <- sd(x)/sqrt(length(x))
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,3), '$, ',
         's.e. = $', round(x_se,3), '$, ',
         '$Z = ', round(x_stat,3), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),3), collapse = '$, $'), '$]' )
)
```

```{r het_treatment}
# on average, participants assigned to receive the accuracy nudge intend to share false information at lower rates under the accuracy nudge as compared to Facebook tips
round(1-  mean( (aipw_scores_any_false[,4]+ aipw_scores_any_false[,1])[which(optimal_assignment == 4)])/mean( (aipw_scores_any_false[,5]+ aipw_scores_any_false[,1])[which(optimal_assignment == 4)] ),3)

x_1 <- (aipw_scores_any_false[,4]+ aipw_scores_any_false[,1])[which(optimal_assignment == 4)]
x_2 <- (aipw_scores_any_false[,5]+ aipw_scores_any_false[,1])[which(optimal_assignment == 4)]
x_est <- (mean(x_1) - mean(x_2))*100
x_se <- sqrt(sd(x_1)/length(x_1) + var(x_2)/length(x_2))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# the reverse is true for participants assigned Facebook tips
round(mean( (aipw_scores_any_false[,4]+ aipw_scores_any_false[,1])[which(optimal_assignment == 5)])/mean( (aipw_scores_any_false[,5]+ aipw_scores_any_false[,1])[which(optimal_assignment == 5)] ),3)

x_1 <- (aipw_scores_any_false[,4]+ aipw_scores_any_false[,1])[which(optimal_assignment == 5)]
x_2 <- (aipw_scores_any_false[,5]+ aipw_scores_any_false[,1])[which(optimal_assignment == 5)]
x_est <- (mean(x_1) - mean(x_2))*100
x_se <- sqrt(sd(x_1)/length(x_1) + var(x_2)/length(x_2))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)
# 
fmla_het <- formula('any_false ~  factor(condition)*factor(optimal==5)')
ols_het <- tidy(lm_robust(fmla_het, data=any_df))
ols_het[4,]
round(ols_het[4,2:7], 3)
```

## Results: Sharing channel
```{r results_channel}

# CHANNEL SHARING

# The Facebook tips treatment and the accuracy nudge are both effective at moving false sharing intentions on messenger
# accuracy
x <- aipw_scores_send_false[,4]
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# fb
x <- aipw_scores_send_false[,5]
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)


# and timeline
# accuracy
x <- aipw_scores_timeline_false[,4]
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)

# fb
x <- aipw_scores_timeline_false[,5]
x_est <- mean(x)*100
x_se <- sd(x)/sqrt(length(x))*100
x_stat <- x_est/x_se

cat(
  paste0('estimate = $', round(x_est,1), '$~pp, ',
         's.e. = $', round(x_se,1), '$, ',
         '$Z = ', round(x_stat,2), '$, ',
         '$p ', ifelse(round(2*(1-pnorm(abs(x_stat))),2)< 0.001, '< 0.001', paste0('= ', round(2*(1-pnorm(abs(x_stat))),2) )) ,'$, ',
         '95\\% Confidence Interval = ', '[$', paste(round(x_est + x_se*1.96*c(-1,1),2), collapse = '$, $'), '$]' )
)


```


## Appendix: Evaluation stage

```{r control_pretest}
# BENEFITS TO CONTROLLING FOR PRE-TEST
# We note here the benefits to controlling for pre-rest response; comparing columns 3 and 4,
# for example, the standard error on the control mean is reduced:
1- (sd(aipw_scores[,1])/sqrt(length(aipw_scores[,1])))/
 (sd(aipw_scores_nopretest[,1])/sqrt(length(aipw_scores_nopretest[,1])))

1- l1[l1$term == 'Control','std.error']/l0[l0$term == 'Control','std.error']






# DESCRIPTION OF ALTERNATIVE TARGETED POLICY, USING COMBINED RESPONSE
prop.table(table(optimal_assignment_c_alt))

sum(diag(prop.table(table(optimal_assignment_c_alt, optimal_assignment))))

sum(diag(prop.table(table(optimal_assignment_c_alt, optimal_assignment_original))))
```


```{r load_cached, eval = FALSE}
qwraps2::lazyload_cache_dir(path = "misinformation_replication_cache/html")
source('utils.R')
```

